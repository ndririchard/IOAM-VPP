From 06b32e3fe737670bc804c4c6b29509f286578b41 Mon Sep 17 00:00:00 2001
From: ndririchard <ndririchard@outlook.com>
Date: Tue, 13 Sep 2022 21:13:32 +0200
Subject: [PATCH] patch vpp

---
 src/plugins/dpdk/node.c                       |  569 +++++
 src/plugins/ioam/analyse/ioam_analyse.h       |  317 ++-
 src/plugins/ioam/encap/ip6_ioam_trace.c       |  610 ++++--
 src/plugins/ioam/encap/ip6_ioam_trace.h       |   20 +-
 src/plugins/ioam/lib-trace/trace.api          |   32 +-
 src/plugins/ioam/lib-trace/trace_api.c        |  102 +-
 src/plugins/ioam/lib-trace/trace_test.c       |    6 +-
 src/plugins/ioam/lib-trace/trace_util.c       |  426 +++-
 src/plugins/ioam/lib-trace/trace_util.h       |  484 +++--
 .../ioam/lib-vxlan-gpe/vxlan_gpe_ioam.h       |    5 -
 .../ioam/lib-vxlan-gpe/vxlan_gpe_ioam_trace.c |  249 ++-
 src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam.h  |  114 ++
 .../ioam/nsh-md2-ioam/nsh_md2_ioam_trace.c    |  461 +++++
 src/plugins/ioam/udp-ping/udp_ping_node.c     |    2 +-
 src/plugins/ioam/udp-ping/udp_ping_util.c     |   11 +-
 src/plugins/ioam/udp-ping/udp_ping_util.h     |    2 +-
 src/plugins/ip/ip.api                         |  769 +++++++
 src/plugins/ip/ip6_hop_by_hop.c               | 1822 +++++++++++++++++
 src/plugins/ip/ip6_hop_by_hop.h               |  296 +++
 src/plugins/ip/ip6_hop_by_hop_packet.h        |   62 +
 src/plugins/ip/ip_api.c                       | 1817 ++++++++++++++++
 src/plugins/timestamp/node.c                  |  245 +++
 src/plugins/timestamp/timestamp.api           |   34 +
 src/plugins/timestamp/timestamp.c             |  177 ++
 src/plugins/timestamp/timestamp.h             |   47 +
 src/plugins/timestamp/timestamp_plugin_doc.md |   44 +
 src/plugins/timestamp/timestamp_test.c        |   83 +
 27 files changed, 8004 insertions(+), 802 deletions(-)
 create mode 100644 src/plugins/dpdk/node.c
 create mode 100644 src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam.h
 create mode 100644 src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam_trace.c
 create mode 100644 src/plugins/ip/ip.api
 create mode 100644 src/plugins/ip/ip6_hop_by_hop.c
 create mode 100644 src/plugins/ip/ip6_hop_by_hop.h
 create mode 100644 src/plugins/ip/ip6_hop_by_hop_packet.h
 create mode 100644 src/plugins/ip/ip_api.c
 create mode 100644 src/plugins/timestamp/node.c
 create mode 100644 src/plugins/timestamp/timestamp.api
 create mode 100644 src/plugins/timestamp/timestamp.c
 create mode 100644 src/plugins/timestamp/timestamp.h
 create mode 100644 src/plugins/timestamp/timestamp_plugin_doc.md
 create mode 100644 src/plugins/timestamp/timestamp_test.c

diff --git a/src/plugins/dpdk/node.c b/src/plugins/dpdk/node.c
new file mode 100644
index 000000000..92ec0d36c
--- /dev/null
+++ b/src/plugins/dpdk/node.c
@@ -0,0 +1,569 @@
+/*
+ * Copyright (c) 2015 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#include <vnet/vnet.h>
+#include <vppinfra/vec.h>
+#include <vppinfra/error.h>
+#include <vppinfra/format.h>
+#include <vppinfra/xxhash.h>
+
+#include <vnet/ethernet/ethernet.h>
+#include <dpdk/buffer.h>
+#include <dpdk/device/dpdk.h>
+#include <vnet/classify/vnet_classify.h>
+#include <vnet/mpls/packet.h>
+#include <vnet/handoff.h>
+#include <vnet/devices/devices.h>
+#include <vnet/interface/rx_queue_funcs.h>
+#include <vnet/feature/feature.h>
+
+#include <dpdk/device/dpdk_priv.h>
+
+#include <vnet/ip/ip6.h>
+
+static char *dpdk_error_strings[] = {
+#define _(n,s) s,
+  foreach_dpdk_error
+#undef _
+};
+
+/* make sure all flags we need are stored in lower 8 bits */
+STATIC_ASSERT ((PKT_RX_IP_CKSUM_BAD | PKT_RX_FDIR) <
+	       256, "dpdk flags not un lower byte, fix needed");
+
+static_always_inline uword
+dpdk_process_subseq_segs (vlib_main_t * vm, vlib_buffer_t * b,
+			  struct rte_mbuf *mb, vlib_buffer_t * bt)
+{
+  u8 nb_seg = 1;
+  struct rte_mbuf *mb_seg = 0;
+  vlib_buffer_t *b_seg, *b_chain = 0;
+  mb_seg = mb->next;
+  b_chain = b;
+
+  if (mb->nb_segs < 2)
+    return 0;
+
+  b->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+  b->total_length_not_including_first_buffer = 0;
+
+  while (nb_seg < mb->nb_segs)
+    {
+      ASSERT (mb_seg != 0);
+
+      b_seg = vlib_buffer_from_rte_mbuf (mb_seg);
+      vlib_buffer_copy_template (b_seg, bt);
+
+      /*
+       * The driver (e.g. virtio) may not put the packet data at the start
+       * of the segment, so don't assume b_seg->current_data == 0 is correct.
+       */
+      b_seg->current_data =
+	(mb_seg->buf_addr + mb_seg->data_off) - (void *) b_seg->data;
+
+      b_seg->current_length = mb_seg->data_len;
+      b->total_length_not_including_first_buffer += mb_seg->data_len;
+
+      b_chain->flags |= VLIB_BUFFER_NEXT_PRESENT;
+      b_chain->next_buffer = vlib_get_buffer_index (vm, b_seg);
+
+      b_chain = b_seg;
+      mb_seg = mb_seg->next;
+      nb_seg++;
+    }
+  return b->total_length_not_including_first_buffer;
+}
+
+static_always_inline void
+dpdk_prefetch_mbuf_x4 (struct rte_mbuf *mb[])
+{
+  CLIB_PREFETCH (mb[0], CLIB_CACHE_LINE_BYTES, LOAD);
+  CLIB_PREFETCH (mb[1], CLIB_CACHE_LINE_BYTES, LOAD);
+  CLIB_PREFETCH (mb[2], CLIB_CACHE_LINE_BYTES, LOAD);
+  CLIB_PREFETCH (mb[3], CLIB_CACHE_LINE_BYTES, LOAD);
+}
+
+static_always_inline void
+dpdk_prefetch_buffer_x4 (struct rte_mbuf *mb[])
+{
+  vlib_buffer_t *b;
+  b = vlib_buffer_from_rte_mbuf (mb[0]);
+  CLIB_PREFETCH (b, CLIB_CACHE_LINE_BYTES, LOAD);
+  b = vlib_buffer_from_rte_mbuf (mb[1]);
+  CLIB_PREFETCH (b, CLIB_CACHE_LINE_BYTES, LOAD);
+  b = vlib_buffer_from_rte_mbuf (mb[2]);
+  CLIB_PREFETCH (b, CLIB_CACHE_LINE_BYTES, LOAD);
+  b = vlib_buffer_from_rte_mbuf (mb[3]);
+  CLIB_PREFETCH (b, CLIB_CACHE_LINE_BYTES, LOAD);
+}
+
+/** \brief Main DPDK input node
+    @node dpdk-input
+
+    This is the main DPDK input node: across each assigned interface,
+    call rte_eth_rx_burst(...) or similar to obtain a vector of
+    packets to process. Derive @c vlib_buffer_t metadata from
+    <code>struct rte_mbuf</code> metadata,
+    Depending on the resulting metadata: adjust <code>b->current_data,
+    b->current_length </code> and dispatch directly to
+    ip4-input-no-checksum, or ip6-input. Trace the packet if required.
+
+    @param vm   vlib_main_t corresponding to the current thread
+    @param node vlib_node_runtime_t
+    @param f    vlib_frame_t input-node, not used.
+
+    @par Graph mechanics: buffer metadata, next index usage
+
+    @em Uses:
+    - <code>struct rte_mbuf mb->ol_flags</code>
+        - PKT_RX_IP_CKSUM_BAD
+
+    @em Sets:
+    - <code>b->error</code> if the packet is to be dropped immediately
+    - <code>b->current_data, b->current_length</code>
+        - adjusted as needed to skip the L2 header in  direct-dispatch cases
+    - <code>vnet_buffer(b)->sw_if_index[VLIB_RX]</code>
+        - rx interface sw_if_index
+    - <code>vnet_buffer(b)->sw_if_index[VLIB_TX] = ~0</code>
+        - required by ipX-lookup
+    - <code>b->flags</code>
+        - to indicate multi-segment pkts (VLIB_BUFFER_NEXT_PRESENT), etc.
+
+    <em>Next Nodes:</em>
+    - Static arcs to: error-drop, ethernet-input,
+      ip4-input-no-checksum, ip6-input, mpls-input
+    - per-interface redirection, controlled by
+      <code>xd->per_interface_next_index</code>
+*/
+
+static_always_inline u16
+dpdk_ol_flags_extract (struct rte_mbuf **mb, u16 * flags, int count)
+{
+  u16 rv = 0;
+  int i;
+  for (i = 0; i < count; i++)
+    {
+      /* all flags we are interested in are in lower 8 bits but
+         that might change */
+      flags[i] = (u16) mb[i]->ol_flags;
+      rv |= flags[i];
+    }
+  return rv;
+}
+
+/*
+ * Inserts TX queue size and number of available descriptors
+*/
+static_always_inline void
+dpdk_insert_tx_ring_stats (vlib_buffer_t * b, dpdk_main_t * dm)
+{
+  /* Find the TX interface and get its queue */
+  u32 adj_index = vnet_buffer (b)->ip.adj_index[VLIB_TX];
+  ip_adjacency_t *adj = adj_get (adj_index);
+  if (adj)
+    {
+      // Get TX hardware interface index
+      u32 txid = adj->rewrite_header.sw_if_index;
+      txid = (vnet_get_sup_hw_interface (dm->vnet_main, txid))->hw_if_index;
+      // Get the device associated with the hardware index provided
+      vnet_hw_interface_t *hw = vnet_get_hw_interface (dm->vnet_main, txid);
+      if (hw)
+	{
+	  dpdk_device_t *txd =
+	    vec_elt_at_index (dm->devices, hw->dev_instance);
+	  if (txd)
+	    {
+	      u16 ring_size = txd->nb_tx_desc;
+	      u16 tx_port_id = txd->port_id;
+
+	      u16 tx_queue_id = dm->vlib_main->thread_index % txd->tx_q_used;
+	      u16 num_desc = 0;
+	      u16 tx_ring_desc_avai = 0;
+	      // Find number of available descriptors
+	      do
+		{
+		  if (rte_eth_tx_descriptor_status
+		      (tx_port_id, tx_queue_id,
+		       num_desc) == RTE_ETH_TX_DESC_DONE)
+		    {
+		      tx_ring_desc_avai++;
+		    }
+		}
+	      while (++num_desc < ring_size);
+	      // Now put into buffer opaque2, 32-bit = [ring_size][descriptors available]
+	      u32 *opaque = &vnet_buffer2 (b)->unused[7];	// 8, 32-bit words in opaque2, use last
+	      *opaque =
+		clib_host_to_net_u32 (((u32) ring_size << 16) |
+				      tx_ring_desc_avai);
+	    }
+	}
+    }
+}
+
+static_always_inline uword
+dpdk_process_rx_burst (vlib_main_t * vm, dpdk_per_thread_data_t * ptd,
+		       uword n_rx_packets, int maybe_multiseg,
+		       u16 * or_flagsp)
+{
+  u32 n_left = n_rx_packets;
+  vlib_buffer_t *b[4];
+  struct rte_mbuf **mb = ptd->mbufs;
+  uword n_bytes = 0;
+  u16 *flags, or_flags = 0;
+  vlib_buffer_t bt;
+
+  mb = ptd->mbufs;
+  flags = ptd->flags;
+
+  dpdk_main_t *dm = &dpdk_main;
+
+  /* copy template into local variable - will save per packet load */
+  vlib_buffer_copy_template (&bt, &ptd->buffer_template);
+  while (n_left >= 8)
+    {
+      dpdk_prefetch_buffer_x4 (mb + 4);
+
+      b[0] = vlib_buffer_from_rte_mbuf (mb[0]);
+      b[1] = vlib_buffer_from_rte_mbuf (mb[1]);
+      b[2] = vlib_buffer_from_rte_mbuf (mb[2]);
+      b[3] = vlib_buffer_from_rte_mbuf (mb[3]);
+
+      vlib_buffer_copy_template (b[0], &bt);
+      vlib_buffer_copy_template (b[1], &bt);
+      vlib_buffer_copy_template (b[2], &bt);
+      vlib_buffer_copy_template (b[3], &bt);
+
+      dpdk_prefetch_mbuf_x4 (mb + 4);
+
+      or_flags |= dpdk_ol_flags_extract (mb, flags, 4);
+      flags += 4;
+
+      b[0]->current_data = mb[0]->data_off - RTE_PKTMBUF_HEADROOM;
+      n_bytes += b[0]->current_length = mb[0]->data_len;
+
+      b[1]->current_data = mb[1]->data_off - RTE_PKTMBUF_HEADROOM;
+      n_bytes += b[1]->current_length = mb[1]->data_len;
+
+      b[2]->current_data = mb[2]->data_off - RTE_PKTMBUF_HEADROOM;
+      n_bytes += b[2]->current_length = mb[2]->data_len;
+
+      b[3]->current_data = mb[3]->data_off - RTE_PKTMBUF_HEADROOM;
+      n_bytes += b[3]->current_length = mb[3]->data_len;
+
+      if (maybe_multiseg)
+	{
+	  n_bytes += dpdk_process_subseq_segs (vm, b[0], mb[0], &bt);
+	  n_bytes += dpdk_process_subseq_segs (vm, b[1], mb[1], &bt);
+	  n_bytes += dpdk_process_subseq_segs (vm, b[2], mb[2], &bt);
+	  n_bytes += dpdk_process_subseq_segs (vm, b[3], mb[3], &bt);
+	}
+
+      VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[0]);
+      VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[1]);
+      VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[2]);
+      VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[3]);
+
+      dpdk_insert_tx_ring_stats (b[0], dm);
+      dpdk_insert_tx_ring_stats (b[1], dm);
+      dpdk_insert_tx_ring_stats (b[2], dm);
+      dpdk_insert_tx_ring_stats (b[3], dm);
+
+      /* next */
+      mb += 4;
+      n_left -= 4;
+    }
+
+  while (n_left)
+    {
+      b[0] = vlib_buffer_from_rte_mbuf (mb[0]);
+      vlib_buffer_copy_template (b[0], &bt);
+      or_flags |= dpdk_ol_flags_extract (mb, flags, 1);
+      flags += 1;
+
+      b[0]->current_data = mb[0]->data_off - RTE_PKTMBUF_HEADROOM;
+      n_bytes += b[0]->current_length = mb[0]->data_len;
+
+      if (maybe_multiseg)
+	n_bytes += dpdk_process_subseq_segs (vm, b[0], mb[0], &bt);
+      VLIB_BUFFER_TRACE_TRAJECTORY_INIT (b[0]);
+
+      dpdk_insert_tx_ring_stats (b[0], dm);
+
+      /* next */
+      mb += 1;
+      n_left -= 1;
+    }
+
+  *or_flagsp = or_flags;
+  return n_bytes;
+}
+
+static_always_inline void
+dpdk_process_flow_offload (dpdk_device_t * xd, dpdk_per_thread_data_t * ptd,
+			   uword n_rx_packets)
+{
+  uword n;
+  dpdk_flow_lookup_entry_t *fle;
+  vlib_buffer_t *b0;
+
+  /* TODO prefetch and quad-loop */
+  for (n = 0; n < n_rx_packets; n++)
+    {
+      if ((ptd->flags[n] & PKT_RX_FDIR_ID) == 0)
+	continue;
+
+      fle = pool_elt_at_index (xd->flow_lookup_entries,
+			       ptd->mbufs[n]->hash.fdir.hi);
+
+      if (fle->next_index != (u16) ~ 0)
+	ptd->next[n] = fle->next_index;
+
+      if (fle->flow_id != ~0)
+	{
+	  b0 = vlib_buffer_from_rte_mbuf (ptd->mbufs[n]);
+	  b0->flow_id = fle->flow_id;
+	}
+
+      if (fle->buffer_advance != ~0)
+	{
+	  b0 = vlib_buffer_from_rte_mbuf (ptd->mbufs[n]);
+	  vlib_buffer_advance (b0, fle->buffer_advance);
+	}
+    }
+}
+
+static_always_inline u32
+dpdk_device_input (vlib_main_t * vm, dpdk_main_t * dm, dpdk_device_t * xd,
+		   vlib_node_runtime_t * node, u32 thread_index, u16 queue_id)
+{
+  uword n_rx_packets = 0, n_rx_bytes;
+  dpdk_rx_queue_t *rxq = vec_elt_at_index (xd->rx_queues, queue_id);
+  u32 n_left, n_trace;
+  u32 *buffers;
+  u32 next_index = VNET_DEVICE_INPUT_NEXT_ETHERNET_INPUT;
+  struct rte_mbuf **mb;
+  vlib_buffer_t *b0;
+  u16 *next;
+  u16 or_flags;
+  u32 n;
+  int single_next = 0;
+
+  dpdk_per_thread_data_t *ptd = vec_elt_at_index (dm->per_thread_data,
+						  thread_index);
+  vlib_buffer_t *bt = &ptd->buffer_template;
+
+  if ((xd->flags & DPDK_DEVICE_FLAG_ADMIN_UP) == 0)
+    return 0;
+
+  /* get up to DPDK_RX_BURST_SZ buffers from PMD */
+  while (n_rx_packets < DPDK_RX_BURST_SZ)
+    {
+      n = rte_eth_rx_burst (xd->port_id, queue_id,
+			    ptd->mbufs + n_rx_packets,
+			    DPDK_RX_BURST_SZ - n_rx_packets);
+      n_rx_packets += n;
+
+      if (n < 32)
+	break;
+    }
+
+  if (n_rx_packets == 0)
+    return 0;
+
+  /* Update buffer template */
+  vnet_buffer (bt)->sw_if_index[VLIB_RX] = xd->sw_if_index;
+  bt->error = node->errors[DPDK_ERROR_NONE];
+  /* as DPDK is allocating empty buffers from mempool provided before interface
+     start for each queue, it is safe to store this in the template */
+  bt->buffer_pool_index = rxq->buffer_pool_index;
+  bt->ref_count = 1;
+  vnet_buffer (bt)->feature_arc_index = 0;
+  bt->current_config_index = 0;
+
+  /* receive burst of packets from DPDK PMD */
+  if (PREDICT_FALSE (xd->per_interface_next_index != ~0))
+    next_index = xd->per_interface_next_index;
+
+  /* as all packets belong to the same interface feature arc lookup
+     can be don once and result stored in the buffer template */
+  if (PREDICT_FALSE (vnet_device_input_have_features (xd->sw_if_index)))
+    vnet_feature_start_device_input_x1 (xd->sw_if_index, &next_index, bt);
+
+  if (xd->flags & DPDK_DEVICE_FLAG_MAYBE_MULTISEG)
+    n_rx_bytes = dpdk_process_rx_burst (vm, ptd, n_rx_packets, 1, &or_flags);
+  else
+    n_rx_bytes = dpdk_process_rx_burst (vm, ptd, n_rx_packets, 0, &or_flags);
+
+  if (PREDICT_FALSE (or_flags & PKT_RX_FDIR))
+    {
+      /* some packets will need to go to different next nodes */
+      for (n = 0; n < n_rx_packets; n++)
+	ptd->next[n] = next_index;
+
+      /* flow offload - process if rx flow offload enabled and at least one
+         packet is marked */
+      if (PREDICT_FALSE ((xd->flags & DPDK_DEVICE_FLAG_RX_FLOW_OFFLOAD) &&
+			 (or_flags & PKT_RX_FDIR)))
+	dpdk_process_flow_offload (xd, ptd, n_rx_packets);
+
+      /* enqueue buffers to the next node */
+      vlib_get_buffer_indices_with_offset (vm, (void **) ptd->mbufs,
+					   ptd->buffers, n_rx_packets,
+					   sizeof (struct rte_mbuf));
+
+      vlib_buffer_enqueue_to_next (vm, node, ptd->buffers, ptd->next,
+				   n_rx_packets);
+    }
+  else
+    {
+      u32 *to_next, n_left_to_next;
+
+      vlib_get_new_next_frame (vm, node, next_index, to_next, n_left_to_next);
+      vlib_get_buffer_indices_with_offset (vm, (void **) ptd->mbufs, to_next,
+					   n_rx_packets,
+					   sizeof (struct rte_mbuf));
+
+      if (PREDICT_TRUE (next_index == VNET_DEVICE_INPUT_NEXT_ETHERNET_INPUT))
+	{
+	  vlib_next_frame_t *nf;
+	  vlib_frame_t *f;
+	  ethernet_input_frame_t *ef;
+	  nf = vlib_node_runtime_get_next_frame (vm, node, next_index);
+	  f = vlib_get_frame (vm, nf->frame);
+	  f->flags = ETH_INPUT_FRAME_F_SINGLE_SW_IF_IDX;
+
+	  ef = vlib_frame_scalar_args (f);
+	  ef->sw_if_index = xd->sw_if_index;
+	  ef->hw_if_index = xd->hw_if_index;
+
+	  /* if PMD supports ip4 checksum check and there are no packets
+	     marked as ip4 checksum bad we can notify ethernet input so it
+	     can send pacets to ip4-input-no-checksum node */
+	  if (xd->flags & DPDK_DEVICE_FLAG_RX_IP4_CKSUM &&
+	      (or_flags & PKT_RX_IP_CKSUM_BAD) == 0)
+	    f->flags |= ETH_INPUT_FRAME_F_IP4_CKSUM_OK;
+	  vlib_frame_no_append (f);
+	}
+      n_left_to_next -= n_rx_packets;
+      vlib_put_next_frame (vm, node, next_index, n_left_to_next);
+      single_next = 1;
+    }
+
+  /* packet trace if enabled */
+  if (PREDICT_FALSE ((n_trace = vlib_get_trace_count (vm, node))))
+    {
+      if (single_next)
+	vlib_get_buffer_indices_with_offset (vm, (void **) ptd->mbufs,
+					     ptd->buffers, n_rx_packets,
+					     sizeof (struct rte_mbuf));
+
+      n_left = n_rx_packets;
+      buffers = ptd->buffers;
+      mb = ptd->mbufs;
+      next = ptd->next;
+
+      while (n_trace && n_left)
+	{
+	  b0 = vlib_get_buffer (vm, buffers[0]);
+	  if (single_next == 0)
+	    next_index = next[0];
+
+	  if (PREDICT_TRUE
+	      (vlib_trace_buffer
+	       (vm, node, next_index, b0, /* follow_chain */ 0)))
+	    {
+
+	      dpdk_rx_trace_t *t0 =
+		vlib_add_trace (vm, node, b0, sizeof t0[0]);
+	      t0->queue_index = queue_id;
+	      t0->device_index = xd->device_index;
+	      t0->buffer_index = vlib_get_buffer_index (vm, b0);
+
+	      clib_memcpy_fast (&t0->mb, mb[0], sizeof t0->mb);
+	      clib_memcpy_fast (&t0->buffer, b0,
+				sizeof b0[0] - sizeof b0->pre_data);
+	      clib_memcpy_fast (t0->buffer.pre_data, b0->data,
+				sizeof t0->buffer.pre_data);
+	      clib_memcpy_fast (&t0->data, mb[0]->buf_addr + mb[0]->data_off,
+				sizeof t0->data);
+	      n_trace--;
+	    }
+
+	  n_left--;
+	  buffers++;
+	  mb++;
+	  next++;
+	}
+      vlib_set_trace_count (vm, node, n_trace);
+    }
+
+  vlib_increment_combined_counter
+    (vnet_get_main ()->interface_main.combined_sw_if_counters
+     + VNET_INTERFACE_COUNTER_RX, thread_index, xd->sw_if_index,
+     n_rx_packets, n_rx_bytes);
+
+  vnet_device_increment_rx_packets (thread_index, n_rx_packets);
+
+  return n_rx_packets;
+}
+
+VLIB_NODE_FN (dpdk_input_node) (vlib_main_t * vm, vlib_node_runtime_t * node,
+				vlib_frame_t * f)
+{
+  dpdk_main_t *dm = &dpdk_main;
+  dpdk_device_t *xd;
+  uword n_rx_packets = 0;
+  vnet_hw_if_rxq_poll_vector_t *pv;
+  u32 thread_index = node->thread_index;
+
+  /*
+   * Poll all devices on this cpu for input/interrupts.
+   */
+
+  pv = vnet_hw_if_get_rxq_poll_vector (vm, node);
+
+  for (int i = 0; i < vec_len (pv); i++)
+    {
+      xd = vec_elt_at_index (dm->devices, pv[i].dev_instance);
+      n_rx_packets +=
+	dpdk_device_input (vm, dm, xd, node, thread_index, pv[i].queue_id);
+    }
+  return n_rx_packets;
+}
+
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (dpdk_input_node) = {
+  .type = VLIB_NODE_TYPE_INPUT,
+  .name = "dpdk-input",
+  .sibling_of = "device-input",
+  .flags = VLIB_NODE_FLAG_TRACE_SUPPORTED,
+
+  /* Will be enabled if/when hardware is detected. */
+  .state = VLIB_NODE_STATE_DISABLED,
+
+  .format_buffer = format_ethernet_header_with_length,
+  .format_trace = format_dpdk_rx_trace,
+
+  .n_errors = DPDK_N_ERROR,
+  .error_strings = dpdk_error_strings,
+};
+/* *INDENT-ON* */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ioam/analyse/ioam_analyse.h b/src/plugins/ioam/analyse/ioam_analyse.h
index 2a2cc1582..639d8df94 100644
--- a/src/plugins/ioam/analyse/ioam_analyse.h
+++ b/src/plugins/ioam/analyse/ioam_analyse.h
@@ -45,7 +45,7 @@ typedef struct
   u8 num_nodes;
 
   /** Data contained in trace - NodeId, TTL, Ingress & Egress Link, Timestamp. */
-  u8 trace_type;
+  u32 trace_type;
 
   /** Flag to indicate whether node is allocated. */
   u8 is_free;
@@ -138,46 +138,46 @@ ip6_ioam_analyse_calc_delay (ioam_trace_hdr_t * trace, u16 trace_len,
   u32 start_time, end_time;
   u8 done = 0;
 
-  size_of_traceopt_per_node = fetch_trace_data_size (trace->ioam_trace_type);
+  size_of_traceopt_per_node = fetch_trace_data_size (trace_profile_find ());
   // Unknown trace type
   if (size_of_traceopt_per_node == 0)
     return 0;
-  size_of_all_traceopts = trace_len;	/*ioam_trace_type,data_list_elts_left */
+  size_of_all_traceopts = trace_len;	/*ioam_trace_type,node_len_flags_remaining_len */
 
   num_nodes = (u8) (size_of_all_traceopts / size_of_traceopt_per_node);
-  if ((num_nodes == 0) || (num_nodes <= trace->data_list_elts_left))
+  if ((num_nodes == 0) || (num_nodes <= (trace->node_len_flags_remaining_len & IOAM_REMAIN_LEN_MASK)))
     return 0;
 
-  num_nodes -= trace->data_list_elts_left;
+  num_nodes -= (trace->node_len_flags_remaining_len & IOAM_REMAIN_LEN_MASK);
 
-  start_elt = trace->elts;
+  start_elt = trace->data_list;
   end_elt =
-    trace->elts +
+    trace->data_list +
     (u32) ((size_of_traceopt_per_node / sizeof (u32)) * (num_nodes - 1));
 
-  if (oneway && (trace->ioam_trace_type & BIT_TTL_NODEID))
+  if ((oneway && (trace->trace_type & IOAM_BIT_TTL_NODEID_SHORT)) || (oneway && (trace->trace_type & IOAM_BIT_TTL_NODEID_WIDE)))
+  {
+    done = 0;
+    do
     {
-      done = 0;
-      do
-	{
-	  uturn_elt = start_elt - size_of_traceopt_per_node / sizeof (u32);
-
-	  if ((clib_net_to_host_u32 (*start_elt) >> 24) <=
-	      (clib_net_to_host_u32 (*uturn_elt) >> 24))
-	    done = 1;
-	}
-      while (!done && (start_elt = uturn_elt) != end_elt);
-    }
-  if (trace->ioam_trace_type & BIT_TTL_NODEID)
-    {
-      start_elt++;
-      end_elt++;
-    }
-  if (trace->ioam_trace_type & BIT_ING_INTERFACE)
-    {
-      start_elt++;
-      end_elt++;
+      uturn_elt = start_elt - size_of_traceopt_per_node / sizeof (u32);
+
+      if ((clib_net_to_host_u32 (*start_elt) >> 24) <=
+          (clib_net_to_host_u32 (*uturn_elt) >> 24))
+        done = 1;
     }
+    while (!done && (start_elt = uturn_elt) != end_elt);
+  }
+  if (trace->trace_type & IOAM_BIT_TTL_NODEID_SHORT)
+  {
+    start_elt++;
+    end_elt++;
+  }
+  if (trace->trace_type & IOAM_BIT_TTL_NODEID_WIDE)
+  {
+    start_elt++;
+    end_elt++;
+  }
   start_time = clib_net_to_host_u32 (*start_elt);
   end_time = clib_net_to_host_u32 (*end_elt);
 
@@ -197,17 +197,17 @@ ip6_ioam_analyse_set_paths_down (ioam_analyser_data_t * data)
   trace_data = &data->trace_data;
 
   for (i = 0; i < IOAM_MAX_PATHS_PER_FLOW; i++)
-    {
-      trace_record = trace_data->path_data + i;
+  {
+    trace_record = trace_data->path_data + i;
 
-      if (trace_record->is_free)
-	continue;
+    if (trace_record->is_free)
+      continue;
 
-      path = trace_record->path;
+    path = trace_record->path;
 
-      for (k = 0; k < trace_record->num_nodes; k++)
-	path[k].state_up = 0;
-    }
+    for (k = 0; k < trace_record->num_nodes; k++)
+      path[k].state_up = 0;
+  }
   clib_spinlock_unlock (&data->writer_lock);
 }
 
@@ -228,55 +228,49 @@ ip6_ioam_analyse_hbh_trace_loopback (ioam_analyser_data_t * data,
   clib_spinlock_lock (&data->writer_lock);
 
   trace_data = &data->trace_data;
-
-  size_of_traceopt_per_node = fetch_trace_data_size (trace->ioam_trace_type);
+  size_of_traceopt_per_node = fetch_trace_data_size (trace_profile_find ());
   if (0 == size_of_traceopt_per_node)
     goto end;
 
   size_of_all_traceopts = trace_len;
 
-  ptr = (u8 *) trace->elts;
+  ptr = (u8 *) trace->data_list;
   max_nodes = (u8) (size_of_all_traceopts / size_of_traceopt_per_node);
-  num_nodes = max_nodes - trace->data_list_elts_left;
+  num_nodes = max_nodes - (trace->node_len_flags_remaining_len & IOAM_REMAIN_LEN_MASK);
 
   for (i = 0; i < IOAM_MAX_PATHS_PER_FLOW; i++)
-    {
-      trace_record = trace_data->path_data + i;
-      path = trace_record->path;
+  {
+    trace_record = trace_data->path_data + i;
+    path = trace_record->path;
 
-      if (trace_record->is_free)
-	continue;
+    if (trace_record->is_free)
+	  continue;
 
-      for (j = max_nodes, k = 0; k < num_nodes; j--, k++)
-	{
-	  ptr =
-	    (u8 *) ((u8 *) trace->elts +
-		    (size_of_traceopt_per_node * (j - 1)));
+    for (j = max_nodes, k = 0; k < num_nodes; j--, k++)
+	  {
+	    ptr = (u8 *) ((u8 *) trace->data_list + (size_of_traceopt_per_node * (j - 1)));
+	    nodeid = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
+	    ptr += 4;
 
-	  nodeid = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
-	  ptr += 4;
+      if (nodeid != path[k].node_id)
+        goto end;
 
-	  if (nodeid != path[k].node_id)
-	    goto end;
-
-	  if ((trace->ioam_trace_type == TRACE_TYPE_IF_TS_APP) ||
-	      (trace->ioam_trace_type == TRACE_TYPE_IF))
+	    if (trace->trace_type == IOAM_BIT_ING_EGR_INT_SHORT)
 	    {
 	      ingress_if = clib_net_to_host_u16 (*((u16 *) ptr));
 	      ptr += 2;
 	      egress_if = clib_net_to_host_u16 (*((u16 *) ptr));
-	      if ((ingress_if != path[k].ingress_if) ||
-		  (egress_if != path[k].egress_if))
-		{
-		  goto end;
-		}
+	      if ((ingress_if != path[k].ingress_if) || (egress_if != path[k].egress_if))
+        {
+          goto end;
+        }
 	    }
-	  /* Found Match - set path hop state to up */
-	  path[k].state_up = 1;
-	}
-    }
-end:
-  clib_spinlock_unlock (&data->writer_lock);
+      /* Found Match - set path hop state to up */
+      path[k].state_up = 1;
+	  }
+  }
+  end:
+    clib_spinlock_unlock (&data->writer_lock);
 }
 
 always_inline int
@@ -298,117 +292,108 @@ ip6_ioam_analyse_hbh_trace (ioam_analyser_data_t * data,
 
   trace_data = &data->trace_data;
 
-  size_of_traceopt_per_node = fetch_trace_data_size (trace->ioam_trace_type);
+  size_of_traceopt_per_node = fetch_trace_data_size (trace_profile_find ());
   // Unknown trace type
   if (size_of_traceopt_per_node == 0)
     goto DONE;
   size_of_all_traceopts = trace_len;
 
-  ptr = (u8 *) trace->elts;
+  ptr = (u8 *) trace->data_list;
   max_nodes = (u8) (size_of_all_traceopts / size_of_traceopt_per_node);
-  num_nodes = max_nodes - trace->data_list_elts_left;
+  num_nodes = max_nodes - (trace->node_len_flags_remaining_len & IOAM_REMAIN_LEN_MASK);
 
   for (i = 0; i < IOAM_MAX_PATHS_PER_FLOW; i++)
-    {
-      trace_record = trace_data->path_data + i;
+  {
+    trace_record = trace_data->path_data + i;
 
-      if (trace_record->is_free ||
-	  (num_nodes != trace_record->num_nodes) ||
-	  (trace->ioam_trace_type != trace_record->trace_type))
-	continue;
+    if (trace_record->is_free || (num_nodes != trace_record->num_nodes) || (trace->trace_type != trace_record->trace_type))
+	    continue;
 
-      path = trace_record->path;
+    path = trace_record->path;
 
-      for (j = max_nodes, k = 0; k < num_nodes; j--, k++)
-	{
-	  ptr =
-	    (u8 *) ((u8 *) trace->elts +
-		    (size_of_traceopt_per_node * (j - 1)));
+    for (j = max_nodes, k = 0; k < num_nodes; j--, k++)
+	  {
+	    ptr = (u8 *) ((u8 *) trace->data_list + (size_of_traceopt_per_node * (j - 1)));
 
-	  nodeid = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
-	  ptr += 4;
+	    nodeid = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
+	    ptr += 4;
 
-	  if (nodeid != path[k].node_id)
-	    break;
+      if (nodeid != path[k].node_id)
+        break;
 
-	  if ((trace->ioam_trace_type == TRACE_TYPE_IF_TS_APP) ||
-	      (trace->ioam_trace_type == TRACE_TYPE_IF))
-	    {
-	      ingress_if = clib_net_to_host_u16 (*((u16 *) ptr));
-	      ptr += 2;
-	      egress_if = clib_net_to_host_u16 (*((u16 *) ptr));
-	      if ((ingress_if != path[k].ingress_if) ||
-		  (egress_if != path[k].egress_if))
-		{
-		  break;
-		}
-	    }
-	}
+      if(trace->trace_type == IOAM_BIT_ING_EGR_INT_SHORT)
+      {
+        ingress_if = clib_net_to_host_u16 (*((u16 *) ptr));
+        ptr += 2;
+        egress_if = clib_net_to_host_u16 (*((u16 *) ptr));
+        if ((ingress_if != path[k].ingress_if) || (egress_if != path[k].egress_if))
+        {
+          break;
+        }
+      }
+	  }
 
-      if (k == num_nodes)
-	{
-	  goto found_match;
-	}
+    if (k == num_nodes)
+    {
+      goto found_match;
     }
+  }
 
   for (i = 0; i < IOAM_MAX_PATHS_PER_FLOW; i++)
+  {
+    trace_record = trace_data->path_data + i;
+    if (trace_record->is_free)
     {
-      trace_record = trace_data->path_data + i;
-      if (trace_record->is_free)
-	{
-	  trace_record->is_free = 0;
-	  trace_record->num_nodes = num_nodes;
-	  trace_record->trace_type = trace->ioam_trace_type;
-	  path = trace_data->path_data[i].path;
-	  trace_record->pkt_counter = 0;
-	  trace_record->bytes_counter = 0;
-	  trace_record->min_delay = 0xFFFFFFFF;
-	  trace_record->max_delay = 0;
-	  trace_record->mean_delay = 0;
-	  break;
-	}
+      trace_record->is_free = 0;
+      trace_record->num_nodes = num_nodes;
+      trace_record->trace_type = trace->trace_type;
+      path = trace_data->path_data[i].path;
+      trace_record->pkt_counter = 0;
+      trace_record->bytes_counter = 0;
+      trace_record->min_delay = 0xFFFFFFFF;
+      trace_record->max_delay = 0;
+      trace_record->mean_delay = 0;
+      break;
     }
+  }
 
   for (j = max_nodes, k = 0; k < num_nodes; j--, k++)
+  {
+    ptr = (u8 *) ((u8 *) trace->data_list + (size_of_traceopt_per_node * (j - 1)));
+
+    path[k].node_id = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
+    ptr += 4;
+
+    if(trace->trace_type == IOAM_BIT_ING_EGR_INT_SHORT)
     {
-      ptr =
-	(u8 *) ((u8 *) trace->elts + (size_of_traceopt_per_node * (j - 1)));
-
-      path[k].node_id = clib_net_to_host_u32 (*((u32 *) ptr)) & 0x00ffffff;
-      ptr += 4;
-
-      if ((trace->ioam_trace_type == TRACE_TYPE_IF_TS_APP) ||
-	  (trace->ioam_trace_type == TRACE_TYPE_IF))
-	{
-	  path[k].ingress_if = clib_net_to_host_u16 (*((u16 *) ptr));
-	  ptr += 2;
-	  path[k].egress_if = clib_net_to_host_u16 (*((u16 *) ptr));
-	}
+      path[k].ingress_if = clib_net_to_host_u16 (*((u16 *) ptr));
+      ptr += 2;
+      path[k].egress_if = clib_net_to_host_u16 (*((u16 *) ptr));
     }
+  }
 
-found_match:
-  /* Set path state to UP */
-  for (k = 0; k < num_nodes; k++)
-    path[k].state_up = 1;
+  found_match:
+    /* Set path state to UP */
+    for (k = 0; k < num_nodes; k++)
+      path[k].state_up = 1;
 
-  trace_record->pkt_counter++;
-  trace_record->bytes_counter += pak_len;
-  if (trace->ioam_trace_type & BIT_TIMESTAMP)
+    trace_record->pkt_counter++;
+    trace_record->bytes_counter += pak_len;
+    if (trace->trace_type & IOAM_BIT_TIMESTAMP_SEC)
     {
       /* Calculate time delay */
       u32 delay = (u32) ip6_ioam_analyse_calc_delay (trace, trace_len, 0);
       if (delay < trace_record->min_delay)
-	trace_record->min_delay = delay;
+        trace_record->min_delay = delay;
       else if (delay > trace_record->max_delay)
-	trace_record->max_delay = delay;
+        trace_record->max_delay = delay;
 
       u64 sum = (trace_record->mean_delay * data->seqno_data.rx_packets);
-      trace_record->mean_delay =
-	(u32) ((sum + delay) / (data->seqno_data.rx_packets + 1));
+      trace_record->mean_delay = (u32) ((sum + delay) / (data->seqno_data.rx_packets + 1));
     }
-DONE:
-  clib_spinlock_unlock (&data->writer_lock);
-  return 0;
+  DONE:
+    clib_spinlock_unlock (&data->writer_lock);
+    return 0;
 }
 
 always_inline int
@@ -433,14 +418,12 @@ format_path_map (u8 * s, va_list * args)
   u32 i;
 
   for (i = 0; i < num_of_elts; i++)
-    {
-      s =
-	format (s,
-		"node_id: 0x%x, ingress_if: 0x%x, egress_if:0x%x, state:%s\n",
-		pm->node_id, pm->ingress_if, pm->egress_if,
-		pm->state_up ? "UP" : "DOWN");
-      pm++;
-    }
+  {
+    s = format (s, "node_id: 0x%x, ingress_if: 0x%x, egress_if:0x%x, state:%s\n",
+                pm->node_id, pm->ingress_if, pm->egress_if,
+                pm->state_up ? "UP" : "DOWN");
+    pm++;
+  }
 
   return (s);
 }
@@ -458,20 +441,20 @@ print_analyse_flow (u8 * s, ioam_analyser_data_t * record)
   s = format (s, "Trace data: \n");
 
   for (j = 0; j < IOAM_MAX_PATHS_PER_FLOW; j++)
-    {
-      trace_record = record->trace_data.path_data + j;
-      if (trace_record->is_free)
-	continue;
-
-      s = format (s, "path_map:\n%U", format_path_map,
-		  trace_record->path, trace_record->num_nodes);
-      s = format (s, "pkt_counter: %u\n", trace_record->pkt_counter);
-      s = format (s, "bytes_counter: %u\n", trace_record->bytes_counter);
-
-      s = format (s, "min_delay: %u\n", trace_record->min_delay);
-      s = format (s, "max_delay: %u\n", trace_record->max_delay);
-      s = format (s, "mean_delay: %u\n", trace_record->mean_delay);
-    }
+  {
+    trace_record = record->trace_data.path_data + j;
+    if (trace_record->is_free)
+      continue;
+
+    s = format (s, "path_map:\n%U", format_path_map,
+    trace_record->path, trace_record->num_nodes);
+    s = format (s, "pkt_counter: %u\n", trace_record->pkt_counter);
+    s = format (s, "bytes_counter: %u\n", trace_record->bytes_counter);
+
+    s = format (s, "min_delay: %u\n", trace_record->min_delay);
+    s = format (s, "max_delay: %u\n", trace_record->max_delay);
+    s = format (s, "mean_delay: %u\n", trace_record->mean_delay);
+  }
 
   s = format (s, "\nPOT data: \n");
   s = format (s, "sfc_validated_count : %u\n",
diff --git a/src/plugins/ioam/encap/ip6_ioam_trace.c b/src/plugins/ioam/encap/ip6_ioam_trace.c
index ea4966104..f7a0aad0e 100644
--- a/src/plugins/ioam/encap/ip6_ioam_trace.c
+++ b/src/plugins/ioam/encap/ip6_ioam_trace.c
@@ -14,6 +14,7 @@
  */
 #include <vlib/vlib.h>
 #include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
 #include <vppinfra/error.h>
 #include <vpp/app/version.h>
 
@@ -33,10 +34,15 @@
 #include <ioam/udp-ping/udp_ping_packet.h>
 #include <ioam/udp-ping/udp_ping_util.h>
 
+// For transit delay
+#include <timestamp/timestamp.h>
+// For queue depth
+#include <linux/if_packet.h>
+#include <vnet/devices/af_packet/af_packet.h>
 /* Timestamp precision multipliers for seconds, milliseconds, microseconds
  * and nanoseconds respectively.
  */
-static f64 trace_tsp_mul[4] = { 1, 1e3, 1e6, 1e9 };
+static f64 trace_tsp_mul[IOAM_TSP_OPTION_SIZE] = { 1, 1e3, 1e6, 1e9 };
 
 typedef union
 {
@@ -86,61 +92,128 @@ always_inline void
 ip6_ioam_trace_stats_increment_counter (u32 counter_index, u64 increment)
 {
   ip6_hop_by_hop_ioam_trace_main_t *hm = &ip6_hop_by_hop_ioam_trace_main;
-
+  
   hm->counters[counter_index] += increment;
 }
-
-
 static u8 *
 format_ioam_data_list_element (u8 * s, va_list * args)
 {
   u32 *elt = va_arg (*args, u32 *);
-  u8 *trace_type_p = va_arg (*args, u8 *);
-  u8 trace_type = *trace_type_p;
-
-
-  if (trace_type & BIT_TTL_NODEID)
-    {
-      u32 ttl_node_id_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ttl 0x%x node id 0x%x ",
-		  ttl_node_id_host_byte_order >> 24,
-		  ttl_node_id_host_byte_order & 0x00FFFFFF);
-
-      elt++;
-    }
-
-  if (trace_type & BIT_ING_INTERFACE && trace_type & BIT_ING_INTERFACE)
-    {
-      u32 ingress_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ingress 0x%x egress 0x%x ",
-		  ingress_host_byte_order >> 16,
-		  ingress_host_byte_order & 0xFFFF);
-      elt++;
-    }
-
-  if (trace_type & BIT_TIMESTAMP)
-    {
-      u32 ts_in_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ts 0x%x \n", ts_in_host_byte_order);
-      elt++;
-    }
-
-  if (trace_type & BIT_APPDATA)
-    {
-      u32 appdata_in_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "app 0x%x ", appdata_in_host_byte_order);
-      elt++;
-    }
-
+  u32 *trace_type_p = va_arg (*args, u32 *);
+  u32 trace_type = *trace_type_p;
+
+  if (trace_type & IOAM_BIT_TTL_NODEID_SHORT)
+  {
+    u32 ttl_node_id_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", ttl: 0x%x, node id short: 0x%x",
+    ttl_node_id_host_byte_order >> 24,
+    ttl_node_id_host_byte_order & IOAM_EMPTY_FIELD_U24);
+
+    elt++;
+  }
+  if (trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
+  {
+    u32 ingress_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", ingress sw: %d, egress sw: %d",
+    ingress_host_byte_order >> 16,
+    ingress_host_byte_order & IOAM_EMPTY_FIELD_U16);
+    elt++;
+  }
+  if (trace_type & IOAM_BIT_TIMESTAMP_SEC)
+  {
+    u32 ts_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", timestamp (s): 0x%x", ts_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_TIMESTAMP_SUB_SEC)
+  {
+    u32 ts_sub_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", timestamp (sub-sec): 0x%x", ts_sub_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_TRANSIT_DELAY)
+  {
+    u32 transit_delay_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", transit delay (ns): 0x%x", transit_delay_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
+  {
+    u32 appdata_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", appdata: 0x%x", appdata_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_QUEUE_DEPTH)
+  {
+    u32 queue_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", queue depth: 0x%x", queue_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_CHECKSUM_COMPLEMENT)
+  {
+    u32 cc_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", checksum complement: 0x%x", cc_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_TTL_NODEID_WIDE)
+  {
+    u64 *ttl_node_id_p = (u64 *)elt;
+    u64 ttl_node_id = clib_net_to_host_u64 (*ttl_node_id_p);
+    elt += 2;
+
+    s = format (s, ", ttl: 0x%x, node id wide: 0x%Lx",
+                ttl_node_id >> 56, 
+                (ttl_node_id & IOAM_EMPTY_FIELD_U56));
+
+  }
+
+  if (trace_type & IOAM_BIT_ING_EGR_INT_WIDE)
+  {
+    u32 ingress_wide_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", ingress hw: %d", ingress_wide_host_byte_order);
+    elt++;
+
+    u32 egress_wide_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", egress hw: %d", egress_wide_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_APPDATA_WIDE_DATA)
+  {
+    u64 *app_data_wide_host_byte_order_p = (u64 *)elt;
+    u64 app_data_wide_host_byte_order = clib_net_to_host_u64 (*app_data_wide_host_byte_order_p);
+    s = format (s, ", appdata wide: 0x%x", app_data_wide_host_byte_order);
+    elt += 2;
+  }
+
+  if (trace_type & IOAM_BIT_BUFFER_OCCUPANCY)
+  {
+    u32 buffer_occ_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", buffers available: %d", buffer_occ_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH)
+  {
+    u32 opaque_len_id_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, ", opaque len: %d , opaque id: 0x%x", \
+    IOAM_GET_OPAQUE_LEN(opaque_len_id_host_byte_order), IOAM_OPAQUE_SCHEMEID_MASK & opaque_len_id_host_byte_order);
+    elt++;
+  }
   return s;
 }
 
-
 int
 ip6_ioam_trace_get_sizeof_handler (u32 * result)
 {
-  u16 size = 0;
-  u8 trace_data_size = 0;
+  u32 size = 0;
+  u32 trace_data_size = 0;
   trace_profile *profile = NULL;
 
   *result = 0;
@@ -148,67 +221,73 @@ ip6_ioam_trace_get_sizeof_handler (u32 * result)
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
-      return (-1);
-    }
+  {
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
+    return (-1);
+  }
 
-  trace_data_size = fetch_trace_data_size (profile->trace_type);
+  trace_data_size = fetch_trace_data_size (profile);
   if (PREDICT_FALSE (trace_data_size == 0))
-    return VNET_API_ERROR_INVALID_VALUE;
+  { 
+    return VNET_API_ERROR_INVALID_VALUE; 
+  }
 
   if (PREDICT_FALSE (profile->num_elts * trace_data_size > 254))
+  {
     return VNET_API_ERROR_INVALID_VALUE;
-
-  size +=
-    sizeof (ioam_trace_option_t) + (profile->num_elts * trace_data_size);
+  }
+  size += sizeof (ioam_trace_option_t) + (profile->num_elts * trace_data_size);
   *result = size;
 
   return 0;
 }
 
-
-
 int
-ip6_hop_by_hop_ioam_trace_rewrite_handler (u8 * rewrite_string,
-					   u8 * rewrite_size)
+ip6_hop_by_hop_ioam_trace_rewrite_handler (u8 * rewrite_string, u8 * rewrite_size)
 {
   ioam_trace_option_t *trace_option = NULL;
-  u8 trace_data_size = 0;
+  u32 trace_data_size = 0;
   u8 trace_option_elts = 0;
   trace_profile *profile = NULL;
 
-
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
-      return (-1);
-    }
+  {
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
+    return (-1);
+  }
 
   if (PREDICT_FALSE (!rewrite_string))
+  {
     return -1;
+  }
 
   trace_option_elts = profile->num_elts;
-  trace_data_size = fetch_trace_data_size (profile->trace_type);
+  trace_data_size = fetch_trace_data_size (profile);
   trace_option = (ioam_trace_option_t *) rewrite_string;
-  trace_option->hdr.type = HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST |
-    HBH_OPTION_TYPE_DATA_CHANGE_ENROUTE;
-  trace_option->hdr.length = 2 /*ioam_trace_type,data_list_elts_left */  +
-    trace_option_elts * trace_data_size;
-  trace_option->trace_hdr.ioam_trace_type =
-    profile->trace_type & TRACE_TYPE_MASK;
-  trace_option->trace_hdr.data_list_elts_left = trace_option_elts;
-  *rewrite_size =
-    sizeof (ioam_trace_option_t) + (trace_option_elts * trace_data_size);
 
+  trace_option->hdr.type = HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST | HBH_OPTION_TYPE_DATA_CHANGE_ENROUTE;
+  // LENGTH
+  trace_option->hdr.length = sizeof(ioam_trace_hdr_t) + (trace_option_elts * trace_data_size) + 2; /* ip6_hop_by_hop_option_t: reserved and ioam_type */
+  trace_option->hdr.ioam_type = profile->option_type;
+  // ioam_trace_hdr_t things
+  trace_option->trace_hdr.namespace_id = clib_host_to_net_u16(profile->namespace_id);
+  u16 node_len = trace_data_size >> 2; // In 4-octets
+  if(IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid))
+  {
+    node_len += IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid); // Should already be in 4 octets
+  }
+  u16 nlfrl = IOAM_SET_NODE_LEN(node_len);
+  nlfrl |= (IOAM_REMAIN_LEN_MASK & trace_option_elts);
+  trace_option->trace_hdr.node_len_flags_remaining_len = clib_host_to_net_u16(nlfrl);
+  trace_option->trace_hdr.trace_type = IOAM_SET_TRACETYPE(profile->trace_type);
+  // LENGTH
+  *rewrite_size = sizeof (ioam_trace_option_t) + (trace_option_elts * trace_data_size);
   return 0;
 }
-
 always_inline void
-ip6_hbh_ioam_loopback_handler (vlib_buffer_t * b, ip6_header_t * ip,
-			       ioam_trace_option_t * trace)
+ip6_hbh_ioam_loopback_handler (vlib_buffer_t * b, ip6_header_t * ip, ioam_trace_option_t * trace)
 {
   u32 buf_index;
   ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
@@ -236,12 +315,11 @@ ip6_hbh_ioam_loopback_handler (vlib_buffer_t * b, ip6_header_t * ip,
 
   ip6 = vlib_buffer_get_current (b0);
   hbh = (ip6_hop_by_hop_header_t *) (ip6 + 1);
-  opt = (ioam_trace_option_t *)
-    ip6_hbh_get_option (hbh, HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST);
+  opt = (ioam_trace_option_t *)ip6_hbh_get_option (hbh, HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST);
 
   udp = (udp_ping_t *) ((u8 *) hbh + ((hbh->length + 1) << 3));
   udp_ping_create_reply_from_probe_ip6 (ip6, hbh, udp);
-  ip6_hbh_ioam_trace_set_bit (opt, BIT_LOOPBACK_REPLY);
+  ip6_hbh_ioam_trace_set_flag_bit (opt, IOAM_BIT_FLAG_LOOPBACK_REPLY);
 
   *to_next = buf_index;
   nf->n_vectors++;
@@ -250,105 +328,268 @@ ip6_hbh_ioam_loopback_handler (vlib_buffer_t * b, ip6_header_t * ip,
   vlib_put_frame_to_node (hm->vlib_main, next_node->index, nf);
   ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_LOOPBACK, 1);
 }
-
 int
-ip6_hbh_ioam_trace_data_list_handler (vlib_buffer_t * b, ip6_header_t * ip,
-				      ip6_hop_by_hop_option_t * opt)
+ip6_hbh_ioam_trace_data_list_handler (vlib_buffer_t * b, ip6_header_t * ip, ip6_hop_by_hop_option_t * opt)
 {
   ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
   u8 elt_index = 0;
   ioam_trace_option_t *trace = (ioam_trace_option_t *) opt;
   u32 adj_index = vnet_buffer (b)->ip.adj_index[VLIB_TX];
   ip_adjacency_t *adj = adj_get (adj_index);
-  time_u64_t time_u64;
   u32 *elt;
   int rv = 0;
   trace_profile *profile = NULL;
 
-
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
-      return (-1);
-    }
+  {
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
+    return (-1);
+  }
+
+  // Ignore if namespace ID is different
+  if(clib_net_to_host_u16(trace->trace_hdr.namespace_id) != profile->namespace_id)
+  {
+    return rv;
+  }
+
+  if(profile->node_type & IOAM_NODE_DECAP)
+  {
+    vnet_buffer (b)->l2_classify.opaque_index |= 0x80000000;
+  }
 
   /* Don't trace loopback reply packets */
-  if (trace->trace_hdr.ioam_trace_type & BIT_LOOPBACK_REPLY)
+  u16 nlfrl_host = clib_net_to_host_u16(trace->trace_hdr.node_len_flags_remaining_len);
+  if ((IOAM_FLAGS_MASK & nlfrl_host) & IOAM_BIT_FLAG_LOOPBACK_REPLY)
+  {  
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_LOOPBACK_REPLY, 1);
+    return rv;
+  }
+
+  u32 data_list_elts_left = IOAM_REMAIN_LEN_MASK & nlfrl_host;
+
+  if (PREDICT_TRUE (data_list_elts_left))
+  {
+    data_list_elts_left--;
+    nlfrl_host &= (~IOAM_REMAIN_LEN_MASK);
+    nlfrl_host |= data_list_elts_left;
+    trace->trace_hdr.node_len_flags_remaining_len = clib_host_to_net_u16(nlfrl_host);
+    /* fetch_trace_data_size returns in bytes. Convert it to 4-bytes
+      * to skip to this node's location.
+      */
+    elt_index = data_list_elts_left * fetch_trace_data_size (profile) / 4;
+    elt = &trace->trace_hdr.data_list[elt_index];
+
+    // START writing the telemtry info
+    u32 trace_type = IOAM_GET_TRACETYPE(trace->trace_hdr.trace_type);
+
+    time_u64_t time_u64;
+    // reports TTL and user defined node-id-short, different from -wide
+    if (trace_type & IOAM_BIT_TTL_NODEID_SHORT)
     {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_LOOPBACK_REPLY,
-					      1);
-      return rv;
+      u32 node_id = profile->node_id_short;
+      if(!node_id)
+      {
+        node_id = IOAM_EMPTY_FIELD_U24;
+      }
+      *elt = clib_host_to_net_u32 ((ip->hop_limit << 24) | node_id);
+      elt++;
     }
-
-  time_u64.as_u64 = 0;
-
-  if (PREDICT_TRUE (trace->trace_hdr.data_list_elts_left))
+    // reports software interface index
+    if (trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
     {
-      trace->trace_hdr.data_list_elts_left--;
-      /* fetch_trace_data_size returns in bytes. Convert it to 4-bytes
-       * to skip to this node's location.
-       */
-      elt_index =
-	trace->trace_hdr.data_list_elts_left *
-	fetch_trace_data_size (trace->trace_hdr.ioam_trace_type) / 4;
-      elt = &trace->trace_hdr.elts[elt_index];
-      if (trace->trace_hdr.ioam_trace_type & BIT_TTL_NODEID)
-	{
-	  *elt =
-	    clib_host_to_net_u32 ((ip->hop_limit << 24) | profile->node_id);
-	  elt++;
-	}
-
-      if (trace->trace_hdr.ioam_trace_type & BIT_ING_INTERFACE)
-	{
-	  *elt =
-	    (vnet_buffer (b)->sw_if_index[VLIB_RX] & 0xFFFF) << 16 |
-	    (adj->rewrite_header.sw_if_index & 0xFFFF);
-	  *elt = clib_host_to_net_u32 (*elt);
-	  elt++;
-	}
-
-      if (trace->trace_hdr.ioam_trace_type & BIT_TIMESTAMP)
-	{
-	  /* Send least significant 32 bits */
-	  f64 time_f64 =
-	    (f64) (((f64) hm->unix_time_0) +
-		   (vlib_time_now (hm->vlib_main) - hm->vlib_time_0));
-
-	  time_u64.as_u64 = time_f64 * trace_tsp_mul[profile->trace_tsp];
-	  *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
-	  elt++;
-	}
-
-      if (trace->trace_hdr.ioam_trace_type & BIT_APPDATA)
-	{
-	  /* $$$ set elt0->app_data */
-	  *elt = clib_host_to_net_u32 (profile->app_data);
-	  elt++;
-	}
-
-
-      if (PREDICT_FALSE (trace->trace_hdr.ioam_trace_type & BIT_LOOPBACK))
-	{
-	  /* if loopback flag set then copy the packet
-	   * and send it back to source */
-	  ip6_hbh_ioam_loopback_handler (b, ip, trace);
-	}
-
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_UPDATED, 1);
+      u32 rxid = (vnet_buffer (b)->sw_if_index[VLIB_RX] & 0xFFFF);
+      u32 txid = (adj->rewrite_header.sw_if_index & 0xFFFF);
+      if(!rxid)
+      {
+        rxid = IOAM_EMPTY_FIELD_U16;
+      }
+      if(!txid)
+      {
+        txid = IOAM_EMPTY_FIELD_U16;
+      }
+      *elt = clib_host_to_net_u32((rxid << 16) | txid);
+      elt++;
     }
-  else
+    // time stamp in secs
+    if (trace_type & IOAM_BIT_TIMESTAMP_SEC)
+    {
+      /* Send least significant 32 bits */
+      f64 time_f64 = (f64) (((f64) hm->unix_time_0) + (vlib_time_now (hm->vlib_main) - hm->vlib_time_0));
+      time_u64.as_u64 = time_f64 * trace_tsp_mul[IOAM_TSP_SECONDS];
+      if(!time_u64.as_u32[0])
+      {
+        time_u64.as_u32[0] = IOAM_EMPTY_FIELD_U32;
+      }
+      *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
+      elt++;
+    }
+    // time stamp in user defined ts-format
+    if (trace_type & IOAM_BIT_TIMESTAMP_SUB_SEC)
+    {
+      /* Send least significant 32 bits */
+      f64 time_sub_f64 = (f64) (((f64) hm->unix_time_0) + (vlib_time_now (hm->vlib_main) - hm->vlib_time_0));
+      time_u64.as_u64 = time_sub_f64 * trace_tsp_mul[profile->ts_format];
+      if(!time_u64.as_u32[0])
+      {
+        time_u64.as_u32[0] = IOAM_EMPTY_FIELD_U32;
+      }
+      *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
+      elt++;
+    }
+    // reports hop delay from ingress (uses timestamp plugin) to here, though
+    // not exactly the 'egress' time, but close to it and provides good insight in nano secs
+    if (trace_type & IOAM_BIT_TRANSIT_DELAY)
+    {
+      /* Ingress timestamp meta in buffer2->unused data */
+      timestamp_meta_t *time_meta = (void *)  &vnet_buffer2 (b)->unused[0];
+      // Copy the ptr to the location it needs to be stored in the packet, egress timestamp node will handle the rest
+      time_meta->ptr_to_ioam_transit_delay = elt;
+      // could mean CLIB_UNIX not defined, always added in case it's not possible to add stamp
+      *elt = clib_host_to_net_u32 (IOAM_EMPTY_FIELD_U32);
+      elt++;
+    }
+    // user defined app data, different from app-data-wide
+    if (trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
+    {
+      *elt = clib_host_to_net_u32(profile->app_data_short);
+      elt++;
+    }
+    /*
+    * Reporting is dependent on what device is selected, see device_driver_info.c
+    */
+    if (trace_type & IOAM_BIT_QUEUE_DEPTH)
+    {
+      u32 depth = IOAM_EMPTY_FIELD_U32;
+      if (profile->queue_depth_type & QUEUE_DEPTH_AF_PACKET)
+      {
+        // Get TX hardware interface index
+        u32 txid = adj->rewrite_header.sw_if_index;
+        txid = (vnet_get_sup_hw_interface (hm->vnet_main, txid))->hw_if_index;
+        af_packet_main_t *am = &af_packet_main;
+        /* Maybe there's a better way to obtain apif from hw_if_index */
+        vnet_hw_interface_t *hw = vnet_get_hw_interface (hm->vnet_main, txid);
+        af_packet_if_t *apif = pool_elt_at_index (am->interfaces, hw->dev_instance);
+        u8 *tx_block_start = apif->tx_ring;
+        struct tpacket2_hdr *tph_tx = (struct tpacket2_hdr *)tx_block_start;
+        u32 frame_size = apif->tx_req->tp_frame_size;
+        u32 frame_num = apif->tx_req->tp_frame_nr;
+        do
+        {
+          if (tph_tx->tp_status == TP_STATUS_AVAILABLE)
+          {
+            depth++;
+          }
+          tph_tx = (struct tpacket2_hdr *) (((u8 *)tph_tx) + frame_size);
+        } while (--frame_num);
+      }
+      // Trick here is similar to transit delay except, the queue depth is saved in unused[7]
+      else if (profile->queue_depth_type & QUEUE_DEPTH_DPDK)
+      {
+        u32 *queueSize_queueDepth = &vnet_buffer2 (b)->unused[7];
+        // Upper bytes is the total queue size, we only intrested in lower
+        depth = 0x0000FFFF & clib_net_to_host_u32(*queueSize_queueDepth);
+      }
+      *elt = clib_host_to_net_u32 (depth);
+      elt++;
+    }
+    /* TODO */
+    if (trace_type & IOAM_BIT_CHECKSUM_COMPLEMENT)
     {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_FULL, 1);
+      *elt = IOAM_EMPTY_FIELD_U32;
+      elt++;
+    }
+    // reports TTL and user defined node id (different from node-id-short)
+    if (trace_type & IOAM_BIT_TTL_NODEID_WIDE)
+    {
+      u64 *elt_tmp = (u64 *)elt;
+      u64 node_id = profile->node_id_wide; 
+      if(!node_id)
+      {
+        node_id = IOAM_EMPTY_FIELD_U56;
+      }
+      *elt_tmp = clib_host_to_net_u64 ( ( ((u64)ip->hop_limit) << 56 ) | node_id);
+      elt += 2;
+    }
+    // reports hardware interface index
+    if (trace_type & IOAM_BIT_ING_EGR_INT_WIDE)
+    {
+      ip6_hop_by_hop_ioam_trace_main_t *hm = &ip6_hop_by_hop_ioam_trace_main;
+      u32 rxid = vnet_buffer (b)->sw_if_index[VLIB_RX];
+      u32 txid = adj->rewrite_header.sw_if_index;
+      rxid = (vnet_get_sup_hw_interface (hm->vnet_main, rxid))->hw_if_index;
+      txid = (vnet_get_sup_hw_interface (hm->vnet_main, txid))->hw_if_index;
+      if(!rxid)
+      {
+        rxid = IOAM_EMPTY_FIELD_U32;
+      }
+      if(!txid)
+      {
+        txid = IOAM_EMPTY_FIELD_U32;
+      }
+      *elt = clib_host_to_net_u32 (rxid);
+      elt++;
+      *elt = clib_host_to_net_u32 (txid);
+      elt++;
+    }
+    // user defined app data, different from -short
+    if (trace_type & IOAM_BIT_APPDATA_WIDE_DATA)
+    {
+      u64 *elt_tmp = (u64 *)elt;
+      *elt_tmp = clib_host_to_net_u64 (profile->app_data_wide);
+      elt += 2;
+    }
+    // reports the number of buffer available in this packet's mem pool
+    if (trace_type & IOAM_BIT_BUFFER_OCCUPANCY)
+    {
+      vlib_buffer_pool_t *bp = vlib_get_buffer_pool (vlib_get_main(), b->buffer_pool_index);
+      u32 buff_avail = IOAM_EMPTY_FIELD_U32;
+      if(bp)
+      {
+        buff_avail = bp->n_avail;
+      }
+      *elt = clib_host_to_net_u32(buff_avail);
+      elt++;
     }
+    // user defined opaque data
+    if (trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH)
+    {
+      u32 schema = profile->opaque.len_schemeid & IOAM_OPAQUE_SCHEMEID_MASK;
+      u32 len = IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid);
+      opaque_scheme_t *opq = (opaque_scheme_t *)elt;
+      if(!schema || !len)
+      {
+        opq->len_schemeid = IOAM_EMPTY_FIELD_U32;
+      }
+      else
+      {
+        opq->len_schemeid = clib_host_to_net_u32(profile->opaque.len_schemeid);
+        // Endianess taken care in trace_profile_create
+        clib_memcpy_fast (opq->data, profile->opaque.data, len << 2);
+        // (1+) for opaque header and len is in 4 octet multipes
+        elt += 1 + len;
+      }
+    }
+
+    if (PREDICT_FALSE ((nlfrl_host & IOAM_FLAGS_MASK) & IOAM_BIT_FLAG_LOOPBACK))
+    {
+      /* if loopback flag set then copy the packet
+      * and send it back to source */
+      ip6_hbh_ioam_loopback_handler (b, ip, trace);
+    }
+
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_UPDATED, 1);
+  }
+  else
+  {
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_FULL, 1);
+  }
   return (rv);
 }
 
 u8 *
-ip6_hbh_ioam_trace_data_list_trace_handler (u8 * s,
-					    ip6_hop_by_hop_option_t * opt)
+ip6_hbh_ioam_trace_data_list_trace_handler (u8 * s, ip6_hop_by_hop_option_t * opt)
 {
   ioam_trace_option_t *trace;
   u8 trace_data_size_in_words = 0;
@@ -356,42 +597,38 @@ ip6_hbh_ioam_trace_data_list_trace_handler (u8 * s,
   int elt_index = 0;
 
   trace = (ioam_trace_option_t *) opt;
-  s =
-    format (s, "  Trace Type 0x%x , %d elts left\n",
-	    trace->trace_hdr.ioam_trace_type,
-	    trace->trace_hdr.data_list_elts_left);
-  trace_data_size_in_words =
-    fetch_trace_data_size (trace->trace_hdr.ioam_trace_type) / 4;
-  elt = &trace->trace_hdr.elts[0];
+
+  s = format (s, " namespace id %d, trace type 0x%x, %d elts left, %d bytes per node\n", 
+                clib_net_to_host_u16(trace->trace_hdr.namespace_id), 
+                IOAM_GET_TRACETYPE(trace->trace_hdr.trace_type), 
+                clib_net_to_host_u16(trace->trace_hdr.node_len_flags_remaining_len) & IOAM_REMAIN_LEN_MASK,
+                IOAM_GET_NODE_LEN(clib_net_to_host_u16(trace->trace_hdr.node_len_flags_remaining_len))<<2);
+  trace_data_size_in_words = fetch_trace_data_size (trace_profile_find()) / 4;
+  elt = &trace->trace_hdr.data_list[0];
+  u32 trace_type = IOAM_GET_TRACETYPE(trace->trace_hdr.trace_type);
   while ((u8 *) elt <
-	 ((u8 *) (&trace->trace_hdr.elts[0]) + trace->hdr.length - 2
-	  /* -2 accounts for ioam_trace_type,elts_left */ ))
-    {
-      s = format (s, "    [%d] %U\n", elt_index,
-		  format_ioam_data_list_element,
-		  elt, &trace->trace_hdr.ioam_trace_type);
-      elt_index++;
-      elt += trace_data_size_in_words;
-    }
+	 ((u8 *) (&trace->trace_hdr.data_list[0]) + trace->hdr.length - sizeof(ioam_trace_hdr_t) - 2)) /* ip6_hop_by_hop_option_t: reserved and ioam_type */
+  {
+    s = format (s, "    [%d]%U\n", elt_index, format_ioam_data_list_element, elt, &trace_type);
+    elt_index++;
+    elt += trace_data_size_in_words;
+  }
   return (s);
 }
 
 
 static clib_error_t *
-ip6_show_ioam_trace_cmd_fn (vlib_main_t * vm,
-			    unformat_input_t * input,
-			    vlib_cli_command_t * cmd)
+ip6_show_ioam_trace_cmd_fn (vlib_main_t * vm, unformat_input_t * input, vlib_cli_command_t * cmd)
 {
   ip6_hop_by_hop_ioam_trace_main_t *hm = &ip6_hop_by_hop_ioam_trace_main;
   u8 *s = 0;
   int i = 0;
 
   for (i = 0; i < IP6_IOAM_TRACE_N_STATS; i++)
-    {
-      s =
-	format (s, " %s - %lu\n", ip6_hop_by_hop_ioam_trace_stats_strings[i],
-		hm->counters[i]);
-    }
+  {
+    s =
+      format (s, " %s - %lu\n", ip6_hop_by_hop_ioam_trace_stats_strings[i], hm->counters[i]);
+  }
 
   vlib_cli_output (vm, "%v", s);
   vec_free (s);
@@ -423,7 +660,6 @@ ip6_hop_by_hop_ioam_trace_init (vlib_main_t * vm)
   hm->vnet_main = vnet_get_main ();
   clib_memset (hm->counters, 0, sizeof (hm->counters));
 
-
   if (ip6_hbh_register_option
       (HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST,
        ip6_hbh_ioam_trace_data_list_handler,
@@ -431,7 +667,6 @@ ip6_hop_by_hop_ioam_trace_init (vlib_main_t * vm)
     return (clib_error_create
 	    ("registration of HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST failed"));
 
-
   if (ip6_hbh_add_register_option (HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST,
 				   sizeof (ioam_trace_option_t),
 				   ip6_hop_by_hop_ioam_trace_rewrite_handler)
@@ -439,7 +674,6 @@ ip6_hop_by_hop_ioam_trace_init (vlib_main_t * vm)
     return (clib_error_create
 	    ("registration of HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST for rewrite failed"));
 
-
   return (0);
 }
 
@@ -457,12 +691,10 @@ ip6_trace_profile_cleanup (void)
   ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
 
   hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] = 0;
-
   return 0;
 
 }
 
-
 int
 ip6_trace_profile_setup (void)
 {
@@ -471,21 +703,21 @@ ip6_trace_profile_setup (void)
 
   trace_profile *profile = NULL;
 
-
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
-      return (-1);
-    }
-
+  {
+    ip6_ioam_trace_stats_increment_counter (IP6_IOAM_TRACE_PROFILE_MISS, 1);
+    return (-1);
+  }
 
   if (ip6_ioam_trace_get_sizeof_handler (&trace_size) < 0)
+  {
     return (-1);
-
+  }
+  // rewrite size for rewrite handler is set here
+  // LENGTH
   hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] = trace_size;
-
   return (0);
 }
 
diff --git a/src/plugins/ioam/encap/ip6_ioam_trace.h b/src/plugins/ioam/encap/ip6_ioam_trace.h
index 4eda6110d..57ff75556 100644
--- a/src/plugins/ioam/encap/ip6_ioam_trace.h
+++ b/src/plugins/ioam/encap/ip6_ioam_trace.h
@@ -29,15 +29,27 @@ typedef CLIB_PACKED(struct {
 /* *INDENT-ON* */
 
 always_inline void
-ip6_hbh_ioam_trace_set_bit (ioam_trace_option_t * trace, u8 trace_bit)
+ip6_hbh_ioam_trace_set_bit (ioam_trace_option_t * trace, u32 trace_bit)
 {
-  ioam_trace_set_bit (&trace->trace_hdr, trace_bit);
+  ioam_tracetype_set_bit (&trace->trace_hdr, trace_bit);
 }
 
 always_inline void
-ip6_hbh_ioam_trace_reset_bit (ioam_trace_option_t * trace, u8 trace_bit)
+ip6_hbh_ioam_trace_set_flag_bit (ioam_trace_option_t * trace, u32 flag_bit)
 {
-  ioam_trace_reset_bit (&trace->trace_hdr, trace_bit);
+  ioam_traceflag_set_bit (&trace->trace_hdr, flag_bit);
+}
+
+always_inline void
+ip6_hbh_ioam_trace_reset_bit (ioam_trace_option_t * trace, u32 trace_bit)
+{
+  ioam_tracetype_reset_bit (&trace->trace_hdr, trace_bit);
+}
+
+always_inline void
+ip6_hbh_ioam_trace_reset_flag_bit (ioam_trace_option_t * trace, u32 flag_bit)
+{
+  ioam_traceflag_reset_bit (&trace->trace_hdr, flag_bit);
 }
 
 #endif /* PLUGINS_IOAM_PLUGIN_IOAM_ENCAP_IP6_IOAM_TRACE_H_ */
diff --git a/src/plugins/ioam/lib-trace/trace.api b/src/plugins/ioam/lib-trace/trace.api
index 52dc648ea..73541960a 100644
--- a/src/plugins/ioam/lib-trace/trace.api
+++ b/src/plugins/ioam/lib-trace/trace.api
@@ -26,11 +26,19 @@ option version = "1.0.0";
 autoreply define trace_profile_add {
   u32 client_index;
   u32 context;
-  u8 trace_type;
+  u16 namespace_id;
   u8 num_elts;
-  u8 trace_tsp;
-  u32 node_id;
-  u32 app_data;
+  u32 node_id_short;
+  u64 node_id_wide;
+  u32 app_data_short;
+  u64 app_data_wide;
+  u8 option_type;
+  u32 trace_type;
+  u8 node_type;
+  u8 ts_format;
+  u8 queue_depth_type;
+  u8 opaque_len;
+  u32 opaque_id;
 };
 
 /** \brief Delete trace Profile
@@ -63,9 +71,17 @@ define trace_profile_show_config {
 define trace_profile_show_config_reply {
   u32 context;
   i32 retval;
-  u8 trace_type;
+  u16 namespace_id;
   u8 num_elts;
-  u8 trace_tsp;
-  u32 node_id;
-  u32 app_data;
+  u32 node_id_short;
+  u64 node_id_wide;
+  u32 app_data_short;
+  u64 app_data_wide;
+  u8 option_type;
+  u32 trace_type;
+  u8 node_type;
+  u8 ts_format;
+  u8 queue_depth_type;
+  u8 opaque_len;
+  u32 opaque_id;
 };
diff --git a/src/plugins/ioam/lib-trace/trace_api.c b/src/plugins/ioam/lib-trace/trace_api.c
index fbabc6d72..8ac1aa17f 100644
--- a/src/plugins/ioam/lib-trace/trace_api.c
+++ b/src/plugins/ioam/lib-trace/trace_api.c
@@ -31,34 +31,45 @@
 #include <ioam/lib-trace/trace.api_enum.h>
 #include <ioam/lib-trace/trace.api_types.h>
 
-static void vl_api_trace_profile_add_t_handler
-  (vl_api_trace_profile_add_t * mp)
+static void vl_api_trace_profile_add_t_handler (vl_api_trace_profile_add_t * mp)
 {
+  /* stuff required for each API function */
   int rv = 0;
   vl_api_trace_profile_add_reply_t *rmp;
-  trace_profile *profile = NULL;
 
+  /* stuff specific to the trace_profile_add API function */
+  trace_profile *profile = NULL;
+  trace_profile tmp;
   profile = trace_profile_find ();
   if (profile)
-    {
-      rv =
-	trace_profile_create (profile, mp->trace_type, mp->num_elts,
-			      mp->trace_tsp, ntohl (mp->node_id),
-			      ntohl (mp->app_data));
-      if (rv != 0)
-	goto ERROROUT;
+  {
+    tmp.namespace_id = mp->namespace_id;
+    tmp.num_elts = mp->num_elts;
+    tmp.node_id_short = ntohl(mp->node_id_short);
+    tmp.node_id_wide = ntohll64(mp->node_id_wide);
+    tmp.app_data_short = ntohl(mp->app_data_short);
+    tmp.app_data_wide = ntohll64(mp->app_data_wide);
+    tmp.option_type = mp->option_type;
+    tmp.trace_type = mp->trace_type;
+    tmp.node_type = mp->node_type;
+    tmp.ts_format = mp->ts_format;
+    tmp.queue_depth_type = mp->queue_depth_type;
+    tmp.opaque.len_schemeid = IOAM_SET_OPAQUE_HEADER(mp->opaque_len, mp->opaque_id);
+    rv = trace_profile_create (profile, &tmp);
+    if (rv != 0) {
+      goto ERROROUT;
     }
+  }
   else
-    {
-      rv = -3;
-    }
-ERROROUT:
-  REPLY_MACRO (VL_API_TRACE_PROFILE_ADD_REPLY);
+  {
+    rv = -3;
+  }
+  ERROROUT:
+    REPLY_MACRO (VL_API_TRACE_PROFILE_ADD_REPLY);
 }
 
 
-static void vl_api_trace_profile_del_t_handler
-  (vl_api_trace_profile_del_t * mp)
+static void vl_api_trace_profile_del_t_handler (vl_api_trace_profile_del_t * mp)
 {
   int rv = 0;
   vl_api_trace_profile_del_reply_t *rmp;
@@ -68,30 +79,48 @@ static void vl_api_trace_profile_del_t_handler
   REPLY_MACRO (VL_API_TRACE_PROFILE_DEL_REPLY);
 }
 
-static void vl_api_trace_profile_show_config_t_handler
-  (vl_api_trace_profile_show_config_t * mp)
+static void vl_api_trace_profile_show_config_t_handler (vl_api_trace_profile_show_config_t * mp)
 {
   vl_api_trace_profile_show_config_reply_t *rmp;
   int rv = 0;
   trace_profile *profile = trace_profile_find ();
+  
   if (profile->valid)
-    {
-      REPLY_MACRO2 (VL_API_TRACE_PROFILE_SHOW_CONFIG_REPLY,
-		    rmp->trace_type = profile->trace_type;
-		    rmp->num_elts = profile->num_elts;
-		    rmp->trace_tsp = profile->trace_tsp;
-		    rmp->node_id = htonl (profile->node_id);
-		    rmp->app_data = htonl (profile->app_data);
-	);
-    }
+  {
+    REPLY_MACRO2 (VL_API_TRACE_PROFILE_SHOW_CONFIG_REPLY,
+      rmp->namespace_id = profile->namespace_id;
+      rmp->num_elts = profile->num_elts;
+      rmp->node_id_short = htonl(profile->node_id_short);
+      rmp->node_id_wide = htonll64(profile->node_id_wide);
+      rmp->app_data_short = htonl(profile->app_data_short);
+      rmp->app_data_wide = htonll64(profile->app_data_wide);
+      rmp->option_type = profile->option_type;
+      rmp->trace_type = profile->trace_type;
+      rmp->node_type = profile->node_type;
+      rmp->ts_format = profile->ts_format;
+      rmp->queue_depth_type = profile->queue_depth_type;
+      rmp->opaque_len = IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid);
+      rmp->opaque_id = IOAM_OPAQUE_SCHEMEID_MASK & profile->opaque.len_schemeid;
+    );
+  }
   else
-    {
-      REPLY_MACRO2 (VL_API_TRACE_PROFILE_SHOW_CONFIG_REPLY,
-		    rmp->trace_type = 0;
-		    rmp->num_elts = 0; rmp->trace_tsp = 0;
-		    rmp->node_id = 0; rmp->app_data = 0;
-	);
-    }
+  {
+    REPLY_MACRO2 (VL_API_TRACE_PROFILE_SHOW_CONFIG_REPLY,
+      rmp->namespace_id = 0;
+      rmp->num_elts = 0;
+      rmp->node_id_short = 0;
+      rmp->node_id_wide = 0;
+      rmp->app_data_short = 0;
+      rmp->app_data_wide = 0;
+      rmp->option_type = 0;
+      rmp->trace_type = 0;
+      rmp->node_type = 0;
+      rmp->ts_format = 0;
+      rmp->queue_depth_type = 0;
+      rmp->opaque_len = 0;
+      rmp->opaque_id = 0;
+    );
+  }
 }
 
 #include <ioam/lib-trace/trace.api.c>
@@ -99,9 +128,8 @@ static clib_error_t *
 trace_init (vlib_main_t * vm)
 {
   trace_main_t *sm = &trace_main;
-
   bzero (sm, sizeof (trace_main));
-  (void) trace_util_init ();
+  (void) trace_util_init (); 
 
   sm->vlib_main = vm;
   sm->vnet_main = vnet_get_main ();
diff --git a/src/plugins/ioam/lib-trace/trace_test.c b/src/plugins/ioam/lib-trace/trace_test.c
index d1f9db41f..7fb85fb63 100644
--- a/src/plugins/ioam/lib-trace/trace_test.c
+++ b/src/plugins/ioam/lib-trace/trace_test.c
@@ -73,9 +73,9 @@ api_trace_profile_add (vat_main_t * vam)
   M (TRACE_PROFILE_ADD, mp);
 
   mp->trace_type = trace_type;
-  mp->trace_tsp = trace_tsp;
-  mp->node_id = htonl (node_id);
-  mp->app_data = htonl (app_data);
+  mp->ts_format = trace_tsp;
+  mp->node_id_short = htonl (node_id);
+  mp->app_data_short = htonl (app_data);
   mp->num_elts = num_elts;
 
   S (mp);
diff --git a/src/plugins/ioam/lib-trace/trace_util.c b/src/plugins/ioam/lib-trace/trace_util.c
index d935543cf..66307cd59 100644
--- a/src/plugins/ioam/lib-trace/trace_util.c
+++ b/src/plugins/ioam/lib-trace/trace_util.c
@@ -25,12 +25,9 @@ __clib_export trace_main_t trace_main;
 static int
 trace_profile_cleanup (trace_profile * profile)
 {
-
   clib_memset (profile, 0, sizeof (trace_profile));
-  profile->trace_tsp = TSP_MICROSECONDS;	/* Micro seconds */
   ip6_trace_profile_cleanup ();	/* lib-trace_TODO: Remove this once IOAM-IPv6 transport is a plugin */
   return 0;
-
 }
 
 static int
@@ -52,42 +49,48 @@ trace_util_init (void)
   return (rv);
 }
 
-
 int
-trace_profile_create (trace_profile * profile, u8 trace_type, u8 num_elts,
-		      u32 trace_tsp, u32 node_id, u32 app_data)
+trace_profile_create (trace_profile * profile, trace_profile *user_defined)
 {
-
-  if (!trace_type || !num_elts || !(node_id))
-    {
-      return (-1);
-    }
   if (profile && !profile->valid)
+  {
+    // Set the rest of the vars
+    profile->namespace_id = user_defined->namespace_id;
+    profile->num_elts = user_defined->num_elts;
+    profile->node_id_short = user_defined->node_id_short;
+    profile->node_id_wide = user_defined->node_id_wide;
+    profile->app_data_short = user_defined->app_data_short;
+    profile->app_data_wide = user_defined->app_data_wide;
+    profile->option_type = user_defined->option_type;
+    profile->node_type = user_defined->node_type;
+    profile->trace_type = user_defined->trace_type;
+    profile->ts_format = user_defined->ts_format;
+    profile->queue_depth_type = user_defined->queue_depth_type;
+    profile->valid = 1;
+    profile->opaque.len_schemeid = user_defined->opaque.len_schemeid;
+    if(user_defined->opaque.data)
     {
-      //rv = trace_profile_cleanup (profile);
-      profile->trace_type = trace_type;
-      profile->num_elts = num_elts;
-      profile->trace_tsp = trace_tsp;
-      profile->node_id = node_id;
-      profile->app_data = app_data;
-      profile->valid = 1;
-
-      /* lib-trace_TODO: Remove this once IOAM-IPv6 transport is a plugin */
-      ip6_trace_profile_setup ();
-      return (0);
+      vlib_cli_output(vlib_get_main(), "Trace Profile Create: Adding %d-bytes of opaque data...\n");
+      u32 olen = IOAM_GET_OPAQUE_LEN(user_defined->opaque.len_schemeid); // Represented as 4 octets
+      u32 i;
+      for(i = 0; i < olen; i++)
+      {
+        // Freaking endianess
+        profile->opaque.data[i] = clib_host_to_net_u32(user_defined->opaque.data[i]);
+      }
+      vec_free(user_defined->opaque.data);
     }
-
+    
+    /* lib-trace_TODO: Remove this once IOAM-IPv6 transport is a plugin */
+    ip6_trace_profile_setup ();
+    return (0);
+  }
   return (-1);
 }
 
-
-
 clib_error_t *
-clear_trace_profile_command_fn (vlib_main_t * vm,
-				unformat_input_t * input,
-				vlib_cli_command_t * cmd)
+clear_trace_profile_command_fn (vlib_main_t * vm, unformat_input_t * input, vlib_cli_command_t * cmd)
 {
-
   trace_main_profiles_reset ();
   return 0;
 }
@@ -105,86 +108,88 @@ VLIB_CLI_COMMAND(clear_trace_profile_command) =
 .short_help = "clear ioam-trace profile [<index>|all]",
 .function = clear_trace_profile_command_fn,
 };
-/* *INDENT-ON* */
-
-static clib_error_t *
-set_trace_profile_command_fn (vlib_main_t * vm,
-			      unformat_input_t * input,
-			      vlib_cli_command_t * cmd)
-{
-  u8 trace_type = 0;
-  u8 num_elts = 0;
-  u32 node_id = 0;
-  u32 app_data = 0;
-  u32 trace_tsp = 0;
-  trace_profile *profile = NULL;
-  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
-    {
-      if (unformat (input, "trace-type 0x%x", &trace_type));
-      else if (unformat (input, "trace-elts %d", &num_elts));
-      else if (unformat (input, "trace-tsp %d", &trace_tsp));
-      else if (unformat (input, "node-id 0x%x", &node_id));
-      else if (unformat (input, "app-data 0x%x", &app_data));
-      else
-	break;
-    }
-  profile = trace_profile_find ();
-  if (profile)
-    {
-      trace_profile_create (profile, trace_type, num_elts, trace_tsp,
-			    node_id, app_data);
-    }
-  return 0;
-}
 
-/* *INDENT-OFF* */
-VLIB_CLI_COMMAND (set_trace_profile_command, static) =
-{
-.path = "set ioam-trace profile",
-.short_help = "set ioam-trace \
-             trace-type <0x1f|0x3|0x9|0x11|0x19> trace-elts <nn> trace-tsp <0|1|2|3> \
-             node-id <node id in hex> app-data <app_data in hex>",
-.function = set_trace_profile_command_fn,
-};
 /* *INDENT-ON* */
-
 static clib_error_t *
-show_trace_profile_command_fn (vlib_main_t * vm,
-			       unformat_input_t * input,
-			       vlib_cli_command_t * cmd)
+show_trace_profile_command_fn (vlib_main_t * vm, unformat_input_t * input, vlib_cli_command_t * cmd)
 {
   trace_profile *p = NULL;
-  u8 *s = 0;
   p = trace_profile_find ();
+  u8 *s = 0;
   if (!(p && p->valid))
-    {
-      s = format (s, "\nTrace configuration not valid\n");
-      vlib_cli_output (vm, "%v", s);
-      vec_free (s);
-      return 0;
-    }
+  {
+    s = format (s, "\nTrace configuration not valid\n");
+    vlib_cli_output (vm, "%v", s);
+    vec_free (s);
+    return 0;
+  }
   s = format (s, " HOP BY HOP OPTIONS - TRACE CONFIG - \n");
-  s = format (s, "                        Trace Type : 0x%x (%d)\n",
-	      p->trace_type, p->trace_type);
+  s = format (s, "        iOAM Namespace      : %d\n",
+	      p->namespace_id);
+  s = format (s, "        iOAM Type           : %d ", p->option_type);
+  u8* stmp = 0;
+  if(p->option_type & IOAM_OPTION_PREALLOC)
+  {
+    stmp = format(stmp, " - Preallocation");
+  }
+  if(p->option_type & IOAM_OPTION_INCREMENT)
+  {
+    stmp = format(stmp, " - Incremental");
+  }
+  if(p->option_type & IOAM_OPTION_POT)
+  {
+    stmp = format(stmp, " - Proof-of-Transit");
+  }
+  if(p->option_type & IOAM_OPTION_E2E)
+  {
+    stmp = format(stmp, " - Edge-to-Edge");
+  }
+  s = format(s, "(%s)\n", stmp);
+  s = format (s, "        Trace Type          : 0x%x\n",
+	      p->trace_type);
   s =
-    format (s, "         Trace timestamp precision : %d (%s)\n",
-	    p->trace_tsp,
-	    (p->trace_tsp ==
-	     TSP_SECONDS) ? "Seconds" : ((p->trace_tsp ==
-					  TSP_MILLISECONDS) ?
+    format (s, "        Timestamp precision : %d (%s)\n",
+	    p->ts_format,
+	    (p->ts_format ==
+	     IOAM_TSP_SECONDS) ? "Seconds" : ((p->ts_format ==
+					  IOAM_TSP_MILLISECONDS) ?
 					 "Milliseconds"
-					 : (((p->trace_tsp ==
-					      TSP_MICROSECONDS) ?
+					 : (((p->ts_format ==
+					      IOAM_TSP_MICROSECONDS) ?
 					     "Microseconds" :
 					     "Nanoseconds"))));
-  s = format (s, "                Num of trace nodes : %d\n", p->num_elts);
+  s = format (s, "        Num of trace nodes  : %d\n", p->num_elts);
+  s =
+    format (s, "        Node-ID-Short/Type  : %d / %s\n",
+	    p->node_id_short, 
+      (p->node_type == IOAM_NODE_ENCAP) ? "Encap" : 
+      ((p->node_type == IOAM_NODE_TRANSIT) ? "Transit" : "Decap"));
   s =
-    format (s, "                           Node-id : 0x%x (%d)\n",
-	    p->node_id, p->node_id);
+    format (s, "        App Data-Short      : 0x%x\n",
+	    p->app_data_short);
   s =
-    format (s, "                          App Data : 0x%x (%d)\n",
-	    p->app_data, p->app_data);
+    format (s, "        Node-ID-Wide/Type   : 0x%Lx / %s\n",
+	    p->node_id_wide, 
+      (p->node_type == IOAM_NODE_ENCAP) ? "Encap" : 
+      ((p->node_type == IOAM_NODE_TRANSIT) ? "Transit" : "Decap"));
+  s =
+    format (s, "        App Data-Wide       : 0x%Lx\n",
+	    p->app_data_wide);
+  s =
+    format (s, "        Queue Depth-Type    : %s\n",
+      (p->queue_depth_type == QUEUE_DEPTH_AF_PACKET) ? "AF_PACKET" : 
+      ((p->queue_depth_type == QUEUE_DEPTH_DPDK) ? "DPDK" : "NON"));
+  s = format (s, "        Opaque Length/ID    : %d / %d\n", 
+    IOAM_GET_OPAQUE_LEN(p->opaque.len_schemeid) << 2, p->opaque.len_schemeid & IOAM_OPAQUE_SCHEMEID_MASK);
+  if (IOAM_GET_OPAQUE_LEN(p->opaque.len_schemeid))
+  {
+    u32 indent = format_get_indent (s);
+    s = format (s, "        Opaque Data         : \n        %U%U", 
+                format_white_space, indent,
+                format_hex_bytes, p->opaque.data, IOAM_GET_OPAQUE_LEN(p->opaque.len_schemeid) << 2);
+  }
   vlib_cli_output (vm, "%v", s);
+  vec_free (stmp);
   vec_free (s);
   return 0;
 }
@@ -198,6 +203,239 @@ VLIB_CLI_COMMAND (show_trace_profile_command, static) =
 };
 /* *INDENT-ON* */
 
+uword
+unformat_option_type (unformat_input_t * input, va_list * args)
+{
+  u8 *result = va_arg (*args, u8 *);
+  *result = 0;
+  u8 tmp = 0;
+  do
+  {
+    if (unformat (input, "prealloc"))
+    {
+      *result |= IOAM_OPTION_PREALLOC;
+    }
+    else if (unformat (input, "increment"))
+    {
+      *result |= IOAM_OPTION_INCREMENT;
+    }
+    else if (unformat (input, "pot"))
+    {
+      *result |= IOAM_OPTION_POT;
+    }
+    else if (unformat (input, "e2e"))
+    {
+      *result |= IOAM_OPTION_E2E;
+    }
+  } while(tmp++ < 4);
+  if( (*result & IOAM_OPTION_PREALLOC) && (*result &  IOAM_OPTION_INCREMENT) )
+  {
+    vlib_cli_output (vlib_get_main(), "WARNING: option-type (0x%x) contains both prealloc and increment, defaulting to prealloc", *result);
+    *result &= ~(IOAM_OPTION_INCREMENT);
+  }
+  if (*result == 0)
+  {
+    vlib_cli_output (vlib_get_main(), "WARNING: No option-type chosen, defaulting to prealloc");
+    *result = IOAM_OPTION_PREALLOC;
+  }
+  return 1;
+}
+uword
+unformat_node_type (unformat_input_t * input, va_list * args)
+{
+  u8 *result = va_arg (*args, u8 *);
+  *result = 99; // For input check later
+
+  if (unformat (input, "encap"))
+  {
+    *result = IOAM_NODE_ENCAP;
+  }
+  else if (unformat (input, "transit"))
+  {
+    *result = IOAM_NODE_TRANSIT;
+  }
+  else if (unformat (input, "decap"))
+  {
+    *result = IOAM_NODE_DECAP;
+  }
+  return 1;
+}
+uword
+unformat_ts_format (unformat_input_t * input, va_list * args)
+{
+  u8 *result = va_arg (*args, u8 *);
+  *result = 99; // For input check later
+
+  if (unformat (input, "sec"))
+  {
+    *result = IOAM_TSP_SECONDS;
+  }
+  else if (unformat (input, "ms"))
+  {
+    *result = IOAM_TSP_MILLISECONDS;
+  }
+  else if (unformat (input, "us"))
+  {
+    *result = IOAM_TSP_MICROSECONDS;
+  }
+  else if (unformat (input, "ns"))
+  {
+    *result = IOAM_TSP_NANOSECONDS;
+  }
+  return 1;
+}
+uword
+unformat_queue_depth_format (unformat_input_t * input, va_list * args)
+{
+  u8 *result = va_arg (*args, u8 *);
+  *result = 99; // For input check later
+
+  if (unformat (input, "drv-af-packet"))
+  {
+    *result = QUEUE_DEPTH_AF_PACKET;
+  }
+  else if (unformat (input, "drv-dpdk"))
+  {
+    *result = QUEUE_DEPTH_DPDK;
+  }
+  return 1;
+}
+static u8 *
+trace_util_check_input(u8 *inerror, va_list * args)
+{
+  vlib_main_t * vm = va_arg (*args, vlib_main_t *);
+  trace_profile *input = va_arg (*args, trace_profile *);
+  u32 *olen = va_arg (*args, u32 *);
+  u32 *oid = va_arg (*args, u32 *);
+  // Invalid instruction
+  if ((input->trace_type & ~IOAM_INSTR_BITMAP_MASK) | (!input->trace_type))
+  {
+    inerror =  format (inerror, " - ERROR: Invalid trace-type (0x%x)\n", input->trace_type);
+  }
+  // check validity of option type
+  u8 all_options = IOAM_OPTION_PREALLOC | IOAM_OPTION_INCREMENT | IOAM_OPTION_POT | IOAM_OPTION_E2E;
+  if( input->option_type & ~all_options )
+  {
+    inerror =  format (inerror, " - ERROR: Invalid option-type - [prealloc | increment | pot | e2e]\n");
+  }
+  if (input->option_type == 0)
+  {
+    vlib_cli_output (vm, "WARNING: No option-type chosen, defaulting to prealloc");
+    input->option_type = IOAM_OPTION_PREALLOC;
+  }
+  u8 all_nodes = IOAM_NODE_ENCAP | IOAM_NODE_TRANSIT | IOAM_NODE_DECAP;
+  if((input->node_type & ~all_nodes) | !input->node_type)
+  {
+    inerror =  format (inerror, " - ERROR: Invalid node-type - [encap | transit | decap]\n");
+  }
+  if(!input->num_elts)
+  {
+    inerror =  format (inerror, " - ERROR: num-elts must be > 0\n");
+  }
+  if (((input->trace_type & IOAM_BIT_TTL_NODEID_SHORT) == 0) && ((input->trace_type & IOAM_BIT_TTL_NODEID_WIDE) == 0))
+  {
+    inerror =  format (inerror, " - ERROR: Node ID (short or wide) is required and must be > 0\n");
+  }
+  if( (input->trace_type & IOAM_BIT_TTL_NODEID_SHORT) && !input->node_id_short)
+  {
+    inerror =  format (inerror, " - ERROR: node-id-short must be > 0\n");
+  }
+  if( (input->trace_type & IOAM_BIT_TTL_NODEID_WIDE) && !input->node_id_wide)
+  {
+    inerror =  format (inerror, " - ERROR: node-id-wide must be > 0\n");
+  }
+  if( (input->trace_type & IOAM_BIT_TIMESTAMP_SUB_SEC) && (input->ts_format >= IOAM_TSP_OPTION_SIZE) )
+  {
+    inerror =  format (inerror, " - ERROR: ts-format-sub must be - [sec | ms | us | ns]\n");
+  }
+  u8 all_depth_types = QUEUE_DEPTH_AF_PACKET | QUEUE_DEPTH_DPDK;
+  if( (input->trace_type & IOAM_BIT_QUEUE_DEPTH) && ((input->queue_depth_type & ~all_depth_types) | !input->queue_depth_type))
+  {
+    inerror =  format (inerror, " - ERROR: queue-depth-type must be - [drv-af-packet | drv-dpdk]\n");
+  }
+  u32 in_olen = *olen;
+  u32 in_oid = *oid;
+  if((in_olen && in_oid) && (input->trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH)) 
+  {
+    u32 odata_len = vec_len(input->opaque.data);
+    if(in_olen != odata_len)
+    {
+      vlib_cli_output(vm, "WARNING: opaque-len (%d) != len(opaque-data) (%d) octets - setting to (%d)", in_olen, odata_len, odata_len);
+      in_olen = odata_len;
+    }
+    // round to 4 octet multiples
+    in_olen = (in_olen + 3) & ~3;
+    if(in_olen > IOAM_MAX_OPAQUE_DATA_BYTE_SIZE) 
+    {
+      vlib_cli_output(vm, "WARNING: in_olen (%d) > max (%d) octets - using max length", in_olen, IOAM_MAX_OPAQUE_DATA_BYTE_SIZE);
+      in_olen = IOAM_MAX_OPAQUE_DATA_BYTE_SIZE;
+    }
+    // lenght in 4 octet units
+    in_olen = in_olen >> 2;
+    input->opaque.len_schemeid = IOAM_SET_OPAQUE_HEADER(in_olen,in_oid);
+  }
+  else if(
+    ((!in_olen || !in_oid) && (input->trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH)) ||
+    (!(input->trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH) && (in_olen || in_oid))
+    ) 
+  {
+    inerror =  
+    format (inerror, "ERROR: Opaque, check - opaque bit in trace-type (0x%x), opaque-len (%d) opaque-id (%d)",
+    input->trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH, in_olen, in_oid);
+  }
+  return inerror;
+}
+/* *INDENT-ON* */
+static clib_error_t *
+set_trace_profile_command_fn (vlib_main_t * vm, unformat_input_t * input, vlib_cli_command_t * cmd)
+{
+  trace_profile *profile = NULL;
+  trace_profile user_defined;
+  clib_memset (&user_defined, 0, sizeof (trace_profile));
+  u32 olen = 0; 
+  u32 oid = 0;
+  clear_trace_profiles ();
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+  {
+    if (unformat (input, "namespace-id %d", &user_defined.namespace_id));
+    else if (unformat (input, "num-elts %d", &user_defined.num_elts));
+    else if (unformat (input, "node-id-short %d", &user_defined.node_id_short));
+    else if (unformat (input, "node-id-wide 0x%Lx", &user_defined.node_id_wide));
+    else if (unformat (input, "app-data-short 0x%x", &user_defined.app_data_short));
+    else if (unformat (input, "app-data-wide 0x%Lx", &user_defined.app_data_wide));
+    else if (unformat (input, "option-type %U", unformat_option_type, &user_defined.option_type));
+    else if (unformat (input, "trace-type 0x%x", &user_defined.trace_type));
+    else if (unformat (input, "node-type %U", unformat_node_type, &user_defined.node_type));
+    else if (unformat (input, "ts-format-sub %U", unformat_ts_format, &user_defined.ts_format));
+    else if (unformat (input, "queue-depth-type %U", unformat_queue_depth_format, &user_defined.queue_depth_type));
+    else if (unformat (input, "opaque-len %d", &olen));
+    else if (unformat (input, "opaque-id %d", &oid));
+    else if (unformat (input, "opaque-data 0x%U", unformat_hex_string, &user_defined.opaque.data));
+    else break;
+  }
+  profile = trace_profile_find ();
+  u8 *errstr = 0;
+  errstr = format(errstr, "%U", trace_util_check_input, vm, &user_defined, &olen, &oid);
+  if (!errstr)
+  {
+    trace_profile_create (profile, &user_defined);
+    show_trace_profile_command_fn (vm, input, cmd);
+  }
+  else
+  {
+    vec_free(user_defined.opaque.data);
+    return clib_error_return (0, "%s", errstr);
+  }
+  return 0;
+}
+
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (set_trace_profile_command, static) =
+{
+.path = "set ioam-trace profile",
+.short_help = "set ioam-trace profile\n   Mandatory:\n      trace-type [as hex] namespace-id [n] num-elts [< 255] node-id-short [n > 0 (dec)] node-id-wide [n > 0x0 (hex)] queue-depth-type (if queue depth in trace-type) [drv-af-packet | drv-dpdk] node-type [encap | transit | decap]\n    Optional:\n     option-type [prealloc (default) | increment | pot | e2e] ts-format-sub [sec | ms | us | ns] app-data-short/-wide [in hex] opaque-len [n < 1020-bytes] opaque-id [n] opaque-data [hex]",
+.function = set_trace_profile_command_fn,
+};
 /*
  * fd.io coding-style-patch-verification: ON
  *
diff --git a/src/plugins/ioam/lib-trace/trace_util.h b/src/plugins/ioam/lib-trace/trace_util.h
index 61f18d917..151be35ed 100644
--- a/src/plugins/ioam/lib-trace/trace_util.h
+++ b/src/plugins/ioam/lib-trace/trace_util.h
@@ -14,13 +14,9 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-
-#ifndef include_vnet_trace_util_h
-#define include_vnet_trace_util_h
-
-#define debug_ioam debug_ioam_fn
-
-
+/*
+ * NOTE: This file utilizes IEFT IOAM DATA DRAFTE v10
+*/
 /**
  * Usage:
  *
@@ -37,215 +33,377 @@
  *         trace_validate
  *
  */
+#ifndef include_vnet_trace_util_h
+#define include_vnet_trace_util_h
 
-typedef struct trace_profile_
-{
-  u8 valid:1;
-  u8 trace_type;
-  u8 num_elts;
-  /* Configured node-id */
-  u32 node_id;
-  u32 app_data;
-  u32 trace_tsp;
-} trace_profile;
-
-typedef struct
-{
-  /* Name of the default profile list in use */
-  trace_profile profile;
-
-  /* API message ID base */
-  u16 msg_id_base;
-
-  /* convenience */
-  vlib_main_t *vlib_main;
-  vnet_main_t *vnet_main;
-} trace_main_t;
+#define debug_ioam debug_ioam_fn
 
+// Useful
+# define htonll64(x)    (((u64)htonl((x) & 0xFFFFFFFF) << 32) | htonl((x) >> 32))
+# define ntohll64(x)    (((u64)ntohl((x) & 0xFFFFFFFF) << 32) | ntohl((x) >> 32))
 
 /*
- * Initialize Trace profile
+ * Data-Field - Set of bits with a defined format and meaning, 4 categories
+ * Preallocated, Incremental, Proof of Transit, and Edge to Edge
  */
-int trace_util_init (void);
-
-
-/* setup and clean up profile */
-int trace_profile_create (trace_profile * profile, u8 trace_type, u8 num_elts,
-			  u32 trace_tsp, u32 node_id, u32 app_data);
-
-void clear_trace_profiles (void);
-
-/* *INDENT-OFF* */
-typedef CLIB_PACKED (struct
-{
-  u8 ioam_trace_type;
-  u8 data_list_elts_left;
-  u32 elts[0]; /* Variable type. So keep it generic */
-}) ioam_trace_hdr_t;
-/* *INDENT-ON* */
-
-
-
-#define    BIT_TTL_NODEID       (1<<0)
-#define    BIT_ING_INTERFACE    (1<<1)
-#define    BIT_EGR_INTERFACE    (1<<2)
-#define    BIT_TIMESTAMP        (1<<3)
-#define    BIT_APPDATA          (1<<4)
-#define    BIT_LOOPBACK         (1<<5)
-#define    BIT_LOOPBACK_REPLY   (1<<6)
-#define    TRACE_TYPE_MASK      0x7F	/* Mask of all above bits */
+/*
+ * Pre alloc - pre allocated space in packet for telemetry data
+ * Incremental - Node allocates and pushes telemetry data following option header
+ * PoT - Proof of transit
+ * E2E - Edge-to-Edge
+ * A nodes can use any of these simultaneously, incremental must precede prealloc
+ */
+#define IOAM_OPTION_PREALLOC    (1<<0)
+#define IOAM_OPTION_INCREMENT   (1<<1)
+#define IOAM_OPTION_POT         (1<<2)
+#define IOAM_OPTION_E2E         (1<<3)
+/*
+ * Node can only be one !
+ * Encapsulation node - A node that adds at least one iOAM option and/or iOAM data 
+ *                      as packet enters iOAM domain
+ * Transit node - Adds iOAM data within an iOAM domain based on the provided iOAM 
+ *                option type. DOES NOT add new or alter existing option types
+ * Decapsulation node - In charge of removing iOAM option type and data before 
+ *                      leaving iOAM domain
+*/
+#define IOAM_NODE_ENCAP     (1<<0)
+#define IOAM_NODE_TRANSIT   (1<<1)
+#define IOAM_NODE_DECAP     (1<<2)
 
-#define    TRACE_TYPE_IF_TS_APP_LOOP    0x3F
+#define IOAM_TSP_SECONDS       ((u8)0)
+#define IOAM_TSP_MILLISECONDS  ((u8)1)
+#define IOAM_TSP_MICROSECONDS  ((u8)2)
+#define IOAM_TSP_NANOSECONDS   ((u8)3)
+#define IOAM_TSP_OPTION_SIZE   ((u8)4)
 
 /*
-     0x00011111  iOAM-trace-type is 0x00011111 then the format of node
-        data is:
-
-          0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+ * Hop-by-hop extension
+           0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |   Hop_Lim     |              node_id                          |
+         |  Next Header  |  Hdr Ext Len  |      Options and Padding      |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |     ingress_if_id             |         egress_if_id          |
+         +       Options and Padding, but will be header below           +
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         +                           timestamp                           +
+ * iOAM Prealloc and Incremental Option Header
+           0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |                            app_data                           |
+         |          Namespace ID         |  NodeLen | Flags| RemainingLen|
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-
-*/
-#define   TRACE_TYPE_IF_TS_APP   0x1f
-typedef struct
-{
-  u32 ttl_node_id;
-  u16 ingress_if;
-  u16 egress_if;
-  u32 timestamp;
-  u32 app_data;
-} ioam_trace_if_ts_app_t;
-
-/*
-     0x00000111  iOAM-trace-type is 0x00000111 then the format is:
-
-          0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+         +                 iOAM Trace Type                |   Reserved   +
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |   Hop_Lim     |              node_id                          |
+         +                       Node Data List [0]                      +
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |     ingress_if_id             |         egress_if_id          |
+         +                              ...                              +
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-
-*/
-
-#define   TRACE_TYPE_IF   0x03
-typedef struct
-{
-  u32 ttl_node_id;
-  u16 ingress_if;
-  u16 egress_if;
-} ioam_trace_if_t;
-
-/*
-     0x00001001  iOAM-trace-type is 0x00001001 then the format is:
+         +                       Node Data List [n]                      +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+ * namespace_id (16-bit) - unique id which is used by the Encap, Tranist, and Decap nodes 
+ *             in order to identify what iOAM options/data to alter/add/remove etc.
+ *             Allows for a namespace specif interpretation of iOAM data fields.
+ *             A subset of all the iOAM option types and data fields are associated
+ *             with this ID. There exists two sub-ranges: Default is 0x0000
+ *              - Operator-assigned range from 0x0001 to 0x7FFF
+ *              - IANA-asigned range from 0x8000 to 0xFFFF
+ *             Nodes can work on several Namespace IDs
+ *
+ * node_len (5-bit) - specified the length of data added by each no in multiples of 4-octets,
+ *                    excluding the length of the "Opaque State Snapshot" field.
+ *                    Set by Encap.
+ *
+ *      If iOAM trace type bit 22 is clear, 
+ *          node_len specifies the actual length added by each node,
+ *      else, actual length added by each node is:
+ *          node_len + length of "Opaque State Snapshot" field in 4-octet units
+ *
+ * flags (4-bit) - in IANA, section 8.3 in Draft IETF IPPM iOAM data v10
+ *                 Bit 0 "Overflow" (MSB). set if Number of iOAM nodes to aggregate their telemetry
+ *                 data is greater than the PMTU.
+ *
+ * remaining_len (7-bit) - specifies the data space in multiples of 4-octets remaining for 
+ *      recording the node data, before the node data list is considered to have overflowed.
+ *      Can be set to MTU (PMTU) in order to compare with node_len how much space there is left.
+ *      In prealloc, this can be used as index for data array, = remaining_len - node_len 
+ *      
+ * trace_type (24-bit) - view bit definitions below,
+    iOAM-trace-type if above bits are set accordingly
+    the format of node header data is something like the following.
+    Short/Wide formats - use is not exclusive, so both can be used
 
           0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |   Hop_Lim     |              node_id                          |
+         |   Hop_Lim     |              node_id (short)                  |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         +                           timestamp                           +
+         |     ingress_if_id (short)       |     egress_if_id (short)    |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-
-*/
-
-#define   TRACE_TYPE_TS   0x09
-typedef struct
-{
-  u32 ttl_node_id;
-  u32 timestamp;
-} ioam_trace_ts_t;
-
-/*
-     0x00010001  iOAM-trace-type is 0x00010001 then the format is:
-
-
-          0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
+         +                       timestamp_sec                           +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         +                       timestamp_sub_sec                       +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         +0|                       transit delay                         +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                        app_data (short)                       |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                          queue_depth                          |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                       checksum_complement                     |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |   Hop_Lim     |              node_id                          |
+         |   Hop_Lim     |              node_id (wide)                  |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |                            app_data                           |
+         |                      node_id_cont (wide)                      |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         +                      ingress_if_id (wide)                     +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         +                      egress_if_id (wide)                      +
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                      app_data_cont (wide)                     |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                        buffer_occupancy                       |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         // opaue data length in 4 octets, max 255 * 4 = 1020 (bytes)
+         |     length    |               schema_id                       |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                           opaque_data                         |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                               ...                             |
+         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
+         |                           opaque_data                         |
          +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
 
+         Explaination of Trace Type data
+ *
+ * Reserved (8-bit) - Encap must set the value to 0s and ignored by transit nodes
+ *
+ * Node data list (variable length field) - data elements determined by trace type
+ *      Order of data followed Trace Type bit order (below). If node is not able to
+ *      populate the data field, it is filled with all 0xFs.
+ */
+ // Trace type instruction bitmap
+#define    IOAM_INSTR_BITMAP_MASK     0xFFF002
+// from pg 15
+#define    IOAM_BIT_TTL_NODEID_SHORT       (1<<23)
+#define    IOAM_BIT_ING_EGR_INT_SHORT      (1<<22)
+#define    IOAM_BIT_TIMESTAMP_SEC          (1<<21)
+#define    IOAM_BIT_TIMESTAMP_SUB_SEC      (1<<20)
+#define    IOAM_BIT_TRANSIT_DELAY          (1<<19)
+#define    IOAM_BIT_APPDATA_SHORT_DATA     (1<<18)
+#define    IOAM_BIT_QUEUE_DEPTH            (1<<17)
+#define    IOAM_BIT_CHECKSUM_COMPLEMENT    (1<<16)
+#define    IOAM_BIT_TTL_NODEID_WIDE        (1<<15)
+#define    IOAM_BIT_ING_EGR_INT_WIDE       (1<<14)
+#define    IOAM_BIT_APPDATA_WIDE_DATA      (1<<13)
+#define    IOAM_BIT_BUFFER_OCCUPANCY       (1<<12)
+/*12-21 are undefined, view pg 16, set to 0 */
+// variable length opaue state snapshot
+#define    IOAM_BIT_VAR_LEN_OP_ST_SNSH     (1<<1)
+// 23 is reserved, set to 0
+// Trace Flags
+#define IOAM_BIT_FLAG_OVERFLOW             (1<<7)
+#define IOAM_BIT_FLAG_LOOPBACK             (1<<8)
+#define IOAM_BIT_FLAG_LOOPBACK_REPLY       (1<<9)
+// For old iOAM Plugin
+#define BIT_LOOPBACK                        IOAM_BIT_FLAG_LOOPBACK
+
+// Trace overflow flag, but also used to indicate if we need to add transit delay
+#define IOAM_BIT_TRANSIT_DELAY_OVERFLOW    (1<<31)
+// Empty values
+#define IOAM_EMPTY_FIELD_U8      (0xFF)
+#define IOAM_EMPTY_FIELD_U16     (0xFFFF)
+#define IOAM_EMPTY_FIELD_U24     (0x00FFFFFF)
+#define IOAM_EMPTY_FIELD_U32     (0xFFFFFFFF)
+#define IOAM_EMPTY_FIELD_U56     (0x00FFFFFFFFFFFFFF)
+#define IOAM_EMPTY_FIELD_U64     (0xFFFFFFFFFFFFFFFF)
+
+#define IOAM_NAMESPACE_ID_MASK  ((u32)0xFFFF0000)
+#define IOAM_NODE_LEN_MASK      ((u16)0xF800)
+#define IOAM_FLAGS_MASK         ((u16)0x0780)
+#define IOAM_REMAIN_LEN_MASK    ((u16)0x0000007F)
+#define IOAM_SET_NODE_LEN(len)  ((u16)((len) << 11) & IOAM_NODE_LEN_MASK)
+#define IOAM_GET_NODE_LEN(n)    ((u16)((n) & IOAM_NODE_LEN_MASK) >> 11)
+#define IOAM_TRACE_TYPE_MASK    ((u32)0xFFFFFF00)
+#define IOAM_SET_TRACETYPE(tt)  ((u32)(clib_host_to_net_u32((tt & IOAM_INSTR_BITMAP_MASK) << 8)))
+#define IOAM_GET_TRACETYPE(tt)  ((u32)((clib_net_to_host_u32(tt) >> 8) & IOAM_INSTR_BITMAP_MASK))
+typedef CLIB_PACKED (struct ioam_trace_hdr_ {
+     u16 namespace_id;
+     u16 node_len_flags_remaining_len;
+     u32 trace_type; // only 24-bits, last 8 is for reserved(=0)
+     u32 data_list[0];
+ }) ioam_trace_hdr_t;
+
+#define IOAM_MAX_OPAQUE_DATA_WORD_SIZE        ((u8)255)
+#define IOAM_MAX_OPAQUE_DATA_BYTE_SIZE        ((u16)(IOAM_MAX_OPAQUE_DATA_WORD_SIZE<<2))
+#define IOAM_OPAQUE_LEN_MASK                  ((u32)0xFF000000)
+#define IOAM_OPAQUE_SCHEMEID_MASK             ((u32)0x00FFFFFF)
+#define IOAM_GET_OPAQUE_LEN(b)                ((u8)(((IOAM_OPAQUE_LEN_MASK & (b)) >> 24)))
+#define IOAM_SET_OPAQUE_HEADER(len,schemaid)  ((u32)((((len) << 24) & IOAM_OPAQUE_LEN_MASK) | (schemaid & IOAM_OPAQUE_SCHEMEID_MASK)))
+// Max data each node can add, minus opaque (60 bytes)
+#define IOAM_MAX_DATA_NO_OPAQUE               ((u8)60)
+// Max data per node with opaque = 1084-bytes max, +4 due to opaque header
+#define IOAM_MAX_DATA_W_OPAQUE                ((u16)(IOAM_MAX_DATA_NO_OPAQUE + 4 + IOAM_MAX_OPAQUE_DATA_BYTE_SIZE))
+typedef CLIB_PACKED (struct opaque_scheme_ {
+     u32 len_schemeid;
+     u32 *data;
+ }) opaque_scheme_t;
+
+// Queue depth type for device driver
+#define QUEUE_DEPTH_AF_PACKET   (1<<0)
+#define QUEUE_DEPTH_DPDK        (1<<1)
+// These below are not implemented
+/*
+#define QUEUE_DEPTH_PIPE        (1<<2)
+#define QUEUE_DEPTH_TUNTAP      (1<<3)
+#define QUEUE_DEPTH_VIRTIO      (1<<4)
+#define QUEUE_DEPTH_NETLINK     (1<<5)
 */
+/*
+ * User sets these values to setup the trace profile
+*/
+ typedef struct trace_profile_ {
+    u8 valid:1;
+    u16 namespace_id;
+    u8 num_elts;
+    u32 node_id_short;
+    u64 node_id_wide;
+    u32 app_data_short;
+    u64 app_data_wide;
+    u8 option_type;
+    u32 trace_type;
+    u8 node_type;
+    u8 ts_format;
+    u8 queue_depth_type;
+    opaque_scheme_t opaque;
+ } trace_profile;
 
-
-#define   TRACE_TYPE_APP   0x11
 typedef struct
 {
-  u32 ttl_node_id;
-  u32 app_data;
-} ioam_trace_app_t;
+  /* Name of the default profile list in use */
+  trace_profile profile;
+
+  /* API message ID base */
+  u16 msg_id_base;
 
+  /* convenience */
+  vlib_main_t *vlib_main;
+  vnet_main_t *vnet_main;
+} trace_main_t;
+ 
 /*
+ * Initialize Trace profile
+ */
+int trace_util_init (void);
 
-     0x00011001  iOAM-trace-type is 0x00011001 then the format is:
+/* setup and clean up profile */
+int trace_profile_create (trace_profile * profile, trace_profile *user_defined);
 
-          0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
-         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |   Hop_Lim     |              node_id                          |
-         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         +                           timestamp                           +
-         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-         |                            app_data                           |
-         +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
-*/
+void clear_trace_profiles (void);
 
-#define   TRACE_TYPE_TS_APP   0x19
-typedef struct
+// Defined as 24-bit
+static inline u32
+fetch_trace_data_size (trace_profile * profile)
 {
-  u32 ttl_node_id;
-  u32 timestamp;
-  u32 app_data;
-} ioam_trace_ts_app_t;
+  u32 trace_data_size = 0;
+  u32 trace_type = profile->trace_type;
+
+  if(trace_type & IOAM_BIT_TTL_NODEID_SHORT ) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_ING_EGR_INT_SHORT) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_TIMESTAMP_SEC) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_TIMESTAMP_SUB_SEC) 
+  {
+      trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_TRANSIT_DELAY) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_APPDATA_SHORT_DATA) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_QUEUE_DEPTH) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_CHECKSUM_COMPLEMENT) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_TTL_NODEID_WIDE) 
+  {
+      trace_data_size += 8;
+  }
+  if(trace_type & IOAM_BIT_ING_EGR_INT_WIDE) 
+  {
+      trace_data_size += 8;
+  }
+  if(trace_type & IOAM_BIT_APPDATA_WIDE_DATA) 
+  {
+    trace_data_size += 8;
+  }
+  if(trace_type & IOAM_BIT_BUFFER_OCCUPANCY) 
+  {
+    trace_data_size += 4;
+  }
+  if(trace_type & IOAM_BIT_VAR_LEN_OP_ST_SNSH)
+  {
+    trace_data_size += 4; // for opaque header, data is variable length but max 255*4 bytes
+    trace_data_size += IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid) << 2;
+  }
+  return trace_data_size;
+}
 
-static inline u8
-fetch_trace_data_size (u16 trace_type)
+always_inline void
+ioam_tracetype_set_bit (ioam_trace_hdr_t * trace_hdr, u32 trace_bit)
 {
-  u8 trace_data_size = 0;
-
-  if ((trace_type & TRACE_TYPE_IF_TS_APP) == TRACE_TYPE_IF_TS_APP)
-    trace_data_size = sizeof (ioam_trace_if_ts_app_t);
-  else if ((trace_type & TRACE_TYPE_IF) == TRACE_TYPE_IF)
-    trace_data_size = sizeof (ioam_trace_if_t);
-  else if ((trace_type & TRACE_TYPE_TS) == TRACE_TYPE_TS)
-    trace_data_size = sizeof (ioam_trace_ts_t);
-  else if ((trace_type & TRACE_TYPE_APP) == TRACE_TYPE_APP)
-    trace_data_size = sizeof (ioam_trace_app_t);
-  else if ((trace_type & TRACE_TYPE_TS_APP) == TRACE_TYPE_TS_APP)
-    trace_data_size = sizeof (ioam_trace_ts_app_t);
+  trace_hdr->trace_type |= clib_host_to_net_u32(trace_bit);
+}
 
-  return trace_data_size;
+always_inline void
+ioam_tracetype_reset_bit (ioam_trace_hdr_t * trace_hdr, u32 trace_bit)
+{
+  trace_hdr->trace_type &= clib_host_to_net_u32(~trace_bit);
 }
 
 always_inline void
-ioam_trace_set_bit (ioam_trace_hdr_t * trace_hdr, u8 trace_bit)
+ioam_traceflag_set_bit (ioam_trace_hdr_t * trace_hdr, u16 flag_bit)
 {
-  trace_hdr->ioam_trace_type |= trace_bit;
+  trace_hdr->node_len_flags_remaining_len |= clib_host_to_net_u16(flag_bit);
 }
 
 always_inline void
-ioam_trace_reset_bit (ioam_trace_hdr_t * trace_hdr, u8 trace_bit)
+ioam_traceflag_reset_bit (ioam_trace_hdr_t * trace_hdr, u16 flag_bit)
+{
+  trace_hdr->node_len_flags_remaining_len &= clib_host_to_net_u16(~flag_bit);
+}
+static inline void
+ioam_print_profile(trace_profile *profile)
 {
-  trace_hdr->ioam_trace_type &= (~trace_bit);
+  if(profile)
+  {
+    vlib_cli_output(vlib_get_main(), "iOAM Profile:\n");
+    vlib_cli_output(vlib_get_main(),
+    " - namespace-id %d\n - num-elts %d\n - node-id-short %d\n - app-data-short 0x%x\n - node-id-wide %Ld\n - app-data-wide 0x%Lx\n - option-type %d\n - trace-type 0x%x\n - node-type %d\n - ts-format-sub %d\n - opaque-len %d\n - opaque-id %d\n", 
+    profile->namespace_id, profile->num_elts, profile->node_id_short, profile->app_data_short, profile->node_id_wide, profile->app_data_wide, profile->option_type, profile->trace_type, profile->node_type, profile->ts_format, IOAM_GET_OPAQUE_LEN(profile->opaque.len_schemeid) << 2, IOAM_OPAQUE_SCHEMEID_MASK & profile->opaque.len_schemeid);
+  }
+  else
+  {
+    vlib_cli_output(vlib_get_main(), "No iOAM Profile to print.\n");
+  }
 }
 
 int ioam_trace_get_sizeof_handler (u32 * result);
 int ip6_trace_profile_setup (void);
 int ip6_trace_profile_cleanup (void);
 
-#define TSP_SECONDS              0
-#define TSP_MILLISECONDS         1
-#define TSP_MICROSECONDS         2
-#define TSP_NANOSECONDS          3
 
-#endif
+#endif /* include_vnet_trace_util_h */
 
 /*
  * fd.io coding-style-patch-verification: ON
diff --git a/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam.h b/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam.h
index 0711b87ab..7c451ec69 100644
--- a/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam.h
+++ b/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam.h
@@ -58,11 +58,6 @@ typedef struct vxlan_gpe_ioam_main_
 #define PPC_DECAP 2
   u8 has_ppc_option;
 
-#define TSP_SECONDS              0
-#define TSP_MILLISECONDS         1
-#define TSP_MICROSECONDS         2
-#define TSP_NANOSECONDS          3
-
   /* Array of function pointers to ADD and POP VxLAN-GPE iOAM option handling routines */
   u8 options_size[256];
   int (*add_options[256]) (u8 * rewrite_string, u8 * rewrite_size);
diff --git a/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam_trace.c b/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam_trace.c
index 1a3705939..cf7e445dd 100644
--- a/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam_trace.c
+++ b/src/plugins/ioam/lib-vxlan-gpe/vxlan_gpe_ioam_trace.c
@@ -14,6 +14,7 @@
  */
 #include <vlib/vlib.h>
 #include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
 #include <vppinfra/error.h>
 
 #include <vnet/vxlan-gpe/vxlan_gpe.h>
@@ -119,11 +120,11 @@ vxlan_gpe_add_unregister_option (u8 option)
 
 int
 vxlan_gpe_ioam_register_option (u8 option,
-				int options (vlib_buffer_t * b,
-					     vxlan_gpe_ioam_option_t * opt,
-					     u8 is_ipv4, u8 use_adj),
-				u8 * trace (u8 * s,
-					    vxlan_gpe_ioam_option_t * opt))
+                                int options (vlib_buffer_t * b,
+                                vxlan_gpe_ioam_option_t * opt,
+                                u8 is_ipv4, u8 use_adj),
+                                u8 * trace (u8 * s,
+                                vxlan_gpe_ioam_option_t * opt))
 {
   vxlan_gpe_ioam_main_t *im = &vxlan_gpe_ioam_main;
 
@@ -174,39 +175,38 @@ format_ioam_data_list_element (u8 * s, va_list * args)
   u8 *trace_type_p = va_arg (*args, u8 *);
   u8 trace_type = *trace_type_p;
 
-
-  if (trace_type & BIT_TTL_NODEID)
-    {
-      u32 ttl_node_id_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ttl 0x%x node id 0x%x ",
-		  ttl_node_id_host_byte_order >> 24,
-		  ttl_node_id_host_byte_order & 0x00FFFFFF);
-
-      elt++;
-    }
-
-  if (trace_type & BIT_ING_INTERFACE && trace_type & BIT_ING_INTERFACE)
-    {
-      u32 ingress_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ingress 0x%x egress 0x%x ",
-		  ingress_host_byte_order >> 16,
-		  ingress_host_byte_order & 0xFFFF);
-      elt++;
-    }
-
-  if (trace_type & BIT_TIMESTAMP)
-    {
-      u32 ts_in_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "ts 0x%x \n", ts_in_host_byte_order);
-      elt++;
-    }
-
-  if (trace_type & BIT_APPDATA)
-    {
-      u32 appdata_in_host_byte_order = clib_net_to_host_u32 (*elt);
-      s = format (s, "app 0x%x ", appdata_in_host_byte_order);
-      elt++;
-    }
+  if (trace_type & IOAM_BIT_TTL_NODEID_SHORT)
+  {
+    u32 ttl_node_id_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ttl 0x%x node id 0x%x ",
+    ttl_node_id_host_byte_order >> 24,
+    ttl_node_id_host_byte_order & 0x00FFFFFF);
+
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
+  {
+    u32 ingress_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ingress 0x%x egress 0x%x ",
+    ingress_host_byte_order >> 16,
+    ingress_host_byte_order & 0xFFFF);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_TIMESTAMP_SEC)
+  {
+    u32 ts_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ts 0x%x \n", ts_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
+  {
+    u32 appdata_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "app 0x%x ", appdata_in_host_byte_order);
+    elt++;
+  }
 
   return s;
 }
@@ -217,7 +217,7 @@ int
 vxlan_gpe_ioam_trace_rewrite_handler (u8 * rewrite_string, u8 * rewrite_size)
 {
   vxlan_gpe_ioam_trace_option_t *trace_option = NULL;
-  u8 trace_data_size = 0;
+  u32 trace_data_size = 0;
   u8 trace_option_elts = 0;
   trace_profile *profile = NULL;
 
@@ -233,12 +233,12 @@ vxlan_gpe_ioam_trace_rewrite_handler (u8 * rewrite_string, u8 * rewrite_size)
     return -1;
 
   trace_option_elts = profile->num_elts;
-  trace_data_size = fetch_trace_data_size (profile->trace_type);
+  trace_data_size = fetch_trace_data_size (profile);
   trace_option = (vxlan_gpe_ioam_trace_option_t *) rewrite_string;
   trace_option->hdr.type = VXLAN_GPE_OPTION_TYPE_IOAM_TRACE;
   trace_option->hdr.length = 2 /*ioam_trace_type,data_list_elts_left */  +
-    trace_option_elts * trace_data_size;
-  trace_option->ioam_trace_type = profile->trace_type & TRACE_TYPE_MASK;
+                            trace_option_elts * trace_data_size;
+  trace_option->ioam_trace_type = profile->trace_type & IOAM_INSTR_BITMAP_MASK;
   trace_option->data_list_elts_left = trace_option_elts;
   *rewrite_size =
     sizeof (vxlan_gpe_ioam_trace_option_t) +
@@ -250,11 +250,11 @@ vxlan_gpe_ioam_trace_rewrite_handler (u8 * rewrite_string, u8 * rewrite_size)
 
 int
 vxlan_gpe_ioam_trace_data_list_handler (vlib_buffer_t * b,
-					vxlan_gpe_ioam_option_t * opt,
-					u8 is_ipv4, u8 use_adj)
+                                        vxlan_gpe_ioam_option_t * opt,
+                                        u8 is_ipv4, u8 use_adj)
 {
   u8 elt_index = 0;
-  vxlan_gpe_ioam_trace_option_t *trace =
+  vxlan_gpe_ioam_trace_option_t *trace = 
     (vxlan_gpe_ioam_trace_option_t *) opt;
   time_u64_t time_u64;
   u32 *elt;
@@ -274,18 +274,17 @@ vxlan_gpe_ioam_trace_data_list_handler (vlib_buffer_t * b,
   time_u64.as_u64 = 0;
 
   if (PREDICT_TRUE (trace->data_list_elts_left))
-    {
-      trace->data_list_elts_left--;
-      /* fetch_trace_data_size returns in bytes. Convert it to 4-bytes
-       * to skip to this node's location.
-       */
-      elt_index =
-	trace->data_list_elts_left *
-	fetch_trace_data_size (trace->ioam_trace_type) / 4;
-      elt = &trace->elts[elt_index];
-      if (is_ipv4)
-	{
-	  if (trace->ioam_trace_type & BIT_TTL_NODEID)
+  {
+    trace->data_list_elts_left--;
+    /* fetch_trace_data_size returns in bytes. Convert it to 4-bytes
+      * to skip to this node's location.
+    */
+    elt_index = 
+      trace->data_list_elts_left * fetch_trace_data_size (profile) / 4;
+    elt = &trace->elts[elt_index];
+    if (is_ipv4)
+	  {
+	    if (trace->ioam_trace_type & IOAM_BIT_TTL_NODEID_SHORT)
 	    {
 	      ip4_header_t *ip0 = vlib_buffer_get_current (b);
 	      /* The transit case is the only case where the TTL decrement happens
@@ -293,82 +292,82 @@ vxlan_gpe_ioam_trace_data_list_handler (vlib_buffer_t * b,
 	       * We can probably use a separate flag instead of overloading the use_adj flag.
 	       */
 	      *elt = clib_host_to_net_u32 (((ip0->ttl - 1 + use_adj) << 24) |
-					   profile->node_id);
-	      elt++;
+					   profile->node_id_short);
+        elt++;
 	    }
 
-	  if (trace->ioam_trace_type & BIT_ING_INTERFACE)
+	    if (trace->ioam_trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
 	    {
 	      u16 tx_if = 0;
 	      u32 adj_index = vnet_buffer (b)->ip.adj_index[VLIB_TX];
 
 	      if (use_adj)
-		{
-		  ip_adjacency_t *adj = adj_get (adj_index);
-		  tx_if = adj->rewrite_header.sw_if_index & 0xFFFF;
-		}
+        {
+          ip_adjacency_t *adj = adj_get (adj_index);
+          tx_if = adj->rewrite_header.sw_if_index & 0xFFFF;
+        }
 
 	      *elt =
 		(vnet_buffer (b)->sw_if_index[VLIB_RX] & 0xFFFF) << 16 |
 		tx_if;
-	      *elt = clib_host_to_net_u32 (*elt);
+    *elt = clib_host_to_net_u32 (*elt);
 	      elt++;
 	    }
-	}
-      else
-	{
-	  if (trace->ioam_trace_type & BIT_TTL_NODEID)
+	  }
+    else
+	  {
+	    if (trace->ioam_trace_type & IOAM_BIT_TTL_NODEID_SHORT)
 	    {
 	      ip6_header_t *ip0 = vlib_buffer_get_current (b);
 	      *elt = clib_host_to_net_u32 ((ip0->hop_limit << 24) |
-					   profile->node_id);
-	      elt++;
+					   profile->node_id_short);
+        elt++;
 	    }
-	  if (trace->ioam_trace_type & BIT_ING_INTERFACE)
+	    if (trace->ioam_trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
 	    {
 	      u16 tx_if = 0;
 	      u32 adj_index = vnet_buffer (b)->ip.adj_index[VLIB_TX];
 
-	      if (use_adj)
-		{
-		  ip_adjacency_t *adj = adj_get (adj_index);
-		  tx_if = adj->rewrite_header.sw_if_index & 0xFFFF;
-		}
+        if (use_adj)
+        {
+          ip_adjacency_t *adj = adj_get (adj_index);
+          tx_if = adj->rewrite_header.sw_if_index & 0xFFFF;
+        }
 
 	      *elt =
 		(vnet_buffer (b)->sw_if_index[VLIB_RX] & 0xFFFF) << 16 |
 		tx_if;
-	      *elt = clib_host_to_net_u32 (*elt);
+        *elt = clib_host_to_net_u32 (*elt);
 	      elt++;
 	    }
-	}
-
-      if (trace->ioam_trace_type & BIT_TIMESTAMP)
-	{
-	  /* Send least significant 32 bits */
-	  f64 time_f64 =
-	    (f64) (((f64) hm->unix_time_0) +
-		   (vlib_time_now (hm->vlib_main) - hm->vlib_time_0));
-
-	  time_u64.as_u64 = time_f64 * trace_tsp_mul[profile->trace_tsp];
-	  *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
-	  elt++;
-	}
-
-      if (trace->ioam_trace_type & BIT_APPDATA)
-	{
-	  /* $$$ set elt0->app_data */
-	  *elt = clib_host_to_net_u32 (profile->app_data);
-	  elt++;
-	}
-      vxlan_gpe_ioam_trace_stats_increment_counter
-	(VXLAN_GPE_IOAM_TRACE_SUCCESS, 1);
+	  }
+
+    if (trace->ioam_trace_type & IOAM_BIT_TIMESTAMP_SEC)
+    {
+      /* Send least significant 32 bits */
+      f64 time_f64 =
+        (f64) (((f64) hm->unix_time_0) +
+        (vlib_time_now (hm->vlib_main) - hm->vlib_time_0));
+
+      time_u64.as_u64 = time_f64 * trace_tsp_mul[profile->ts_format];
+      *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
+      elt++;
     }
-  else
+
+    if (trace->ioam_trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
     {
+      /* $$$ set elt0->app_data */
+      *elt = clib_host_to_net_u32 (profile->app_data_short);
+      elt++;
+    }
       vxlan_gpe_ioam_trace_stats_increment_counter
-	(VXLAN_GPE_IOAM_TRACE_FAILED, 1);
+	      (VXLAN_GPE_IOAM_TRACE_SUCCESS, 1);
     }
+  else
+  {
+    vxlan_gpe_ioam_trace_stats_increment_counter
+	    (VXLAN_GPE_IOAM_TRACE_FAILED, 1);
+  }
   return (rv);
 }
 
@@ -377,7 +376,7 @@ vxlan_gpe_ioam_trace_data_list_trace_handler (u8 * s,
 					      vxlan_gpe_ioam_option_t * opt)
 {
   vxlan_gpe_ioam_trace_option_t *trace;
-  u8 trace_data_size_in_words = 0;
+  u32 trace_data_size_in_words = 0;
   u32 *elt;
   int elt_index = 0;
 
@@ -386,35 +385,35 @@ vxlan_gpe_ioam_trace_data_list_trace_handler (u8 * s,
     format (s, "  Trace Type 0x%x , %d elts left\n", trace->ioam_trace_type,
 	    trace->data_list_elts_left);
   trace_data_size_in_words =
-    fetch_trace_data_size (trace->ioam_trace_type) / 4;
+    fetch_trace_data_size (trace_profile_find()) / 4;
   elt = &trace->elts[0];
   while ((u8 *) elt < ((u8 *) (&trace->elts[0]) + trace->hdr.length - 2
 		       /* -2 accounts for ioam_trace_type,elts_left */ ))
-    {
-      s = format (s, "    [%d] %U\n", elt_index,
-		  format_ioam_data_list_element,
-		  elt, &trace->ioam_trace_type);
-      elt_index++;
-      elt += trace_data_size_in_words;
-    }
+  {
+    s = format (s, "    [%d] %U\n", elt_index,
+    format_ioam_data_list_element,
+    elt, &trace->ioam_trace_type);
+    elt_index++;
+    elt += trace_data_size_in_words;
+  }
   return (s);
 }
 
 
 static clib_error_t *
 vxlan_gpe_show_ioam_trace_cmd_fn (vlib_main_t * vm,
-				  unformat_input_t * input,
-				  vlib_cli_command_t * cmd)
+                                  unformat_input_t * input,
+                                  vlib_cli_command_t * cmd)
 {
   vxlan_gpe_ioam_trace_main_t *hm = &vxlan_gpe_ioam_trace_main;
   u8 *s = 0;
   int i = 0;
 
   for (i = 0; i < VXLAN_GPE_IOAM_TRACE_N_STATS; i++)
-    {
-      s = format (s, " %s - %lu\n", vxlan_gpe_ioam_trace_stats_strings[i],
-		  hm->counters[i]);
-    }
+  {
+    s = format (s, " %s - %lu\n", vxlan_gpe_ioam_trace_stats_strings[i],
+    hm->counters[i]);
+  }
 
   vlib_cli_output (vm, "%v", s);
   vec_free (s);
@@ -483,7 +482,7 @@ static int
 vxlan_gpe_ioam_trace_get_sizeof_handler (u32 * result)
 {
   u16 size = 0;
-  u8 trace_data_size = 0;
+  u32 trace_data_size = 0;
   trace_profile *profile = NULL;
 
   *result = 0;
@@ -491,11 +490,11 @@ vxlan_gpe_ioam_trace_get_sizeof_handler (u32 * result)
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      return (-1);
-    }
+  {
+    return (-1);
+  }
 
-  trace_data_size = fetch_trace_data_size (profile->trace_type);
+  trace_data_size = fetch_trace_data_size (profile);
   if (PREDICT_FALSE (trace_data_size == 0))
     return VNET_API_ERROR_INVALID_VALUE;
 
@@ -523,9 +522,9 @@ vxlan_gpe_trace_profile_setup (void)
   profile = trace_profile_find ();
 
   if (PREDICT_FALSE (!profile))
-    {
-      return (-1);
-    }
+  {
+    return (-1);
+  }
 
 
   if (vxlan_gpe_ioam_trace_get_sizeof_handler (&trace_size) < 0)
diff --git a/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam.h b/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam.h
new file mode 100644
index 000000000..6652621b5
--- /dev/null
+++ b/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam.h
@@ -0,0 +1,114 @@
+/*
+ * Copyright (c) 2017 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef __included_nsh_md2_ioam_h__
+#define __included_nsh_md2_ioam_h__
+
+#include <nsh/nsh.h>
+#include <nsh/nsh_packet.h>
+#include <vnet/ip/ip.h>
+#include <vnet/ip/ip4_packet.h>
+#include <vnet/ip/ip6_packet.h>
+
+
+typedef struct nsh_md2_ioam_sw_interface_
+{
+  u32 sw_if_index;
+} nsh_md2_ioam_sw_interface_t;
+
+typedef struct nsh_md2_ioam_dest_tunnels_
+{
+  ip46_address_t dst_addr;
+  u32 fp_proto;
+  u32 sibling_index;
+  fib_node_index_t fib_entry_index;
+  u32 outer_fib_index;
+} nsh_md2_ioam_dest_tunnels_t;
+
+typedef struct nsh_md2_ioam_main_
+{
+  /**
+   * Linkage into the FIB object graph
+   */
+  fib_node_t node;
+
+  /* time scale transform. Joy. */
+  u32 unix_time_0;
+  f64 vlib_time_0;
+
+
+  /* Trace option */
+  u8 has_trace_option;
+
+  /* Pot option */
+  u8 has_pot_option;
+
+#define PPC_NONE  0
+#define PPC_ENCAP 1
+#define PPC_DECAP 2
+  u8 has_ppc_option;
+
+
+  /* API message ID base */
+  u16 msg_id_base;
+
+  /* Override to export for iOAM */
+  uword decap_v4_next_override;
+  uword decap_v6_next_override;
+
+  /* sequence of node graph for encap */
+  uword encap_v4_next_node;
+  uword encap_v6_next_node;
+
+  /* Software interfaces. */
+  nsh_md2_ioam_sw_interface_t *sw_interfaces;
+
+  /* hash ip4/ip6 -> list of destinations for doing transit iOAM operation */
+  nsh_md2_ioam_dest_tunnels_t *dst_tunnels;
+  uword *dst_by_ip4;
+  uword *dst_by_ip6;
+
+  /** per sw_if_index, to maintain bitmap */
+  u8 *bool_ref_by_sw_if_index;
+  fib_node_type_t fib_entry_type;
+
+
+} nsh_md2_ioam_main_t;
+extern nsh_md2_ioam_main_t nsh_md2_ioam_main;
+
+/*
+ * Primary h-b-h handler trace support
+ */
+typedef struct
+{
+  u32 next_index;
+  u32 trace_len;
+  u8 option_data[256];
+} ioam_trace_t;
+
+
+clib_error_t *nsh_md2_ioam_enable_disable (int has_trace_option,
+						int has_pot_option,
+						int has_ppc_option);
+
+
+
+int nsh_md2_ioam_trace_profile_setup (void);
+
+int nsh_md2_ioam_trace_profile_cleanup (void);
+extern void nsh_md2_ioam_interface_init (void);
+
+
+
+#endif
diff --git a/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam_trace.c b/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam_trace.c
new file mode 100644
index 000000000..5274d483b
--- /dev/null
+++ b/src/plugins/ioam/nsh-md2-ioam/nsh_md2_ioam_trace.c
@@ -0,0 +1,461 @@
+/*
+ * Copyright (c) 2017 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#include <vlib/vlib.h>
+#include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
+#include <vppinfra/error.h>
+
+#include <vppinfra/hash.h>
+#include <vppinfra/error.h>
+#include <vppinfra/elog.h>
+
+#include <ioam/lib-trace/trace_util.h>
+#include <nsh/nsh-md2-ioam/nsh_md2_ioam.h>
+#include <nsh/nsh_packet.h>
+
+/* Timestamp precision multipliers for seconds, milliseconds, microseconds
+ * and nanoseconds respectively.
+ */
+static f64 trace_tsp_mul[4] = { 1, 1e3, 1e6, 1e9 };
+
+#define NSH_MD2_IOAM_TRACE_SIZE_DUMMY 20
+
+typedef union
+{
+  u64 as_u64;
+  u32 as_u32[2];
+} time_u64_t;
+
+
+/* *INDENT-OFF* */
+typedef CLIB_PACKED(struct {
+  u16 class;
+  u8 type;
+  u8 length;
+  u8 data_list_elts_left;
+  u32 ioam_trace_type;
+  u8 reserve;
+  u32 elts[0]; /* Variable type. So keep it generic */
+}) nsh_md2_ioam_trace_option_t;
+/* *INDENT-ON* */
+
+
+#define foreach_nsh_md2_ioam_trace_stats				\
+  _(SUCCESS, "Pkts updated with TRACE records")					\
+  _(FAILED, "Errors in TRACE due to lack of TRACE records")
+
+static char *nsh_md2_ioam_trace_stats_strings[] = {
+#define _(sym,string) string,
+  foreach_nsh_md2_ioam_trace_stats
+#undef _
+};
+
+typedef enum
+{
+#define _(sym,str) NSH_MD2_IOAM_TRACE_##sym,
+  foreach_nsh_md2_ioam_trace_stats
+#undef _
+    NSH_MD2_IOAM_TRACE_N_STATS,
+} nsh_md2_ioam_trace_stats_t;
+
+
+typedef struct
+{
+  /* stats */
+  u64 counters[ARRAY_LEN (nsh_md2_ioam_trace_stats_strings)];
+
+  /* convenience */
+  vlib_main_t *vlib_main;
+  vnet_main_t *vnet_main;
+} nsh_md2_ioam_trace_main_t;
+
+nsh_md2_ioam_trace_main_t nsh_md2_ioam_trace_main;
+
+/*
+ * Find a trace profile
+ */
+
+extern u8 *nsh_trace_main;
+always_inline trace_profile *
+nsh_trace_profile_find (void)
+{
+  trace_main_t *sm = (trace_main_t *) nsh_trace_main;
+
+  return (&(sm->profile));
+}
+
+
+always_inline void
+nsh_md2_ioam_trace_stats_increment_counter (u32 counter_index, u64 increment)
+{
+  nsh_md2_ioam_trace_main_t *hm = &nsh_md2_ioam_trace_main;
+
+  hm->counters[counter_index] += increment;
+}
+
+
+static u8 *
+format_ioam_data_list_element (u8 * s, va_list * args)
+{
+  u32 *elt = va_arg (*args, u32 *);
+  u8 *trace_type_p = va_arg (*args, u8 *);
+  u8 trace_type = *trace_type_p;
+
+  if (trace_type & IOAM_BIT_TTL_NODEID_SHORT)
+  {
+    u32 ttl_node_id_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ttl 0x%x node id 0x%x ",
+    ttl_node_id_host_byte_order >> 24,
+    ttl_node_id_host_byte_order & 0x00FFFFFF);
+
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
+  {
+    u32 ingress_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ingress 0x%x egress 0x%x ",
+    ingress_host_byte_order >> 16,
+    ingress_host_byte_order & 0xFFFF);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_TIMESTAMP_SEC)
+  {
+    u32 ts_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "ts 0x%x \n", ts_in_host_byte_order);
+    elt++;
+  }
+
+  if (trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
+  {
+    u32 appdata_in_host_byte_order = clib_net_to_host_u32 (*elt);
+    s = format (s, "app 0x%x ", appdata_in_host_byte_order);
+    elt++;
+  }
+
+  return s;
+}
+
+
+
+int
+nsh_md2_ioam_trace_rewrite_handler (u8 * rewrite_string, u8 * rewrite_size)
+{
+  nsh_md2_ioam_trace_option_t *trace_option = NULL;
+  u32 trace_data_size = 0;
+  u8 trace_option_elts = 0;
+  trace_profile *profile = NULL;
+
+  profile = nsh_trace_profile_find ();
+
+  if (PREDICT_FALSE (!profile))
+  {
+    return (-1);
+  }
+
+  if (PREDICT_FALSE (!rewrite_string))
+    return -1;
+
+  trace_option_elts = profile->num_elts;
+  trace_data_size = fetch_trace_data_size (profile);
+
+  trace_option = (nsh_md2_ioam_trace_option_t *) rewrite_string;
+  trace_option->class = clib_host_to_net_u16 (0x9);
+  trace_option->type = NSH_MD2_IOAM_OPTION_TYPE_TRACE;
+  trace_option->length = (trace_option_elts * trace_data_size) + 4;
+  trace_option->data_list_elts_left = trace_option_elts;
+  trace_option->ioam_trace_type = 
+        clib_host_to_net_u16 (profile->trace_type & IOAM_INSTR_BITMAP_MASK);
+
+  *rewrite_size =
+    sizeof (nsh_md2_ioam_trace_option_t) +
+    (trace_option_elts * trace_data_size);
+
+  return 0;
+}
+
+
+int
+nsh_md2_ioam_trace_data_list_handler (vlib_buffer_t * b,
+				      nsh_tlv_header_t * opt)
+{
+  u8 elt_index = 0;
+  nsh_md2_ioam_trace_option_t *trace =
+    (nsh_md2_ioam_trace_option_t *) ((u8 *) opt);
+  time_u64_t time_u64;
+  u32 *elt;
+  int rv = 0;
+  trace_profile *profile = NULL;
+  nsh_md2_ioam_main_t *hm = &nsh_md2_ioam_main;
+  nsh_main_t *gm = &nsh_main;
+  u32 ioam_trace_type = 0;
+
+  profile = nsh_trace_profile_find ();
+
+  if (PREDICT_FALSE (!profile))
+  {
+    return (-1);
+  }
+
+
+  ioam_trace_type = profile->trace_type & IOAM_INSTR_BITMAP_MASK;
+  time_u64.as_u64 = 0;
+
+  if (PREDICT_TRUE (trace->data_list_elts_left))
+  {
+    trace->data_list_elts_left--;
+    /* fetch_trace_data_size returns in bytes. Convert it to 4-bytes
+      * to skip to this node's location.
+      */
+    elt_index =
+    trace->data_list_elts_left *
+    fetch_trace_data_size (profile) / 4;
+        elt = &trace->elts[elt_index];
+        if (ioam_trace_type & IOAM_BIT_TTL_NODEID_SHORT)
+    {
+      ip4_header_t *ip0 = vlib_buffer_get_current (b);
+      *elt = clib_host_to_net_u32 (((ip0->ttl - 1) << 24) |
+                profile->node_id_short);
+      elt++;
+    }
+
+    if (ioam_trace_type & IOAM_BIT_ING_EGR_INT_SHORT)
+    {
+      u16 tx_if = vnet_buffer (b)->sw_if_index[VLIB_TX];
+
+      *elt =
+        (vnet_buffer (b)->sw_if_index[VLIB_RX] & 0xFFFF) << 16 | tx_if;
+      *elt = clib_host_to_net_u32 (*elt);
+      elt++;
+    }
+
+
+    if (ioam_trace_type & IOAM_BIT_TIMESTAMP_SEC)
+    {
+      /* Send least significant 32 bits */
+      f64 time_f64 =
+        (f64) (((f64) hm->unix_time_0) +
+        (vlib_time_now (gm->vlib_main) - hm->vlib_time_0));
+
+      time_u64.as_u64 = time_f64 * trace_tsp_mul[profile->ts_format];
+      *elt = clib_host_to_net_u32 (time_u64.as_u32[0]);
+      elt++;
+    }
+
+    if (ioam_trace_type & IOAM_BIT_APPDATA_SHORT_DATA)
+    {
+      /* $$$ set elt0->app_data */
+      *elt = clib_host_to_net_u32 (profile->app_data_short);
+      elt++;
+    }
+        nsh_md2_ioam_trace_stats_increment_counter
+    (NSH_MD2_IOAM_TRACE_SUCCESS, 1);
+  }
+  else
+  {
+    nsh_md2_ioam_trace_stats_increment_counter(NSH_MD2_IOAM_TRACE_FAILED, 1);
+  }
+  return (rv);
+}
+
+
+
+u8 *
+nsh_md2_ioam_trace_data_list_trace_handler (u8 * s, nsh_tlv_header_t * opt)
+{
+  nsh_md2_ioam_trace_option_t *trace;
+  u8 trace_data_size_in_words = 0;
+  u32 *elt;
+  int elt_index = 0;
+  u32 ioam_trace_type = 0;
+
+  trace = (nsh_md2_ioam_trace_option_t *) ((u8 *) opt);
+  ioam_trace_type = clib_net_to_host_u16 (trace->ioam_trace_type);
+  trace_data_size_in_words = fetch_trace_data_size (nsh_trace_profile_find()) / 4; // NOTE: origianlly ioam_trace_type
+  elt = &trace->elts[0];
+  s =
+    format (s, "  Trace Type 0x%x , %d elts left\n", ioam_trace_type,
+	    trace->data_list_elts_left);
+  while ((u8 *) elt < ((u8 *) (&trace->elts[0]) + trace->length - 4
+		       /* -2 accounts for ioam_trace_type,elts_left */ ))
+  {
+    s = format (s, "    [%d] %U\n", elt_index,
+    format_ioam_data_list_element, elt, &ioam_trace_type);
+    elt_index++;
+    elt += trace_data_size_in_words;
+  }
+  return (s);
+}
+
+int
+nsh_md2_ioam_trace_swap_handler (vlib_buffer_t * b,
+				 nsh_tlv_header_t * old_opt,
+				 nsh_tlv_header_t * new_opt)
+{
+
+  clib_memcpy_fast (new_opt, old_opt,
+		    new_opt->length + sizeof (nsh_tlv_header_t));
+  return nsh_md2_ioam_trace_data_list_handler (b, new_opt);
+}
+
+static clib_error_t *
+nsh_md2_ioam_show_ioam_trace_cmd_fn (vlib_main_t * vm,
+				     unformat_input_t * input,
+				     vlib_cli_command_t * cmd)
+{
+  nsh_md2_ioam_trace_main_t *hm = &nsh_md2_ioam_trace_main;
+  u8 *s = 0;
+  int i = 0;
+
+  for (i = 0; i < NSH_MD2_IOAM_TRACE_N_STATS; i++)
+  {
+    s = format (s, " %s - %lu\n", nsh_md2_ioam_trace_stats_strings[i],
+    hm->counters[i]);
+  }
+
+  vlib_cli_output (vm, "%v", s);
+  vec_free (s);
+  return 0;
+}
+
+
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (nsh_md2_ioam_show_ioam_trace_cmd, static) = {
+  .path = "show ioam nsh-lisp-gpe trace",
+  .short_help = "iOAM trace statistics",
+  .function = nsh_md2_ioam_show_ioam_trace_cmd_fn,
+};
+/* *INDENT-ON* */
+
+
+int
+nsh_md2_ioam_trace_pop_handler (vlib_buffer_t * b, nsh_tlv_header_t * opt)
+{
+  return nsh_md2_ioam_trace_data_list_handler (b, opt);
+}
+
+static clib_error_t *
+nsh_md2_ioam_trace_init (vlib_main_t * vm)
+{
+  nsh_md2_ioam_trace_main_t *hm = &nsh_md2_ioam_trace_main;
+  nsh_md2_ioam_main_t *gm = &nsh_md2_ioam_main;
+
+  hm->vlib_main = vm;
+  hm->vnet_main = vnet_get_main ();
+  gm->unix_time_0 = (u32) time (0);	/* Store starting time */
+  gm->vlib_time_0 = vlib_time_now (vm);
+
+  clib_memset (hm->counters, 0, sizeof (hm->counters));
+
+  if (nsh_md2_register_option
+      (clib_host_to_net_u16 (0x9),
+       NSH_MD2_IOAM_OPTION_TYPE_TRACE,
+       NSH_MD2_IOAM_TRACE_SIZE_DUMMY,
+       nsh_md2_ioam_trace_rewrite_handler,
+       nsh_md2_ioam_trace_data_list_handler,
+       nsh_md2_ioam_trace_swap_handler,
+       nsh_md2_ioam_trace_pop_handler,
+       nsh_md2_ioam_trace_data_list_trace_handler) < 0)
+    return (clib_error_create
+	    ("registration of NSH_MD2_IOAM_OPTION_TYPE_TRACE failed"));
+
+  return (0);
+}
+
+/* *INDENT-OFF* */
+VLIB_INIT_FUNCTION (nsh_md2_ioam_trace_init) =
+{
+  .runs_after = VLIB_INITS ("nsh_init", "nsh_md2_ioam_init"),
+};
+/* *INDENT-ON* */
+
+int
+nsh_md2_ioam_trace_profile_cleanup (void)
+{
+  nsh_main_t *hm = &nsh_main;
+
+  hm->options_size[NSH_MD2_IOAM_OPTION_TYPE_TRACE] = 0;
+
+  return 0;
+
+}
+
+static int
+nsh_md2_ioam_trace_get_sizeof_handler (u32 * result)
+{
+  u16 size = 0;
+  u32 trace_data_size = 0;
+  trace_profile *profile = NULL;
+
+  *result = 0;
+
+  profile = nsh_trace_profile_find ();
+
+  if (PREDICT_FALSE (!profile))
+  {
+    return (-1);
+  }
+
+  trace_data_size = fetch_trace_data_size (profile);
+  if (PREDICT_FALSE (trace_data_size == 0))
+    return VNET_API_ERROR_INVALID_VALUE;
+
+  if (PREDICT_FALSE (profile->num_elts * trace_data_size > 254))
+    return VNET_API_ERROR_INVALID_VALUE;
+
+  size +=
+    sizeof (nsh_md2_ioam_trace_option_t) +
+    profile->num_elts * trace_data_size;
+  *result = size;
+
+  return 0;
+}
+
+
+int
+nsh_md2_ioam_trace_profile_setup (void)
+{
+  u32 trace_size = 0;
+  nsh_main_t *hm = &nsh_main;
+
+  trace_profile *profile = NULL;
+
+
+  profile = nsh_trace_profile_find ();
+
+  if (PREDICT_FALSE (!profile))
+  {
+    return (-1);
+  }
+
+
+  if (nsh_md2_ioam_trace_get_sizeof_handler (&trace_size) < 0)
+    return (-1);
+
+  hm->options_size[NSH_MD2_IOAM_OPTION_TYPE_TRACE] = trace_size;
+
+  return (0);
+}
+
+
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ioam/udp-ping/udp_ping_node.c b/src/plugins/ioam/udp-ping/udp_ping_node.c
index 6bfa8f67e..71e4fa836 100644
--- a/src/plugins/ioam/udp-ping/udp_ping_node.c
+++ b/src/plugins/ioam/udp-ping/udp_ping_node.c
@@ -480,7 +480,7 @@ udp_ping_analyse_hbh (vlib_buffer_t * b0,
 	  vnet_buffer (b0)->sw_if_index[VLIB_TX] = ~0;
 	  trace = (ioam_trace_option_t *) opt0;
 	  if (PREDICT_FALSE
-	      (trace->trace_hdr.ioam_trace_type & BIT_LOOPBACK_REPLY))
+	      ((trace->trace_hdr.trace_type & IOAM_FLAGS_MASK) && IOAM_BIT_FLAG_LOOPBACK_REPLY))
 	    {
 	      ip6_ioam_analyse_hbh_trace_loopback (data, &trace->trace_hdr,
 						   (trace->hdr.length - 2));
diff --git a/src/plugins/ioam/udp-ping/udp_ping_util.c b/src/plugins/ioam/udp-ping/udp_ping_util.c
index d3612cd01..929fb0deb 100644
--- a/src/plugins/ioam/udp-ping/udp_ping_util.c
+++ b/src/plugins/ioam/udp-ping/udp_ping_util.c
@@ -87,7 +87,7 @@ udp_ping_create_ip6_pak (u8 * buf,	/*u16 len, */
 
   /* Calculate hbh header len */
   //profile = trace_profile_find();
-  trace_data_size = fetch_trace_data_size (TRACE_TYPE_IF_TS_APP);
+  trace_data_size = fetch_trace_data_size (trace_profile_find()); // NOTE: INSTR_BITMAP_MASK & ~(BIT_VAR_LEN_OP_ST_SNSH));
   /* We need 2 times data for trace as packet traverse back to source */
   trace_len = sizeof (ioam_trace_option_t) +
     (5 * trace_data_size * 2) - sizeof (ip6_hop_by_hop_option_t);
@@ -107,10 +107,11 @@ udp_ping_create_ip6_pak (u8 * buf,	/*u16 len, */
   trace_option->hdr.type = HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST |
     HBH_OPTION_TYPE_DATA_CHANGE_ENROUTE;
   trace_option->hdr.length = trace_len;
-  trace_option->trace_hdr.ioam_trace_type =
-    TRACE_TYPE_IF_TS_APP & TRACE_TYPE_MASK;
+  trace_option->trace_hdr.trace_type = 
+          IOAM_INSTR_BITMAP_MASK & ~(IOAM_BIT_VAR_LEN_OP_ST_SNSH);
 
-  trace_option->trace_hdr.data_list_elts_left = 5 * 2;
+  trace_option->trace_hdr.node_len_flags_remaining_len &= (~IOAM_REMAIN_LEN_MASK);
+  trace_option->trace_hdr.node_len_flags_remaining_len |= 5 * 2;
   //profile->num_elts * 2;
 
   current += trace_option->hdr.length + sizeof (ip6_hop_by_hop_option_t);
@@ -293,7 +294,7 @@ udp_ping_send_ip6_pak (vlib_main_t * vm, ip46_udp_ping_flow * flow)
 	{
 	  ioam_trace_option_t *opt = (ioam_trace_option_t *)
 	    ip6_hbh_get_option (hbh, HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST);
-	  ip6_hbh_ioam_trace_set_bit (opt, BIT_LOOPBACK);
+	  ip6_hbh_ioam_trace_set_flag_bit (opt, IOAM_BIT_FLAG_LOOPBACK);
 	}
 
       /* Checksum not pre-computed as we intend to vary packet length for every
diff --git a/src/plugins/ioam/udp-ping/udp_ping_util.h b/src/plugins/ioam/udp-ping/udp_ping_util.h
index fcaf27bd4..4e0788f40 100644
--- a/src/plugins/ioam/udp-ping/udp_ping_util.h
+++ b/src/plugins/ioam/udp-ping/udp_ping_util.h
@@ -60,7 +60,7 @@ udp_ping_create_reply_from_probe_ip6 (ip6_header_t * ip,
 
   trace = (ioam_trace_option_t *)
     ip6_hbh_get_option (hbh, HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST);
-  ip6_hbh_ioam_trace_reset_bit (trace, BIT_LOOPBACK);
+  ip6_hbh_ioam_trace_reset_flag_bit (trace, IOAM_BIT_FLAG_LOOPBACK);
 
   /* No need of endian transform */
   src_port = udp->udp.src_port;
diff --git a/src/plugins/ip/ip.api b/src/plugins/ip/ip.api
new file mode 100644
index 000000000..66e072158
--- /dev/null
+++ b/src/plugins/ip/ip.api
@@ -0,0 +1,769 @@
+/* Hey Emacs use -*- mode: C -*- */
+/*
+ * Copyright (c) 2018 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/** \file
+
+    This file defines vpp IP control-plane API messages which are generally
+    called through a shared memory interface.
+*/
+
+option version = "3.0.3";
+
+import "vnet/interface_types.api";
+import "vnet/fib/fib_types.api";
+import "vnet/ethernet/ethernet_types.api";
+import "vnet/mfib/mfib_types.api";
+import "vnet/interface_types.api";
+
+/** \brief An IP table
+    @param is_ipv6 - V4 or V6 table
+    @param table_id - table ID associated with the route
+                     This table ID will apply to both the unicast
+		      and multicast FIBs
+    @param name - A client provided name/tag for the table. If this is
+                  not set by the client, then VPP will generate something
+		  meaningful.
+*/
+typedef ip_table
+{
+  u32 table_id;
+  bool is_ip6;
+  string name[64];
+};
+
+/** \brief Add / del table request
+           A table can be added multiple times, but need be deleted only once.
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+*/
+autoreply define ip_table_add_del
+{
+  u32 client_index;
+  u32 context;
+  bool is_add [default=true];
+  vl_api_ip_table_t table;
+};
+
+/** \brief Dump IP all fib tables
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+*/
+define ip_table_dump
+{
+  u32 client_index;
+  u32 context;
+};
+
+/** \brief IP table replace being
+
+    The use-case is that, for some unspecified reason, the control plane
+    has a very different set of entries it wants in the table than VPP
+    currently has. The CP would thus like to 'replace' VPP's current table
+    only by specifying what the new set of entries shall be, i.e. it is not
+    going to delete anything that already exists.
+    the CP declares the start of this procedure with this begin_replace
+    API Call, and when it has populated all the entries it wants, it calls
+    the below end_replace API. From this point on it is of course free
+    to add and delete entries as usual.
+    The underlying mechanism by which VPP implements this replace is
+    purposefully left unspecified.
+
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param table - The table to resync
+*/
+autoreply define ip_table_replace_begin
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief IP table replace end
+
+    see replace start/
+
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param table - The table that has converged
+*/
+autoreply define ip_table_replace_end
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief IP table flush
+    Flush a table of all routes
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param table - The table to flush
+*/
+autoreply define ip_table_flush
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief IP FIB table response
+    @param context - sender context
+    @param table - description of the table
+*/
+define ip_table_details
+{
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief An IP route
+  @param table_id The IP table the route is in
+  @param stats_index The index of the route in the stats segment
+  @param prefix the prefix for the route
+  @param n_paths The number of paths the route has
+  @param paths The paths of the route
+*/
+typedef ip_route
+{
+  u32 table_id;
+  u32 stats_index;
+  vl_api_prefix_t prefix;
+  u8 n_paths;
+  vl_api_fib_path_t paths[n_paths];
+};
+
+/** \brief Add / del route request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param is_multipath - Set to 1 if these paths will be added/removed
+                          to/from the existing set, or 0 to replace
+			  the existing set.
+                          is_add=0 & is_multipath=0 implies delete all paths
+    @param is_add - Are the paths being added or removed
+*/
+define ip_route_add_del
+{
+  u32 client_index;
+  u32 context;
+  bool is_add [default=true];
+  bool is_multipath;
+  vl_api_ip_route_t route;
+};
+define ip_route_add_del_reply
+{
+  u32 context;
+  i32 retval;
+  u32 stats_index;
+};
+
+/** \brief Dump IP routes from a table
+    @param client_index - opaque cookie to identify the sender
+    @param table - The table from which to dump routes (ony ID an AF are needed)
+*/
+define ip_route_dump
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief IP FIB table entry response
+    @param route The route entry in the table
+*/
+define ip_route_details
+{
+  u32 context;
+  vl_api_ip_route_t route;
+};
+
+/** \brief Lookup IP route from a table
+    @param client_index - opaque cookie to identify the sender
+    @param table_id - The IP table to look the route up in
+    @param exact - 0 for normal route lookup, 1 for exact match only
+    @param prefix - The prefix (or host) for route lookup.
+*/
+define ip_route_lookup
+{
+  u32 client_index;
+  u32 context;
+  u32 table_id;
+  u8 exact;
+  vl_api_prefix_t prefix;
+};
+
+/** \brief IP FIB table lookup response
+    @param retval - return code of the lookup
+    @param route - The route entry in the table if found
+*/
+define ip_route_lookup_reply
+{
+  u32 context;
+  i32 retval;
+  vl_api_ip_route_t route;
+};
+
+/** \brief Set the ip flow hash config for a fib request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param vrf_id - vrf/fib id
+    @param is_ipv6 - if non-zero the fib is ip6, else ip4
+    @param src - if non-zero include src in flow hash
+    @param dst - if non-zero include dst in flow hash
+    @param sport - if non-zero include sport in flow hash
+    @param dport - if non-zero include dport in flow hash
+    @param proto -if non-zero include proto in flow hash
+    @param reverse - if non-zero include reverse in flow hash
+    @param symmetric - if non-zero include symmetry in flow hash
+*/
+autoreply define set_ip_flow_hash
+{
+  option deprecated;
+  u32 client_index;
+  u32 context;
+  u32 vrf_id;
+  bool is_ipv6;
+  bool src;
+  bool dst;
+  bool sport;
+  bool dport;
+  bool proto;
+  bool reverse;
+  bool symmetric;
+};
+
+/**
+    @brief flow hash settings for an IP table
+    @param src - include src in flow hash
+    @param dst - include dst in flow hash
+    @param sport - include sport in flow hash
+    @param dport - include dport in flow hash
+    @param proto - include proto in flow hash
+    @param reverse - include reverse in flow hash
+    @param symmetric - include symmetry in flow hash
+    @param flowlabel - include flowlabel in flow hash
+*/
+enumflag ip_flow_hash_config
+{
+  IP_API_FLOW_HASH_SRC_IP = 0x01,
+  IP_API_FLOW_HASH_DST_IP = 0x02,
+  IP_API_FLOW_HASH_SRC_PORT = 0x04,
+  IP_API_FLOW_HASH_DST_PORT = 0x08,
+  IP_API_FLOW_HASH_PROTO = 0x10,
+  IP_API_FLOW_HASH_REVERSE = 0x20,
+  IP_API_FLOW_HASH_SYMETRIC = 0x40,
+  IP_API_FLOW_HASH_FLOW_LABEL = 0x80,
+};
+
+autoreply define set_ip_flow_hash_v2
+{
+  u32 client_index;
+  u32 context;
+  u32 table_id;
+  vl_api_address_family_t af;
+  vl_api_ip_flow_hash_config_t flow_hash_config;
+};
+
+/** \brief Set the ip flow hash router ID
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param router_id - The ID of the router. Mixed into the hash.
+                       Used to prevent polarisation across a network,
+                       since each router is assumed to have a different ID
+*/
+autoreply define set_ip_flow_hash_router_id
+{
+  u32 client_index;
+  u32 context;
+  u32 router_id;
+};
+
+/** \brief IPv6 interface enable / disable request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param sw_if_index - interface used to reach neighbor
+    @param enable - if non-zero enable ip6 on interface, else disable
+*/
+autoreply define sw_interface_ip6_enable_disable
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  bool enable;			/* set to true if enable */
+};
+
+/** \brief Dump IP multicast fib table
+    @param client_index - opaque cookie to identify the sender
+*/
+define ip_mtable_dump
+{
+  u32 client_index;
+  u32 context;
+};
+define ip_mtable_details
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief Add / del route request
+
+    Adds a route, consisting both of the MFIB entry to match packets
+    (which may already exist) and a path to send those packets down.
+    Routes can be entered repeatedly to add multiple paths.  Deletions are
+    per-path.
+
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param table_id - fib table /vrf associated with the route
+    @param is_add - true if adding a route; false if deleting one
+    @param is_ipv6 - true iff all the addresses are v6
+    @param entry_flags - see fib_entry_flag_t
+    @param itf_flags - see mfib_entry_flags_t
+    @param next_hop_afi - see dpo_proto_t; the type of destination description
+    @param src_address - the source of the packet
+    @param grp_address - the group the packet is destined to
+    @param nh_address - the nexthop to forward the packet to
+    @param next_hop_sw_if_index - interface to emit packet on
+
+    BIER AFIs use the BIER imposition ID.  v4 and v6 AFIs use either the
+    interface or the nexthop address.
+
+    Note that if the route is source-specific (S is supplied, not all 0s),
+    the prefix match is treated as exact (prefixlen /32 or /128).
+
+    FIXME not complete yet
+*/
+typedef ip_mroute
+{
+  u32 table_id;
+  vl_api_mfib_entry_flags_t entry_flags;
+  u32 rpf_id;
+  vl_api_mprefix_t prefix;
+  u8 n_paths;
+  vl_api_mfib_path_t paths[n_paths];
+};
+
+define ip_mroute_add_del
+{
+  u32 client_index;
+  u32 context;
+  bool is_add [default=true];
+  bool is_multipath;
+  vl_api_ip_mroute_t route;
+};
+define ip_mroute_add_del_reply
+{
+  u32 context;
+  i32 retval;
+  u32 stats_index;
+};
+
+/** \brief Dump IP multicast fib table
+    @param table - The table from which to dump routes (ony ID an AF are needed)
+*/
+define ip_mroute_dump
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_table_t table;
+};
+
+/** \brief IP Multicast Route Details
+    @param route - Details of the route
+*/
+define ip_mroute_details
+{
+  u32 context;
+  vl_api_ip_mroute_t route;
+};
+
+define ip_address_details
+{
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  vl_api_address_with_prefix_t prefix;
+};
+
+define ip_address_dump
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  bool is_ipv6;
+};
+
+/** \brief IP unnumbered configurations
+    @param sw_if_index The interface that has unnumbered configuration
+    @param ip_sw_if_index The IP interface that it is unnumbered to
+*/
+define ip_unnumbered_details
+{
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  vl_api_interface_index_t ip_sw_if_index;
+};
+
+/** \brief Dump IP unnumbered configurations
+    @param sw_if_index ~0 for all interfaces, else the interface desired
+*/
+define ip_unnumbered_dump
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index [default=0xffffffff];
+};
+
+define ip_details
+{
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  bool is_ipv6;
+};
+
+define ip_dump
+{
+  u32 client_index;
+  u32 context;
+  bool is_ipv6;
+};
+
+define mfib_signal_dump
+{
+  u32 client_index;
+  u32 context;
+};
+
+define mfib_signal_details
+{
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  u32 table_id;
+  vl_api_mprefix_t prefix;
+  u16 ip_packet_len;
+  u8 ip_packet_data[256];
+};
+
+/** \brief IP punt policer
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param is_add - 1 to add neighbor, 0 to delete
+    @param is_ipv6 - 1 for IPv6 neighbor, 0 for IPv4
+    @param policer_index - Index of policer to use
+*/
+autoreply define ip_punt_police
+{
+  u32 client_index;
+  u32 context;
+  u32 policer_index;
+  bool is_add [default=true];
+  bool is_ip6;
+};
+
+/** \brief Punt redirect type
+    @param rx_sw_if_index - specify the original RX interface of traffic
+                            that should be redirected. ~0 means any interface.
+    @param tx_sw_if_index - the TX interface to which traffic should be
+                            redirected.
+    @param nh - the next-hop to redirect the traffic to.
+    @param is_ipv6 - 1 for IPv6 neighbor, 0 for IPv4
+*/
+typedef punt_redirect
+{
+  vl_api_interface_index_t rx_sw_if_index;
+  vl_api_interface_index_t tx_sw_if_index;
+  vl_api_address_t nh;
+};
+
+/** \brief IP punt redirect
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param punt - punt definition
+    @param is_add - 1 to add neighbor, 0 to delete
+*/
+autoreply define ip_punt_redirect
+{
+  u32 client_index;
+  u32 context;
+  vl_api_punt_redirect_t punt;
+  bool is_add [default=true];
+};
+
+define ip_punt_redirect_dump
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  bool is_ipv6;
+};
+
+define ip_punt_redirect_details
+{
+  u32 context;
+  vl_api_punt_redirect_t punt;
+};
+
+autoreply define ip_container_proxy_add_del
+{
+  u32 client_index;
+  u32 context;
+  vl_api_prefix_t pfx;
+  vl_api_interface_index_t sw_if_index;
+  bool is_add [default=true];
+};
+
+define ip_container_proxy_dump
+{
+  u32 client_index;
+  u32 context;
+};
+
+define ip_container_proxy_details
+{
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  vl_api_prefix_t prefix;
+};
+
+/** \brief Configure IP source and L4 port-range check
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param is_ip6 - 1 if source address type is IPv6
+    @param is_add - 1 if add, 0 if delete
+    @param ip - prefix to match
+    @param number_of_ranges - length of low_port and high_port arrays (must match)
+    @param low_ports[32] - up to 32 low end of port range entries (must have corresponding high_ports entry)
+    @param high_ports[32] - up to 32 high end of port range entries (must have corresponding low_ports entry)
+    @param vrf_id - fib table/vrf id to associate the source and port-range check with
+    @note To specify a single port set low_port and high_port entry the same
+*/
+autoreply define ip_source_and_port_range_check_add_del
+{
+  u32 client_index;
+  u32 context;
+  bool is_add [default=true];
+  vl_api_prefix_t prefix;
+  u8 number_of_ranges;
+  u16 low_ports[32];
+  u16 high_ports[32];
+  u32 vrf_id;
+};
+
+/** \brief Set interface source and L4 port-range request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param interface_id - interface index
+    @param tcp_vrf_id - VRF associated with source and TCP port-range check
+    @param udp_vrf_id - VRF associated with source and TCP port-range check
+*/
+autoreply define ip_source_and_port_range_check_interface_add_del
+{
+  u32 client_index;
+  u32 context;
+  bool is_add [default=true];
+  vl_api_interface_index_t sw_if_index;
+  u32 tcp_in_vrf_id;
+  u32 tcp_out_vrf_id;
+  u32 udp_in_vrf_id;
+  u32 udp_out_vrf_id;
+};
+
+/** \brief IPv6 set link local address on interface request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param sw_if_index - interface to set link local on
+    @param ip - the new link local address
+*/
+autoreply define sw_interface_ip6_set_link_local_address
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  vl_api_ip6_address_t ip;
+};
+
+/** \brief IPv6 get link local address on interface request
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param sw_if_index - interface to set link local on
+*/
+define sw_interface_ip6_get_link_local_address
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+};
+
+/** \brief IPv6 link local address detail
+    @param context - sender context, to match reply w/ request
+    @param ip - the link local address
+*/
+define sw_interface_ip6_get_link_local_address_reply
+{
+  u32 context;
+  i32 retval;
+  vl_api_ip6_address_t ip;
+};
+
+/** \brief IOAM enable : Enable in-band OAM
+    @param id - profile id
+    @param seqno - To enable Seqno Processing
+    @param analyse - Enabling analysis of iOAM at decap node
+    @param pow_enable - Proof of Work enabled or not flag
+    @param trace_enable - iOAM Trace enabled or not flag
+*/
+autoreply define ioam_enable
+{
+  u32 client_index;
+  u32 context;
+  u16 id;
+  bool seqno;
+  bool analyse;
+  bool pot_enable;
+  bool trace_enable;
+  vl_api_ip6_address_t dst_addr;
+  u32 node_id;
+};
+
+/** \brief iOAM disable
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param index - MAP Domain index
+*/
+autoreply define ioam_disable
+{
+  u32 client_index;
+  u32 context;
+  u16 id;
+};
+
+enum ip_reass_type
+{
+  IP_REASS_TYPE_FULL = 0,
+  IP_REASS_TYPE_SHALLOW_VIRTUAL = 0x1,
+};
+
+autoreply define ip_reassembly_set
+{
+  u32 client_index;
+  u32 context;
+  u32 timeout_ms;
+  u32 max_reassemblies;
+  u32 max_reassembly_length;
+  u32 expire_walk_interval_ms;
+  bool is_ip6;
+  vl_api_ip_reass_type_t type;
+};
+
+define ip_reassembly_get
+{
+  u32 client_index;
+  u32 context;
+  bool is_ip6;
+  vl_api_ip_reass_type_t type;
+};
+
+define ip_reassembly_get_reply
+{
+  u32 context;
+  i32 retval;
+  u32 timeout_ms;
+  u32 max_reassemblies;
+  u32 max_reassembly_length;
+  u32 expire_walk_interval_ms;
+  bool is_ip6;
+};
+
+/** \brief Enable/disable reassembly feature
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param sw_if_index - interface to enable/disable feature on
+    @param enable_ip4 - enable ip4 reassembly if non-zero, disable if 0
+    @param enable_ip6 - enable ip6 reassembly if non-zero, disable if 0
+*/
+autoreply define ip_reassembly_enable_disable
+{
+  u32 client_index;
+  u32 context;
+  vl_api_interface_index_t sw_if_index;
+  bool enable_ip4;
+  bool enable_ip6;
+  vl_api_ip_reass_type_t type;
+};
+
+/**
+    @brief Set a Path MTU value. i.e. a MTU value for a given neighbour.
+           The neighbour can be described as attached (w/ interface and next-hop)
+           or remote (w/ table_id and next-hop);
+    @param client_index - opaque cookie to identify the sender
+    @param context - sender context, to match reply w/ request
+    @param table_id - table-ID for next-hop
+    @param nh - Next hop
+    @param path_mtu - value to set, 0 is disable.
+*/
+typedef ip_path_mtu
+{
+  u32 client_index;
+  u32 context;
+  u32 table_id;
+  vl_api_address_t nh;
+  u16 path_mtu;
+};
+autoreply define ip_path_mtu_update
+{
+  u32 client_index;
+  u32 context;
+  vl_api_ip_path_mtu_t pmtu;
+};
+define ip_path_mtu_get
+{
+  u32 client_index;
+  u32 context;
+  u32 cursor;
+};
+define ip_path_mtu_get_reply
+{
+  u32 context;
+  i32 retval;
+  u32 cursor;
+};
+define ip_path_mtu_details
+{
+  u32 context;
+  vl_api_ip_path_mtu_t pmtu;
+};
+service {
+  rpc ip_path_mtu_get returns ip_path_mtu_get_reply
+    stream ip_path_mtu_details;
+};
+
+autoreply define ip_path_mtu_replace_begin
+{
+  u32 client_index;
+  u32 context;
+};
+autoreply define ip_path_mtu_replace_end
+{
+  u32 client_index;
+  u32 context;
+};
+
+/*
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ip/ip6_hop_by_hop.c b/src/plugins/ip/ip6_hop_by_hop.c
new file mode 100644
index 000000000..0b8bda521
--- /dev/null
+++ b/src/plugins/ip/ip6_hop_by_hop.c
@@ -0,0 +1,1822 @@
+/*
+ * Copyright (c) 2016 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#include <vlib/vlib.h>
+#include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
+#include <vppinfra/error.h>
+
+#include <vnet/ip/ip.h>
+#include <vnet/ip/ip6_link.h>
+
+#include <vppinfra/hash.h>
+#include <vppinfra/error.h>
+#include <vppinfra/elog.h>
+
+#include <vnet/ip/ip6_hop_by_hop.h>
+#include <vnet/fib/ip6_fib.h>
+#include <vnet/fib/fib_sas.h>
+#include <vnet/classify/vnet_classify.h>
+#include <vnet/interface_output.h>
+
+/**
+ * @file
+ * @brief In-band OAM (iOAM).
+ *
+ * In-band OAM (iOAM) is an implementation study to record operational
+ * information in the packet while the packet traverses a path between
+ * two points in the network.
+ *
+ * VPP can function as in-band OAM encapsulating, transit and
+ * decapsulating node. In this version of VPP in-band OAM data is
+ * transported as options in an IPv6 hop-by-hop extension header. Hence
+ * in-band OAM can be enabled for IPv6 traffic.
+ */
+
+#ifndef CLIB_MARCH_VARIANT
+ip6_hop_by_hop_ioam_main_t ip6_hop_by_hop_ioam_main;
+#endif /* CLIB_MARCH_VARIANT */
+
+#define foreach_ip6_hbyh_ioam_input_next	\
+  _(IP6_REWRITE, "ip6-rewrite")			\
+  _(IP6_LOOKUP, "ip6-lookup")			\
+  _(DROP, "ip6-drop")
+
+typedef enum
+{
+#define _(s,n) IP6_HBYH_IOAM_INPUT_NEXT_##s,
+  foreach_ip6_hbyh_ioam_input_next
+#undef _
+    IP6_HBYH_IOAM_INPUT_N_NEXT,
+} ip6_hbyh_ioam_input_next_t;
+
+#ifndef CLIB_MARCH_VARIANT
+static uword
+unformat_opaque_ioam (unformat_input_t * input, va_list * args)
+{
+  u64 *opaquep = va_arg (*args, u64 *);
+  u8 *flow_name = NULL;
+  uword ret = 0;
+
+  if (unformat (input, "ioam-encap %s", &flow_name))
+  {
+    *opaquep = ioam_flow_add (1, flow_name);
+    ret = 1;
+  }
+  else if (unformat (input, "ioam-decap %s", &flow_name))
+  {
+    *opaquep = ioam_flow_add (0, flow_name);
+    ret = 1;
+  }
+
+  vec_free (flow_name);
+  return ret;
+}
+
+u8 *
+get_flow_name_from_flow_ctx (u32 flow_ctx)
+{
+  flow_data_t *flow = NULL;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  u32 index;
+
+  index = IOAM_MASK_DECAP_BIT (flow_ctx);
+  if (pool_is_free_index (hm->flows, index))
+  {
+    return NULL;
+  }
+
+  flow = pool_elt_at_index (hm->flows, index);
+  return (flow->flow_name);
+}
+
+/* The main h-b-h tracer will be invoked, no need to do much here */
+int
+ip6_hbh_add_register_option (u8 option,
+			     u8 size,
+			     int rewrite_options (u8 * rewrite_string,
+						  u8 * rewrite_size))
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->add_options));
+
+  /* Already registered */
+  if (hm->add_options[option])
+    return (-1);
+
+  hm->add_options[option] = rewrite_options;
+  hm->options_size[option] = size;
+
+  return (0);
+}
+
+int
+ip6_hbh_add_unregister_option (u8 option)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->add_options));
+
+  /* Not registered */
+  if (!hm->add_options[option])
+    return (-1);
+
+  hm->add_options[option] = NULL;
+  hm->options_size[option] = 0;
+  return (0);
+}
+
+/* Config handler registration */
+int
+ip6_hbh_config_handler_register (u8 option,
+				 int config_handler (void *data, u8 disable))
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->config_handler));
+
+  /* Already registered  */
+  if (hm->config_handler[option])
+    return (VNET_API_ERROR_INVALID_REGISTRATION);
+
+  hm->config_handler[option] = config_handler;
+
+  return (0);
+}
+
+int
+ip6_hbh_config_handler_unregister (u8 option)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->config_handler));
+
+  /* Not registered */
+  if (!hm->config_handler[option])
+    return (VNET_API_ERROR_INVALID_REGISTRATION);
+
+  hm->config_handler[option] = NULL;
+  return (0);
+}
+
+/* Flow handler registration */
+int
+ip6_hbh_flow_handler_register (u8 option,
+			       u32 ioam_flow_handler (u32 flow_ctx, u8 add))
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->flow_handler));
+
+  /* Already registered */
+  if (hm->flow_handler[option])
+    return (VNET_API_ERROR_INVALID_REGISTRATION);
+
+  hm->flow_handler[option] = ioam_flow_handler;
+
+  return (0);
+}
+
+int
+ip6_hbh_flow_handler_unregister (u8 option)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->flow_handler));
+
+  /* Not registered */
+  if (!hm->flow_handler[option])
+    return (VNET_API_ERROR_INVALID_REGISTRATION);
+
+  hm->flow_handler[option] = NULL;
+  return (0);
+}
+#endif /* CLIB_MARCH_VARIANT */
+
+typedef struct
+{
+  u32 next_index;
+} ip6_add_hop_by_hop_trace_t;
+
+/* packet trace format function */
+static u8 *
+format_ip6_add_hop_by_hop_trace (u8 * s, va_list * args)
+{
+  CLIB_UNUSED (vlib_main_t * vm) = va_arg (*args, vlib_main_t *);
+  CLIB_UNUSED (vlib_node_t * node) = va_arg (*args, vlib_node_t *);
+  ip6_add_hop_by_hop_trace_t *t = va_arg (*args,
+					  ip6_add_hop_by_hop_trace_t *);
+  
+  s = format (s, "IP6_ADD_HOP_BY_HOP: next index %d", t->next_index);
+  return s;
+}
+
+extern vlib_node_registration_t ip6_add_hop_by_hop_node;
+
+#define foreach_ip6_add_hop_by_hop_error \
+_(PROCESSED, "Pkts w/ added ip6 hop-by-hop options") \
+_(SRC_ADDR_FAILED, "Ip6 add hbh failed to determine source address for packet") \
+_(ALLOC_ERR, "Error while allocating new buffer")
+
+typedef enum
+{
+#define _(sym,str) IP6_ADD_HOP_BY_HOP_ERROR_##sym,
+  foreach_ip6_add_hop_by_hop_error
+#undef _
+    IP6_ADD_HOP_BY_HOP_N_ERROR,
+} ip6_add_hop_by_hop_error_t;
+
+static char *ip6_add_hop_by_hop_error_strings[] = {
+#define _(sym,string) string,
+  foreach_ip6_add_hop_by_hop_error
+#undef _
+};
+
+VLIB_NODE_FN (ip6_add_hop_by_hop_node) (vlib_main_t * vm,
+					vlib_node_runtime_t * node,
+					vlib_frame_t * frame)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  u32 n_left_from, *from, *to_next;
+  ip_lookup_next_t next_index;
+  u32 processed = 0;
+  u32 no_src_addr = 0;
+  u32 alloc_err = 0;
+  u8 *rewrite = hm->rewrite;
+  u32 rewrite_length = vec_len (rewrite);
+  u32 outer_header_length = rewrite_length + sizeof(ip6_header_t);
+  u32 new_bi[VLIB_FRAME_SIZE], *b;
+  vlib_buffer_t *new_bufs[VLIB_FRAME_SIZE], **bufs;
+  bufs = new_bufs;
+  b = new_bi;
+
+  from = vlib_frame_vector_args (frame);
+  n_left_from = frame->n_vectors;
+  next_index = node->cached_next_index;
+
+  if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+  {
+    if (vlib_buffer_alloc (vm, new_bi, n_left_from) != n_left_from)
+    {
+      alloc_err++;
+      return frame->n_vectors;
+    }
+    vlib_get_buffers (vm, new_bi, new_bufs, n_left_from);
+  }
+
+  while (n_left_from > 0)
+  {
+    u32 n_left_to_next;
+
+    vlib_get_next_frame (vm, node, next_index, to_next, n_left_to_next);
+
+    while (n_left_from >= 4 && n_left_to_next >= 2)
+	  {
+      u32 bi0, bi1;
+      vlib_buffer_t *b0, *b1;
+      u32 next0, next1;
+      ip6_header_t *ip0, *ip1;
+      ip6_header_t *new_ip0, *new_ip1;
+      ip6_hop_by_hop_header_t *hbh0, *hbh1;
+      u16 new_l0, new_l1;
+
+	    /* Prefetch next iteration. */
+	    {
+        vlib_buffer_t *p2, *p3;
+
+        p2 = vlib_get_buffer (vm, from[2]);
+        p3 = vlib_get_buffer (vm, from[3]);
+
+        vlib_prefetch_buffer_header (p2, LOAD);
+        vlib_prefetch_buffer_header (p3, LOAD);
+
+        CLIB_PREFETCH (p2->data,
+          2 * CLIB_CACHE_LINE_BYTES, STORE);
+        CLIB_PREFETCH (p3->data,
+          2 * CLIB_CACHE_LINE_BYTES, STORE);
+	    }
+
+      /* speculatively enqueue b0 and b1 to the current next frame */
+      bi0 = from[0];
+      bi1 = from[1];
+      if (outer_header_length <= VLIB_BUFFER_PRE_DATA_SIZE)
+      {
+        b[0] = bi0;
+        b[1] = bi1;
+      }
+      to_next[0] = b[0];
+      to_next[1] = b[1];
+      from += 2;
+      to_next += 2;
+      n_left_from -= 2;
+      n_left_to_next -= 2;
+
+      b0 = vlib_get_buffer (vm, bi0);
+      b1 = vlib_get_buffer (vm, bi1);
+
+      /* $$$$$ Dual loop: process 2 x packets here $$$$$ */
+      ip0 = vlib_buffer_get_current (b0);
+      ip1 = vlib_buffer_get_current (b1);
+      if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+      {
+        new_ip0 = vlib_buffer_get_current (bufs[0]);
+        new_ip1 = vlib_buffer_get_current (bufs[1]);
+      }
+
+      if (b0->flags & VNET_BUFFER_F_OFFLOAD)
+      {
+        vnet_calc_checksums_inline (vm, b0, 0, 1);
+        b0->flags &= ~VNET_BUFFER_F_OFFLOAD;
+      }
+      if (b1->flags & VNET_BUFFER_F_OFFLOAD)
+      {
+        vnet_calc_checksums_inline (vm, b1, 0, 1);
+        b1->flags &= ~VNET_BUFFER_F_OFFLOAD;
+      }
+
+      if (PREDICT_TRUE(!(b0->flags & VNET_BUFFER_F_LOCALLY_ORIGINATED)))
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[0]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[0]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[0]->current_length = outer_header_length;
+          bufs[0]->total_length_not_including_first_buffer = b0->current_length;
+          bufs[0]->next_buffer = bi0;
+          bufs[0]->trace_handle = b0->trace_handle;
+          clib_memcpy_fast (bufs[0]->opaque, b0->opaque, sizeof (b0->opaque));
+          clib_memcpy_fast (bufs[0]->opaque2, b0->opaque2, sizeof (b0->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b0, -outer_header_length);
+          new_ip0 = vlib_buffer_get_current (b0);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip0, ip0, 40);
+
+        hbh0 = (ip6_hop_by_hop_header_t *) (new_ip0 + 1);
+
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh0, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh0->protocol = 41; // not ip->protocol
+        /* Set outer Ip6 header destination and source address */
+        copy_ip6_address(&new_ip0->dst_address, &hm->dst_addr);
+        copy_ip6_address(&new_ip0->src_address, &hm->src_addr);
+
+        new_ip0->protocol = 0;
+
+        new_l0 =
+          clib_net_to_host_u16 (new_ip0->payload_length) + outer_header_length;
+        new_ip0->payload_length = clib_host_to_net_u16 (new_l0);
+      }
+      else
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[0]->flags |= VNET_BUFFER_F_LOCALLY_ORIGINATED;
+          bufs[0]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[0]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[0]->current_length = outer_header_length;
+          bufs[0]->total_length_not_including_first_buffer = b0->current_length - 40;
+          bufs[0]->next_buffer = bi0;
+          bufs[0]->trace_handle = b0->trace_handle;
+          clib_memcpy_fast (bufs[0]->opaque, b0->opaque, sizeof (b0->opaque));
+          clib_memcpy_fast (bufs[0]->opaque2, b0->opaque2, sizeof (b0->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b0, -rewrite_length);
+          new_ip0 = vlib_buffer_get_current (b0);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip0, ip0, 40);
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+          vlib_buffer_advance(b0, 40);
+
+        hbh0 = (ip6_hop_by_hop_header_t *) (new_ip0 + 1);
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh0, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh0->protocol = new_ip0->protocol;
+        new_ip0->protocol = 0;
+
+        new_l0 =
+          clib_net_to_host_u16 (new_ip0->payload_length) + rewrite_length;
+        new_ip0->payload_length = clib_host_to_net_u16 (new_l0);
+      }
+
+      if (PREDICT_TRUE(!(b1->flags & VNET_BUFFER_F_LOCALLY_ORIGINATED)))
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[1]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[1]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[1]->current_length = outer_header_length;
+          bufs[1]->total_length_not_including_first_buffer = b1->current_length;
+          bufs[1]->next_buffer = bi1;
+          bufs[1]->trace_handle = b1->trace_handle;
+          clib_memcpy_fast (bufs[1]->opaque, b1->opaque, sizeof (b1->opaque));
+          clib_memcpy_fast (bufs[1]->opaque2, b1->opaque2, sizeof (b1->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b1, -outer_header_length);
+          new_ip1 = vlib_buffer_get_current (b1);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip1, ip1, 40);
+
+        hbh1 = (ip6_hop_by_hop_header_t *) (new_ip1 + 1);
+
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh1, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh1->protocol = 41; // not ip->protocol
+        /* Set outer Ip6 header destination and source address */
+        copy_ip6_address(&new_ip1->dst_address, &hm->dst_addr);
+        copy_ip6_address(&new_ip1->src_address, &hm->src_addr);
+
+        new_ip1->protocol = 0;
+
+        new_l1 =
+          clib_net_to_host_u16 (new_ip1->payload_length) + outer_header_length;
+        new_ip1->payload_length = clib_host_to_net_u16 (new_l1);
+      }
+      else
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[1]->flags |= VNET_BUFFER_F_LOCALLY_ORIGINATED;
+          bufs[1]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[1]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[1]->current_length = outer_header_length;
+          bufs[1]->total_length_not_including_first_buffer = b1->current_length - 40;
+          bufs[1]->next_buffer = bi1;
+          bufs[1]->trace_handle = b1->trace_handle;
+          clib_memcpy_fast (bufs[1]->opaque, b1->opaque, sizeof (b1->opaque));
+          clib_memcpy_fast (bufs[1]->opaque2, b1->opaque2, sizeof (b1->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b1, -rewrite_length);
+          new_ip1 = vlib_buffer_get_current (b1);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip1, ip1, 40);
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+          vlib_buffer_advance(b1, 40);
+
+        hbh1 = (ip6_hop_by_hop_header_t *) (new_ip1 + 1);
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh1, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh1->protocol = new_ip1->protocol;
+        new_ip1->protocol = 0;
+
+        new_l1 =
+          clib_net_to_host_u16 (new_ip1->payload_length) + rewrite_length;
+        new_ip1->payload_length = clib_host_to_net_u16 (new_l1);
+      }
+
+      /* Populate the (first) h-b-h list elt */
+      next0 = IP6_HBYH_IOAM_INPUT_NEXT_IP6_LOOKUP;
+      next1 = IP6_HBYH_IOAM_INPUT_NEXT_IP6_LOOKUP;
+
+	    /* $$$$$ End of processing 2 x packets $$$$$ */
+
+	    if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)))
+	    {
+	      if (b0->flags & VLIB_BUFFER_IS_TRACED)
+		    {
+          if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+          {
+            bufs[0]->flags |= VLIB_BUFFER_IS_TRACED;
+            ip6_add_hop_by_hop_trace_t *t =
+              vlib_add_trace (vm, node, bufs[0], sizeof (*t));
+            t->next_index = next0;
+          }
+          else
+          {
+            ip6_add_hop_by_hop_trace_t *t =
+              vlib_add_trace (vm, node, b0, sizeof (*t));
+            t->next_index = next0;
+          }
+		    }
+	      if (b1->flags & VLIB_BUFFER_IS_TRACED)
+        {
+          if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+          {
+            bufs[1]->flags |= VLIB_BUFFER_IS_TRACED;
+            ip6_add_hop_by_hop_trace_t *t =
+              vlib_add_trace (vm, node, bufs[1], sizeof (*t));
+            t->next_index = next1;
+          }
+          else
+          {
+            ip6_add_hop_by_hop_trace_t *t =
+              vlib_add_trace (vm, node, b1, sizeof (*t));
+            t->next_index = next1;
+          }
+        }
+	    }
+      processed += 2;
+      /* verify speculative enqueues, maybe switch current next frame */
+      vlib_validate_buffer_enqueue_x2 (vm, node, next_index,
+              to_next, n_left_to_next,
+              b[0], b[1], next0, next1);
+
+      b += 2;
+      bufs += 2;
+	  }
+
+    while (n_left_from > 0 && n_left_to_next > 0)
+	  {
+      u32 bi0;
+      vlib_buffer_t *b0;
+      u32 next0;
+      ip6_header_t *ip0;
+      ip6_header_t *new_ip0;
+      ip6_hop_by_hop_header_t *hbh0;
+      u16 new_l0;
+
+      /* speculatively enqueue b0 to the current next frame */
+      bi0 = from[0];
+      if (outer_header_length <= VLIB_BUFFER_PRE_DATA_SIZE)
+        b[0] = bi0;
+      to_next[0] = b[0];
+      from += 1;
+      to_next += 1;
+      n_left_from -= 1;
+      n_left_to_next -= 1;
+
+      b0 = vlib_get_buffer (vm, bi0);
+
+      ip0 = vlib_buffer_get_current (b0);
+      if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        new_ip0 = vlib_buffer_get_current (bufs[0]);
+
+      if (b0->flags & VNET_BUFFER_F_OFFLOAD)
+      {
+        vnet_calc_checksums_inline (vm, b0, 0, 1);
+        b0->flags &= ~VNET_BUFFER_F_OFFLOAD;
+      }
+
+      if (PREDICT_TRUE(!(b0->flags & VNET_BUFFER_F_LOCALLY_ORIGINATED)))
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[0]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[0]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[0]->current_length = outer_header_length;
+          bufs[0]->total_length_not_including_first_buffer = b0->current_length;
+          bufs[0]->next_buffer = bi0;
+          bufs[0]->trace_handle = b0->trace_handle;
+          clib_memcpy_fast (bufs[0]->opaque, b0->opaque, sizeof (b0->opaque));
+          clib_memcpy_fast (bufs[0]->opaque2, b0->opaque2, sizeof (b0->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b0, -outer_header_length);
+          new_ip0 = vlib_buffer_get_current (b0);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip0, ip0, 40);
+
+        hbh0 = (ip6_hop_by_hop_header_t *) (new_ip0 + 1);
+
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh0, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh0->protocol = 41; // not ip->protocol
+        /* Set outer Ip6 header destination and source address */
+        copy_ip6_address(&new_ip0->dst_address, &hm->dst_addr);
+        copy_ip6_address(&new_ip0->src_address, &hm->src_addr);
+
+        new_ip0->protocol = 0;
+
+        new_l0 =
+          clib_net_to_host_u16 (new_ip0->payload_length) + outer_header_length;
+        new_ip0->payload_length = clib_host_to_net_u16 (new_l0);
+      }
+      else
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          /* Adapt new buffer's metadata */
+          bufs[0]->flags |= VNET_BUFFER_F_LOCALLY_ORIGINATED;
+          bufs[0]->flags |= VLIB_BUFFER_NEXT_PRESENT;
+          bufs[0]->flags |= VLIB_BUFFER_TOTAL_LENGTH_VALID;
+          bufs[0]->current_length = outer_header_length;
+          bufs[0]->total_length_not_including_first_buffer = b0->current_length - 40;
+          bufs[0]->next_buffer = bi0;
+          bufs[0]->trace_handle = b0->trace_handle;
+          clib_memcpy_fast (bufs[0]->opaque, b0->opaque, sizeof (b0->opaque));
+          clib_memcpy_fast (bufs[0]->opaque2, b0->opaque2, sizeof (b0->opaque2));
+        }
+        else
+        {
+          vlib_buffer_advance (b0, -rewrite_length);
+          new_ip0 = vlib_buffer_get_current (b0);
+        }
+
+        /* Copy ip header to new area */
+        clib_memcpy_fast (new_ip0, ip0, 40);
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+          vlib_buffer_advance(b0, 40);
+
+        hbh0 = (ip6_hop_by_hop_header_t *) (new_ip0 + 1);
+        /* $$$ tune, rewrite_length is a multiple of 8 */
+        clib_memcpy_fast (hbh0, rewrite, rewrite_length);
+        /* Patch the protocol chain, insert the h-b-h (type 0) header */
+        hbh0->protocol = new_ip0->protocol;
+        new_ip0->protocol = 0;
+
+        new_l0 =
+          clib_net_to_host_u16 (new_ip0->payload_length) + rewrite_length;
+        new_ip0->payload_length = clib_host_to_net_u16 (new_l0);
+      }
+
+      /* Populate the (first) h-b-h list elt */
+      next0 = IP6_HBYH_IOAM_INPUT_NEXT_IP6_LOOKUP;
+
+      if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)
+            && (b0->flags & VLIB_BUFFER_IS_TRACED)))
+      {
+        if (outer_header_length > VLIB_BUFFER_PRE_DATA_SIZE)
+        {
+          bufs[0]->flags |= VLIB_BUFFER_IS_TRACED;
+          ip6_add_hop_by_hop_trace_t *t =
+            vlib_add_trace (vm, node, bufs[0], sizeof (*t));
+          t->next_index = next0;
+        }
+        else
+        {
+          ip6_add_hop_by_hop_trace_t *t =
+            vlib_add_trace (vm, node, b0, sizeof (*t));
+          t->next_index = next0;
+        }
+      }
+
+	    processed++;
+
+      /* verify speculative enqueue, maybe switch current next frame */
+      vlib_validate_buffer_enqueue_x1 (vm, node, next_index,
+              to_next, n_left_to_next,
+              b[0], next0);
+      
+      b += 1;
+      bufs += 1;
+	  }
+
+    vlib_put_next_frame (vm, node, next_index, n_left_to_next);
+  }
+
+  vlib_node_increment_counter (vm, ip6_add_hop_by_hop_node.index,
+			       IP6_ADD_HOP_BY_HOP_ERROR_PROCESSED, processed);
+  vlib_node_increment_counter (vm, ip6_add_hop_by_hop_node.index,
+			       IP6_ADD_HOP_BY_HOP_ERROR_SRC_ADDR_FAILED, no_src_addr);
+  vlib_node_increment_counter (vm, ip6_add_hop_by_hop_node.index,
+			       IP6_ADD_HOP_BY_HOP_ERROR_ALLOC_ERR, alloc_err);
+
+  return frame->n_vectors;
+}
+
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (ip6_add_hop_by_hop_node) =	/* *INDENT-OFF* */
+{
+  .name = "ip6-add-hop-by-hop",
+  .vector_size = sizeof (u32),
+  .format_trace = format_ip6_add_hop_by_hop_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+  .n_errors = ARRAY_LEN (ip6_add_hop_by_hop_error_strings),
+  .error_strings = ip6_add_hop_by_hop_error_strings,
+  /* See ip/lookup.h */
+  .n_next_nodes = IP6_HBYH_IOAM_INPUT_N_NEXT,
+  .next_nodes = {
+#define _(s,n) [IP6_HBYH_IOAM_INPUT_NEXT_##s] = n,
+    foreach_ip6_hbyh_ioam_input_next
+#undef _
+  },
+};
+/* *INDENT-ON* */
+
+/* The main h-b-h tracer was already invoked, no need to do much here */
+typedef struct
+{
+  u32 next_index;
+} ip6_pop_hop_by_hop_trace_t;
+
+/* packet trace format function */
+static u8 *
+format_ip6_pop_hop_by_hop_trace (u8 * s, va_list * args)
+{
+  CLIB_UNUSED (vlib_main_t * vm) = va_arg (*args, vlib_main_t *);
+  CLIB_UNUSED (vlib_node_t * node) = va_arg (*args, vlib_node_t *);
+  ip6_pop_hop_by_hop_trace_t *t =
+    va_arg (*args, ip6_pop_hop_by_hop_trace_t *);
+
+  s = format (s, "IP6_POP_HOP_BY_HOP: next index %d", t->next_index);
+
+  return s;
+}
+
+#ifndef CLIB_MARCH_VARIANT
+int
+ip6_hbh_pop_register_option (u8 option,
+			     int options (vlib_buffer_t * b,
+					  ip6_header_t * ip,
+					  ip6_hop_by_hop_option_t * opt))
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->pop_options));
+
+  /* Already registered */
+  if (hm->pop_options[option])
+    return (-1);
+
+  hm->pop_options[option] = options;
+
+  return (0);
+}
+
+int
+ip6_hbh_pop_unregister_option (u8 option)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  ASSERT ((u32) option < ARRAY_LEN (hm->pop_options));
+
+  /* Not registered */
+  if (!hm->pop_options[option])
+    return (-1);
+
+  hm->pop_options[option] = NULL;
+
+  return (0);
+}
+#endif /* CLIB_MARCH_VARIANT */
+
+extern vlib_node_registration_t ip6_pop_hop_by_hop_node;
+
+#define foreach_ip6_pop_hop_by_hop_error                \
+_(PROCESSED, "Pkts w/ removed ip6 hop-by-hop options")  \
+_(NO_HOHO, "Pkts w/ no ip6 hop-by-hop options")         \
+_(OPTION_FAILED, "ip6 pop hop-by-hop failed to process")
+
+typedef enum
+{
+#define _(sym,str) IP6_POP_HOP_BY_HOP_ERROR_##sym,
+  foreach_ip6_pop_hop_by_hop_error
+#undef _
+    IP6_POP_HOP_BY_HOP_N_ERROR,
+} ip6_pop_hop_by_hop_error_t;
+
+static char *ip6_pop_hop_by_hop_error_strings[] = {
+#define _(sym,string) string,
+  foreach_ip6_pop_hop_by_hop_error
+#undef _
+};
+
+static inline void
+ioam_pop_hop_by_hop_processing (vlib_main_t * vm,
+				ip6_header_t * ip0,
+				ip6_hop_by_hop_header_t * hbh0,
+				vlib_buffer_t * b)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  ip6_hop_by_hop_option_t *opt0, *limit0;
+  u8 type0;
+
+  if (!hbh0 || !ip0)
+    return;
+
+  opt0 = (ip6_hop_by_hop_option_t *) (hbh0 + 1);
+  limit0 = (ip6_hop_by_hop_option_t *)
+    ((u8 *) hbh0 + ((hbh0->length + 1) << 3));
+
+  /* Scan the set of h-b-h options, process ones that we understand */
+  while (opt0 < limit0)
+  {
+    type0 = opt0->type;
+    switch (type0)
+    {
+      case 0:		/* Pad1 */
+        opt0 = (ip6_hop_by_hop_option_t *) ((u8 *) opt0) + 1;
+        continue;
+      case 1:		/* PadN */
+        break;
+      default:
+        if (hm->pop_options[type0])
+        {
+          if ((*hm->pop_options[type0]) (b, ip0, opt0) < 0)
+          {
+            vlib_node_increment_counter (vm,
+                        ip6_pop_hop_by_hop_node.index,
+                        IP6_POP_HOP_BY_HOP_ERROR_OPTION_FAILED,
+                        1);
+          }
+        }
+    }
+    opt0 =
+	        (ip6_hop_by_hop_option_t *) (((u8 *) opt0) + opt0->length +
+				  sizeof (ip6_hop_by_hop_option_t));
+  }
+}
+
+VLIB_NODE_FN (ip6_pop_hop_by_hop_node) (vlib_main_t * vm,
+					vlib_node_runtime_t * node,
+					vlib_frame_t * frame)
+{
+  u32 n_left_from, *from, *to_next;
+  ip_lookup_next_t next_index;
+  u32 processed = 0;
+  u32 no_header = 0;
+
+  from = vlib_frame_vector_args (frame);
+  n_left_from = frame->n_vectors;
+  next_index = node->cached_next_index;
+
+  while (n_left_from > 0)
+  {
+    u32 n_left_to_next;
+
+    vlib_get_next_frame (vm, node, next_index, to_next, n_left_to_next);
+
+    while (n_left_from >= 4 && n_left_to_next >= 2)
+	{
+	  u32 bi0, bi1;
+	  vlib_buffer_t *b0, *b1;
+	  u32 next0, next1;
+	  u32 adj_index0, adj_index1;
+	  ip6_header_t *ip0, *ip1;
+	  ip_adjacency_t *adj0, *adj1;
+	  ip6_hop_by_hop_header_t *hbh0, *hbh1;
+	  u64 *copy_dst0, *copy_src0, *copy_dst1, *copy_src1;
+	  u16 new_l0, new_l1;
+
+	  /* Prefetch next iteration. */
+	  {
+	    vlib_buffer_t *p2, *p3;
+
+	    p2 = vlib_get_buffer (vm, from[2]);
+	    p3 = vlib_get_buffer (vm, from[3]);
+
+	    vlib_prefetch_buffer_header (p2, LOAD);
+	    vlib_prefetch_buffer_header (p3, LOAD);
+
+	    CLIB_PREFETCH (p2->data, CLIB_CACHE_LINE_BYTES, STORE);
+	    CLIB_PREFETCH (p3->data, CLIB_CACHE_LINE_BYTES, STORE);
+	  }
+
+	  /* speculatively enqueue b0 and b1 to the current next frame */
+	  to_next[0] = bi0 = from[0];
+	  to_next[1] = bi1 = from[1];
+	  from += 2;
+	  to_next += 2;
+	  n_left_from -= 2;
+	  n_left_to_next -= 2;
+
+	  b0 = vlib_get_buffer (vm, bi0);
+	  b1 = vlib_get_buffer (vm, bi1);
+
+	  /* $$$$$ Dual loop: process 2 x packets here $$$$$ */
+	  ip0 = vlib_buffer_get_current (b0);
+	  ip1 = vlib_buffer_get_current (b1);
+	  adj_index0 = vnet_buffer (b0)->ip.adj_index[VLIB_TX];
+	  adj_index1 = vnet_buffer (b1)->ip.adj_index[VLIB_TX];
+	  adj0 = adj_get (adj_index0);
+	  adj1 = adj_get (adj_index1);
+
+	  next0 = adj0->lookup_next_index;
+	  next1 = adj1->lookup_next_index;
+
+	  hbh0 = (ip6_hop_by_hop_header_t *) (ip0 + 1);
+	  hbh1 = (ip6_hop_by_hop_header_t *) (ip1 + 1);
+
+	  ioam_pop_hop_by_hop_processing (vm, ip0, hbh0, b0);
+	  ioam_pop_hop_by_hop_processing (vm, ip1, hbh1, b1);
+
+	  vlib_buffer_advance (b0, (hbh0->length + 1) << 3);
+	  vlib_buffer_advance (b1, (hbh1->length + 1) << 3);
+
+	  new_l0 = clib_net_to_host_u16 (ip0->payload_length) -
+	    ((hbh0->length + 1) << 3);
+	  new_l1 = clib_net_to_host_u16 (ip1->payload_length) -
+	    ((hbh1->length + 1) << 3);
+
+	  ip0->payload_length = clib_host_to_net_u16 (new_l0);
+	  ip1->payload_length = clib_host_to_net_u16 (new_l1);
+
+	  ip0->protocol = hbh0->protocol;
+	  ip1->protocol = hbh1->protocol;
+
+	  copy_src0 = (u64 *) ip0;
+	  copy_src1 = (u64 *) ip1;
+	  copy_dst0 = copy_src0 + (hbh0->length + 1);
+	  copy_dst0[4] = copy_src0[4];
+	  copy_dst0[3] = copy_src0[3];
+	  copy_dst0[2] = copy_src0[2];
+	  copy_dst0[1] = copy_src0[1];
+	  copy_dst0[0] = copy_src0[0];
+	  copy_dst1 = copy_src1 + (hbh1->length + 1);
+	  copy_dst1[4] = copy_src1[4];
+	  copy_dst1[3] = copy_src1[3];
+	  copy_dst1[2] = copy_src1[2];
+	  copy_dst1[1] = copy_src1[1];
+	  copy_dst1[0] = copy_src1[0];
+	  processed += 2;
+	  /* $$$$$ End of processing 2 x packets $$$$$ */
+
+	  if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)))
+	    {
+	      if (b0->flags & VLIB_BUFFER_IS_TRACED)
+		{
+		  ip6_pop_hop_by_hop_trace_t *t =
+		    vlib_add_trace (vm, node, b0, sizeof (*t));
+		  t->next_index = next0;
+		}
+	      if (b1->flags & VLIB_BUFFER_IS_TRACED)
+		{
+		  ip6_pop_hop_by_hop_trace_t *t =
+		    vlib_add_trace (vm, node, b1, sizeof (*t));
+		  t->next_index = next1;
+		}
+	    }
+
+	  /* verify speculative enqueues, maybe switch current next frame */
+	  vlib_validate_buffer_enqueue_x2 (vm, node, next_index,
+					   to_next, n_left_to_next,
+					   bi0, bi1, next0, next1);
+	}
+
+      while (n_left_from > 0 && n_left_to_next > 0)
+	{
+	  u32 bi0;
+	  vlib_buffer_t *b0;
+	  u32 next0;
+	  u32 adj_index0;
+	  ip6_header_t *ip0;
+	  ip_adjacency_t *adj0;
+	  ip6_hop_by_hop_header_t *hbh0;
+	  u64 *copy_dst0, *copy_src0;
+	  u16 new_l0;
+
+	  /* speculatively enqueue b0 to the current next frame */
+	  bi0 = from[0];
+	  to_next[0] = bi0;
+	  from += 1;
+	  to_next += 1;
+	  n_left_from -= 1;
+	  n_left_to_next -= 1;
+
+	  b0 = vlib_get_buffer (vm, bi0);
+
+	  ip0 = vlib_buffer_get_current (b0);
+	  adj_index0 = vnet_buffer (b0)->ip.adj_index[VLIB_TX];
+	  adj0 = adj_get (adj_index0);
+
+	  /* Default use the next_index from the adjacency. */
+	  next0 = adj0->lookup_next_index;
+
+	  /* Perfectly normal to end up here w/ out h-b-h header */
+	  hbh0 = (ip6_hop_by_hop_header_t *) (ip0 + 1);
+
+	  /* TODO:Temporarily doing it here.. do this validation in end_of_path_cb */
+	  ioam_pop_hop_by_hop_processing (vm, ip0, hbh0, b0);
+	  /* Pop the trace data */
+	  vlib_buffer_advance (b0, (hbh0->length + 1) << 3);
+	  new_l0 = clib_net_to_host_u16 (ip0->payload_length) -
+	    ((hbh0->length + 1) << 3);
+	  ip0->payload_length = clib_host_to_net_u16 (new_l0);
+	  ip0->protocol = hbh0->protocol;
+	  copy_src0 = (u64 *) ip0;
+	  copy_dst0 = copy_src0 + (hbh0->length + 1);
+	  copy_dst0[4] = copy_src0[4];
+	  copy_dst0[3] = copy_src0[3];
+	  copy_dst0[2] = copy_src0[2];
+	  copy_dst0[1] = copy_src0[1];
+	  copy_dst0[0] = copy_src0[0];
+	  processed++;
+
+	  if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)
+			     && (b0->flags & VLIB_BUFFER_IS_TRACED)))
+	    {
+	      ip6_pop_hop_by_hop_trace_t *t =
+		vlib_add_trace (vm, node, b0, sizeof (*t));
+	      t->next_index = next0;
+	    }
+
+	  /* verify speculative enqueue, maybe switch current next frame */
+	  vlib_validate_buffer_enqueue_x1 (vm, node, next_index,
+					   to_next, n_left_to_next,
+					   bi0, next0);
+	}
+
+      vlib_put_next_frame (vm, node, next_index, n_left_to_next);
+    }
+
+  vlib_node_increment_counter (vm, ip6_pop_hop_by_hop_node.index,
+			       IP6_POP_HOP_BY_HOP_ERROR_PROCESSED, processed);
+  vlib_node_increment_counter (vm, ip6_pop_hop_by_hop_node.index,
+			       IP6_POP_HOP_BY_HOP_ERROR_NO_HOHO, no_header);
+
+  return frame->n_vectors;
+}
+
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (ip6_pop_hop_by_hop_node) =
+{
+  .name = "ip6-pop-hop-by-hop",
+  .vector_size = sizeof (u32),
+  .format_trace = format_ip6_pop_hop_by_hop_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+  .sibling_of = "ip6-lookup",
+  .n_errors = ARRAY_LEN (ip6_pop_hop_by_hop_error_strings),
+  .error_strings = ip6_pop_hop_by_hop_error_strings,
+  /* See ip/lookup.h */
+  .n_next_nodes = 0,
+};
+/* *INDENT-ON* */
+
+typedef struct
+{
+  u32 protocol;
+  u32 next_index;
+} ip6_local_hop_by_hop_trace_t;
+
+#ifndef CLIB_MARCH_VARIANT
+
+/* packet trace format function */
+static u8 *
+format_ip6_local_hop_by_hop_trace (u8 * s, va_list * args)
+{
+  CLIB_UNUSED (vlib_main_t * vm) = va_arg (*args, vlib_main_t *);
+  CLIB_UNUSED (vlib_node_t * node) = va_arg (*args, vlib_node_t *);
+  ip6_local_hop_by_hop_trace_t *t =
+    va_arg (*args, ip6_local_hop_by_hop_trace_t *);
+
+  s = format (s, "IP6_LOCAL_HOP_BY_HOP: protocol %d,  next index %d\n",
+	      t->protocol, t->next_index);
+  return s;
+}
+
+vlib_node_registration_t ip6_local_hop_by_hop_node;
+
+#endif /* CLIB_MARCH_VARIANT */
+
+#define foreach_ip6_local_hop_by_hop_error                      \
+_(UNKNOWN, "Unknown protocol ip6 local h-b-h packets dropped")  \
+_(OK, "Good ip6 local h-b-h packets")
+
+typedef enum
+{
+#define _(sym,str) IP6_LOCAL_HOP_BY_HOP_ERROR_##sym,
+  foreach_ip6_local_hop_by_hop_error
+#undef _
+    IP6_LOCAL_HOP_BY_HOP_N_ERROR,
+} ip6_local_hop_by_hop_error_t;
+
+#ifndef CLIB_MARCH_VARIANT
+static char *ip6_local_hop_by_hop_error_strings[] = {
+#define _(sym,string) string,
+  foreach_ip6_local_hop_by_hop_error
+#undef _
+};
+#endif /* CLIB_MARCH_VARIANT */
+
+typedef enum
+{
+  IP6_LOCAL_HOP_BY_HOP_NEXT_DROP,
+  IP6_LOCAL_HOP_BY_HOP_N_NEXT,
+} ip6_local_hop_by_hop_next_t;
+
+always_inline uword
+ip6_local_hop_by_hop_inline (vlib_main_t * vm,
+			     vlib_node_runtime_t * node, vlib_frame_t * frame,
+			     int is_trace)
+{
+  u32 n_left_from, *from;
+  vlib_buffer_t *bufs[VLIB_FRAME_SIZE], **b;
+  u16 nexts[VLIB_FRAME_SIZE], *next;
+  u32 ok = 0;
+  u32 unknown_proto_error = node->errors[IP6_LOCAL_HOP_BY_HOP_ERROR_UNKNOWN];
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  /* Note: there is only one of these */
+  ip6_local_hop_by_hop_runtime_t *rt = hm->ip6_local_hbh_runtime;
+
+  from = vlib_frame_vector_args (frame);
+  n_left_from = frame->n_vectors;
+
+  vlib_get_buffers (vm, from, bufs, n_left_from);
+  b = bufs;
+  next = nexts;
+
+  while (n_left_from >= 4)
+  {
+    ip6_header_t *ip0, *ip1, *ip2, *ip3;
+    u8 *hbh0, *hbh1, *hbh2, *hbh3;
+
+    /* Prefetch next iteration. */
+    if (PREDICT_TRUE (n_left_from >= 8))
+    {
+      vlib_prefetch_buffer_header (b[4], STORE);
+      vlib_prefetch_buffer_header (b[5], STORE);
+      vlib_prefetch_buffer_header (b[6], STORE);
+      vlib_prefetch_buffer_header (b[7], STORE);
+      CLIB_PREFETCH (b[4]->data, CLIB_CACHE_LINE_BYTES, STORE);
+      CLIB_PREFETCH (b[5]->data, CLIB_CACHE_LINE_BYTES, STORE);
+      CLIB_PREFETCH (b[6]->data, CLIB_CACHE_LINE_BYTES, STORE);
+      CLIB_PREFETCH (b[7]->data, CLIB_CACHE_LINE_BYTES, STORE);
+    }
+
+    /*
+      * Leave current_data pointing at the IP header.
+      * It's reasonably likely that any registered handler
+      * will want to know where to find the ip6 header.
+      */
+    ip0 = vlib_buffer_get_current (b[0]);
+    ip1 = vlib_buffer_get_current (b[1]);
+    ip2 = vlib_buffer_get_current (b[2]);
+    ip3 = vlib_buffer_get_current (b[3]);
+
+    /* Look at hop-by-hop header */
+    hbh0 = ip6_next_header (ip0);
+    hbh1 = ip6_next_header (ip1);
+    hbh2 = ip6_next_header (ip2);
+    hbh3 = ip6_next_header (ip3);
+
+    /*
+    * ... to find the next header type and see if we
+    * have a handler for it...
+    */
+    next[0] = rt->next_index_by_protocol[*hbh0];
+    next[1] = rt->next_index_by_protocol[*hbh1];
+    next[2] = rt->next_index_by_protocol[*hbh2];
+    next[3] = rt->next_index_by_protocol[*hbh3];
+
+    b[0]->error = unknown_proto_error;
+    b[1]->error = unknown_proto_error;
+    b[2]->error = unknown_proto_error;
+    b[3]->error = unknown_proto_error;
+
+    /* Account for non-drop pkts */
+    ok += next[0] != 0;
+    ok += next[1] != 0;
+    ok += next[2] != 0;
+    ok += next[3] != 0;
+
+    if (is_trace)
+    {
+      if (b[0]->flags & VLIB_BUFFER_IS_TRACED)
+      {
+        ip6_local_hop_by_hop_trace_t *t =
+        vlib_add_trace (vm, node, b[0], sizeof (*t));
+        t->next_index = next[0];
+        t->protocol = *hbh0;
+      }
+      if (b[1]->flags & VLIB_BUFFER_IS_TRACED)
+      {
+        ip6_local_hop_by_hop_trace_t *t =
+        vlib_add_trace (vm, node, b[1], sizeof (*t));
+        t->next_index = next[1];
+        t->protocol = *hbh1;
+      }
+      if (b[2]->flags & VLIB_BUFFER_IS_TRACED)
+      {
+        ip6_local_hop_by_hop_trace_t *t =
+        vlib_add_trace (vm, node, b[2], sizeof (*t));
+        t->next_index = next[2];
+        t->protocol = *hbh2;
+      }
+      if (b[3]->flags & VLIB_BUFFER_IS_TRACED)
+      {
+        ip6_local_hop_by_hop_trace_t *t =
+        vlib_add_trace (vm, node, b[3], sizeof (*t));
+        t->next_index = next[3];
+        t->protocol = *hbh3;
+      }
+    }
+
+    ioam_pop_hop_by_hop_processing (vm, ip0, (ip6_hop_by_hop_header_t *) hbh0, b[0]);
+    ioam_pop_hop_by_hop_processing (vm, ip1, (ip6_hop_by_hop_header_t *) hbh1, b[1]);
+    ioam_pop_hop_by_hop_processing (vm, ip2, (ip6_hop_by_hop_header_t *) hbh2, b[2]);
+    ioam_pop_hop_by_hop_processing (vm, ip3, (ip6_hop_by_hop_header_t *) hbh3, b[3]);
+
+    /* In that case it is necessary to remove the IP header */
+    if (*hbh0 == IP_PROTOCOL_IPV6)
+    {
+      ip6_hop_by_hop_header_t *hbh_header = (ip6_hop_by_hop_header_t *) hbh0;
+      vlib_buffer_advance(b[0], (word) (40 + ((hbh_header->length + 1) << 3)));
+    }
+
+    if (*hbh1 == IP_PROTOCOL_IPV6)
+    {
+      ip6_hop_by_hop_header_t *hbh_header = (ip6_hop_by_hop_header_t *) hbh1;
+      vlib_buffer_advance(b[1], (word) (40 + ((hbh_header->length + 1) << 3)));
+    }
+
+    if (*hbh2 == IP_PROTOCOL_IPV6)
+    {
+      ip6_hop_by_hop_header_t *hbh_header = (ip6_hop_by_hop_header_t *) hbh2;
+      vlib_buffer_advance(b[2], (word) (40 + ((hbh_header->length + 1) << 3)));
+    }
+
+    if (*hbh3 == IP_PROTOCOL_IPV6)
+    {
+      ip6_hop_by_hop_header_t *hbh_header = (ip6_hop_by_hop_header_t *) hbh3;
+      vlib_buffer_advance(b[3], (word) (40 + ((hbh_header->length + 1) << 3)));
+    }
+
+    b += 4;
+    next += 4;
+    n_left_from -= 4;
+  }
+
+  while (n_left_from > 0)
+  {
+    ip6_header_t *ip0;
+    u8 *hbh0;
+
+    ip0 = vlib_buffer_get_current (b[0]);
+
+    hbh0 = ip6_next_header (ip0);
+
+    next[0] = rt->next_index_by_protocol[*hbh0];
+
+    b[0]->error = unknown_proto_error;
+    ok += next[0] != 0;
+
+    if (is_trace)
+    {
+      if (b[0]->flags & VLIB_BUFFER_IS_TRACED)
+      {
+        ip6_local_hop_by_hop_trace_t *t =
+        vlib_add_trace (vm, node, b[0], sizeof (*t));
+        t->next_index = next[0];
+        t->protocol = *hbh0;
+      }
+    }
+
+    ioam_pop_hop_by_hop_processing (vm, ip0, (ip6_hop_by_hop_header_t *) hbh0, b[0]);
+
+    /* In that case it is necessary to remove the IP header */
+    if (*hbh0 == IP_PROTOCOL_IPV6)
+    {
+      ip6_hop_by_hop_header_t *hbh_header = (ip6_hop_by_hop_header_t *) hbh0;
+      vlib_buffer_advance(b[0], (word) (40 + ((hbh_header->length + 1) << 3)));
+    }
+
+    b += 1;
+    next += 1;
+    n_left_from -= 1;
+  }
+
+  vlib_buffer_enqueue_to_next (vm, node, from, nexts, frame->n_vectors);
+
+  vlib_node_increment_counter (vm, node->node_index,
+			       IP6_LOCAL_HOP_BY_HOP_ERROR_OK, ok);
+  return frame->n_vectors;
+}
+
+VLIB_NODE_FN (ip6_local_hop_by_hop_node) (vlib_main_t * vm,
+					  vlib_node_runtime_t * node,
+					  vlib_frame_t * frame)
+{
+  if (PREDICT_FALSE (node->flags & VLIB_NODE_FLAG_TRACE))
+    return ip6_local_hop_by_hop_inline (vm, node, frame, 1 /* is_trace */ );
+  else
+    return ip6_local_hop_by_hop_inline (vm, node, frame, 0 /* is_trace */ );
+}
+
+#ifndef CLIB_MARCH_VARIANT
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (ip6_local_hop_by_hop_node) =
+{
+  .name = "ip6-local-hop-by-hop",
+  .vector_size = sizeof (u32),
+  .format_trace = format_ip6_local_hop_by_hop_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+
+  .n_errors = ARRAY_LEN(ip6_local_hop_by_hop_error_strings),
+  .error_strings = ip6_local_hop_by_hop_error_strings,
+
+  .n_next_nodes = IP6_LOCAL_HOP_BY_HOP_N_NEXT,
+
+  /* edit / add dispositions here */
+  .next_nodes =
+  {
+    [IP6_LOCAL_HOP_BY_HOP_NEXT_DROP] = "error-drop",
+  },
+};
+/* *INDENT-ON* */
+
+clib_error_t *
+show_ip6_hbh_command_fn (vlib_main_t * vm,
+			 unformat_input_t * input, vlib_cli_command_t * cmd)
+{
+  int i;
+  u32 next_index;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  ip6_local_hop_by_hop_runtime_t *rt = hm->ip6_local_hbh_runtime;
+  vlib_node_t *n = vlib_get_node (vm, ip6_local_hop_by_hop_node.index);
+
+  vlib_cli_output (vm, "%-6s%s", "Proto", "Node Name");
+
+  for (i = 0; i < ARRAY_LEN (rt->next_index_by_protocol); i++)
+  {
+    if ((next_index = rt->next_index_by_protocol[i]))
+    {
+      u32 next_node_index = n->next_nodes[next_index];
+      vlib_node_t *next_n = vlib_get_node (vm, next_node_index);
+      vlib_cli_output (vm, "[%3d] %v", i, next_n->name);
+    }
+  }
+  return 0;
+}
+
+/*?
+ * Display the set of ip6 local hop-by-hop next protocol handler nodes
+ *
+ * @cliexpar
+ * Display ip6 local hop-by-hop next protocol handler nodes
+ * @cliexcmd{show ip6 hbh}
+?*/
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (show_ip6_hbh, static) = {
+  .path = "show ip6 hbh",
+  .short_help = "show ip6 hbh",
+  .function = show_ip6_hbh_command_fn,
+};
+/* *INDENT-ON* */
+
+
+#endif /* CLIB_MARCH_VARIANT */
+
+
+#ifndef CLIB_MARCH_VARIANT
+static clib_error_t *
+ip6_hop_by_hop_ioam_init (vlib_main_t * vm)
+{
+  clib_error_t *error;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  if ((error = vlib_call_init_function (vm, ip_main_init)))
+    return (error);
+
+  if ((error = vlib_call_init_function (vm, ip6_lookup_init)))
+    return error;
+
+  hm->vlib_main = vm;
+  hm->vnet_main = vnet_get_main ();
+  hm->unix_time_0 = (u32) time (0);	/* Store starting time */
+  hm->vlib_time_0 = vlib_time_now (vm);
+  hm->ioam_flag = IOAM_HBYH_MOD;
+  clib_memset (hm->add_options, 0, sizeof (hm->add_options));
+  clib_memset (hm->pop_options, 0, sizeof (hm->pop_options));
+  clib_memset (hm->options_size, 0, sizeof (hm->options_size));
+
+  vnet_classify_register_unformat_opaque_index_fn (unformat_opaque_ioam);
+  hm->ip6_local_hbh_runtime = clib_mem_alloc_aligned
+    (sizeof (ip6_local_hop_by_hop_runtime_t), CLIB_CACHE_LINE_BYTES);
+
+  memset (hm->ip6_local_hbh_runtime, 0,
+	  sizeof (ip6_local_hop_by_hop_runtime_t));
+
+  ip6_register_protocol (IP_PROTOCOL_IP6_HOP_BY_HOP_OPTIONS,
+			 ip6_local_hop_by_hop_node.index);
+  ip6_local_hop_by_hop_register_protocol (IP_PROTOCOL_IPV6,
+       ip6_lookup_node.index);
+  return (0);
+}
+
+/* *INDENT-OFF* */
+VLIB_INIT_FUNCTION (ip6_hop_by_hop_ioam_init) =
+{
+  .runs_after = VLIB_INITS("ip_main_init", "ip6_lookup_init"),
+};
+/* *INDENT-ON* */
+
+void
+ip6_local_hop_by_hop_register_protocol (u32 protocol, u32 node_index)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  vlib_main_t *vm = hm->vlib_main;
+  ip6_local_hop_by_hop_runtime_t *local_hbh_runtime
+    = hm->ip6_local_hbh_runtime;
+  u32 old_next_index;
+
+
+  ASSERT (protocol < ARRAY_LEN (local_hbh_runtime->next_index_by_protocol));
+
+  old_next_index = local_hbh_runtime->next_index_by_protocol[protocol];
+
+  local_hbh_runtime->next_index_by_protocol[protocol] =
+    vlib_node_add_next (vm, ip6_local_hop_by_hop_node.index, node_index);
+
+  /* Someone will eventually do this. Trust me. */
+  if (old_next_index &&
+      (old_next_index != local_hbh_runtime->next_index_by_protocol[protocol]))
+  {
+    clib_warning ("WARNING: replaced next index for protocol %d", protocol);
+  }
+}
+
+int
+ip6_ioam_set_rewrite (u8 ** rwp, int has_trace_option,
+		      int has_pot_option, int has_seqno_option)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  u8 *rewrite = NULL;
+  u32 size, rnd_size;
+  ip6_hop_by_hop_header_t *hbh;
+  u8 *current;
+  u8 *trace_data_size = NULL;
+  u8 *pot_data_size = NULL;
+
+  vec_free (*rwp);
+
+  if (has_trace_option == 0 && has_pot_option == 0)
+    return -1;
+
+  /* Work out how much space we need */
+  size = sizeof (ip6_hop_by_hop_header_t);
+
+  //if (has_trace_option && hm->get_sizeof_options[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] != 0)
+  if (has_trace_option
+      && hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] != 0)
+  {
+    size += hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST];
+  }
+  if (has_pot_option
+      && hm->add_options[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT] != 0)
+  {
+    size += hm->options_size[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT];
+  }
+
+  if (has_seqno_option)
+  {
+    size += hm->options_size[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE];
+  }
+
+  /* Round to a multiple of 8 octets */
+  rnd_size = (size + 7) & ~7;
+
+  /* allocate it, zero-fill / pad by construction */
+  vec_validate (rewrite, rnd_size - 1);
+
+  hbh = (ip6_hop_by_hop_header_t *) rewrite;
+  /* Length of header in 8 octet units, not incl first 8 octets */
+  // LENGTH_SET_HERE
+  hbh->length = (rnd_size >> 3) - 1;
+  current = (u8 *) (hbh + 1);
+
+  if (has_trace_option
+      && hm->add_options[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] != 0)
+  {
+    if (0 != (hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST]))
+	  {
+	    trace_data_size =
+	      &hm->options_size[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST];
+	    if (0 ==
+	      hm->add_options[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] (current,
+								     trace_data_size))
+      {
+        current += *trace_data_size;
+      }
+	  }
+  }
+  if (has_pot_option
+      && hm->add_options[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT] != 0)
+  {
+    pot_data_size =
+	    &hm->options_size[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT];
+    if (0 ==
+	    hm->add_options[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT] (current,
+								    pot_data_size))
+    {
+      current += *pot_data_size;
+    }
+  }
+  if (has_seqno_option &&
+      (hm->add_options[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE] != 0))
+  {
+    if (0 == hm->add_options[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE] (current,
+								   &
+								   (hm->options_size
+								    [HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE])))
+    {
+      current += hm->options_size[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE];
+    }
+  }
+  *rwp = rewrite;
+  return 0;
+}
+
+clib_error_t *
+clear_ioam_rewrite_fn (void)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  vec_free (hm->rewrite);
+  hm->rewrite = 0;
+  hm->has_trace_option = 0;
+  hm->has_pot_option = 0;
+  hm->has_seqno_option = 0;
+  hm->has_analyse_option = 0;
+  if (hm->config_handler[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST])
+    hm->config_handler[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] (NULL, 1);
+
+  if (hm->config_handler[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT])
+    hm->config_handler[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT] (NULL, 1);
+
+  if (hm->config_handler[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE])
+    {
+      hm->config_handler[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE] ((void *)
+							     &hm->has_analyse_option,
+							     1);
+    }
+  return 0;
+}
+
+clib_error_t *
+clear_ioam_rewrite_command_fn (vlib_main_t * vm,
+			       unformat_input_t * input,
+			       vlib_cli_command_t * cmd)
+{
+  return (clear_ioam_rewrite_fn ());
+}
+
+/*?
+ * This command clears all the In-band OAM (iOAM) features enabled by
+ * the '<em>set ioam rewrite</em>' command. Use '<em>show ioam summary</em>' to
+ * verify the configured settings cleared.
+ *
+ * @cliexpar
+ * Example of how to clear iOAM features:
+ * @cliexcmd{clear ioam rewrite}
+?*/
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (ip6_clear_ioam_rewrite_cmd, static) = {
+  .path = "clear ioam rewrite",
+  .short_help = "clear ioam rewrite",
+  .function = clear_ioam_rewrite_command_fn,
+};
+/* *INDENT-ON* */
+
+clib_error_t *
+ip6_ioam_enable (int has_trace_option, int has_pot_option,
+		 int has_seqno_option, int has_analyse_option, ip6_address_t* dst_addr)
+{
+  int rv;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  rv = ip6_ioam_set_rewrite (&hm->rewrite, has_trace_option,
+			     has_pot_option, has_seqno_option);
+
+  switch (rv)
+  {
+    case 0:
+      copy_ip6_address(&hm->dst_addr, dst_addr);
+
+      /* Compute outer Ip6 header source address for beginning of IOAM tunnel */
+      u32 fib_index, sw_if_index;
+      u32 table_id = 0;
+      fib_index = ip6_fib_index_from_table_id (table_id);
+      fib_node_index_t fib_entry_index = ip6_fib_table_lookup (fib_index, &hm->dst_addr, 128);
+      sw_if_index = fib_entry_get_resolving_interface (fib_entry_index);
+
+      if (PREDICT_FALSE((~0 == fib_index) || (~0 == sw_if_index)))
+        return clib_error_return_code (0, -1, 0, 
+            "ip6_ioam_set_rewrite returned %d", -1);
+
+      if (PREDICT_FALSE(!fib_sas6_get (sw_if_index, dst_addr, &hm->src_addr)))
+        return clib_error_return_code (0, -1, 0, 
+            "ip6_ioam_set_rewrite returned %d", -1);
+
+      if (has_trace_option)
+	    {
+	      hm->has_trace_option = has_trace_option;
+	      if (hm->config_handler[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST])
+	      {
+          hm->config_handler[HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST] (NULL, 0);
+	      }
+      }
+
+      if (has_pot_option)
+      {
+        hm->has_pot_option = has_pot_option;
+        if (hm->config_handler[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT])
+        {
+          hm->config_handler[HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT] (NULL, 0);
+        }
+      }
+      hm->has_analyse_option = has_analyse_option;
+      if (has_seqno_option)
+      {
+        hm->has_seqno_option = has_seqno_option;
+        if (hm->config_handler[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE])
+        {
+          hm->config_handler[HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE] ((void *)&has_analyse_option, 0);
+        }
+      }
+      break;
+
+    default:
+      return clib_error_return_code (0, rv, 0, 
+              "ip6_ioam_set_rewrite returned %d", rv);
+  }
+  return 0;
+}
+
+
+static clib_error_t *
+ip6_set_ioam_rewrite_command_fn (vlib_main_t * vm,
+				 unformat_input_t * input,
+				 vlib_cli_command_t * cmd)
+{
+  int has_dst_addr = 0;
+  int has_trace_option = 0;
+  int has_pot_option = 0;
+  int has_seqno_option = 0;
+  int has_analyse_option = 0;
+  ip6_address_t dst_addr;
+  clib_error_t *rv = 0;
+
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT)
+  {
+    if (unformat (input, "dst_addr %U", unformat_ip6_address, &dst_addr))
+      has_dst_addr = 1;
+    else if (unformat (input, "trace"))
+      has_trace_option = 1;
+    else if (unformat (input, "pot"))
+      has_pot_option = 1;
+    else if (unformat (input, "seqno"))
+      has_seqno_option = 1;
+    else if (unformat (input, "analyse"))
+      has_analyse_option = 1;
+    else
+      break;
+  }
+
+  if (!has_dst_addr)
+    return clib_error_return (0, "- ERROR: Destination address of IOAM tunnel is required\n");
+
+  rv = ip6_ioam_enable (has_trace_option, has_pot_option,
+			has_seqno_option, has_analyse_option, &dst_addr);
+  return rv;
+}
+
+/*?
+ * This command is used to enable In-band OAM (iOAM) features on IPv6.
+ * '<em>trace</em>' is used to enable iOAM trace feature. '<em>pot</em>' is used to
+ * enable the Proof Of Transit feature. '<em>ppc</em>' is used to indicate the
+ * Per Packet Counter feature for Edge to Edge processing. '<em>ppc</em>' is
+ * used to indicate if this node is an '<em>encap</em>' node (iOAM edge node
+ * where packet enters iOAM domain), a '<em>decap</em>' node (iOAM edge node
+ * where packet leaves iOAM domain) or '<em>none</em>' (iOAM node where packet
+ * is in-transit through the iOAM domain). '<em>ppc</em>' can only be set if
+ * '<em>trace</em>' or '<em>pot</em>' is enabled.
+ *
+ * Use '<em>clear ioam rewrite</em>' to disable all features enabled by this
+ * command. Use '<em>show ioam summary</em>' to verify the configured settings.
+ *
+ * @cliexpar
+ * Example of how to enable trace and pot with ppc set to encap:
+ * @cliexcmd{set ioam rewrite trace pot ppc encap}
+?*/
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (ip6_set_ioam_rewrite_cmd, static) = {
+  .path = "set ioam rewrite",
+  .short_help = "set ioam dst_addr <dest address> [trace] [pot] [seqno] [analyse]",
+  .function = ip6_set_ioam_rewrite_command_fn,
+};
+/* *INDENT-ON* */
+
+static clib_error_t *
+ip6_show_ioam_summary_cmd_fn (vlib_main_t * vm,
+			      unformat_input_t * input,
+			      vlib_cli_command_t * cmd)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  u8 *s = 0;
+
+
+  if (!is_zero_ip6_address (&hm->adj))
+    {
+      s = format (s, "              REWRITE FLOW CONFIGS - \n");
+      s = format (s, "               Destination Address : %U\n",
+		  format_ip6_address, &hm->adj, sizeof (ip6_address_t));
+      s =
+	format (s, "                    Flow operation : %d (%s)\n",
+		hm->ioam_flag,
+		(hm->ioam_flag ==
+		 IOAM_HBYH_ADD) ? "Add" : ((hm->ioam_flag ==
+					    IOAM_HBYH_MOD) ? "Mod" : "Pop"));
+    }
+  else
+    {
+      s = format (s, "              REWRITE FLOW CONFIGS - Not configured\n");
+    }
+
+
+  s = format (s, "                        TRACE OPTION - %d (%s)\n",
+	      hm->has_trace_option,
+	      (hm->has_trace_option ? "Enabled" : "Disabled"));
+  if (hm->has_trace_option)
+    s =
+      format (s,
+	      "Try 'show ioam trace and show ioam-trace profile' for more information\n");
+
+
+  s = format (s, "                        POT OPTION - %d (%s)\n",
+	      hm->has_pot_option,
+	      (hm->has_pot_option ? "Enabled" : "Disabled"));
+  if (hm->has_pot_option)
+    s =
+      format (s,
+	      "Try 'show ioam pot and show pot profile' for more information\n");
+
+  s = format (s, "         EDGE TO EDGE - SeqNo OPTION - %d (%s)\n",
+	      hm->has_seqno_option,
+	      hm->has_seqno_option ? "Enabled" : "Disabled");
+  if (hm->has_seqno_option)
+    s = format (s, "Try 'show ioam e2e' for more information\n");
+
+  s = format (s, "         iOAM Analyse OPTION - %d (%s)\n",
+	      hm->has_analyse_option,
+	      hm->has_analyse_option ? "Enabled" : "Disabled");
+
+  s = format (s, "         IOAM rewrite length - %u \n",
+	      vec_len(hm->rewrite));
+
+  vlib_cli_output (vm, "%v", s);
+  vec_free (s);
+  return 0;
+}
+
+/*?
+ * This command displays the current configuration data for In-band
+ * OAM (iOAM).
+ *
+ * @cliexpar
+ * Example to show the iOAM configuration:
+ * @cliexstart{show ioam summary}
+ *               REWRITE FLOW CONFIGS -
+ *                Destination Address : ff02::1
+ *                     Flow operation : 2 (Pop)
+ *                         TRACE OPTION - 1 (Enabled)
+ * Try 'show ioam trace and show ioam-trace profile' for more information
+ *                         POT OPTION - 1 (Enabled)
+ * Try 'show ioam pot and show pot profile' for more information
+ *          EDGE TO EDGE - PPC OPTION - 1 (Encap)
+ * @cliexend
+?*/
+/* *INDENT-OFF* */
+VLIB_CLI_COMMAND (ip6_show_ioam_run_cmd, static) = {
+  .path = "show ioam summary",
+  .short_help = "show ioam summary",
+  .function = ip6_show_ioam_summary_cmd_fn,
+};
+/* *INDENT-ON* */
+
+void
+vnet_register_ioam_end_of_path_callback (void *cb)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  hm->ioam_end_of_path_cb = cb;
+}
+
+#endif /* CLIB_MARCH_VARIANT */
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ip/ip6_hop_by_hop.h b/src/plugins/ip/ip6_hop_by_hop.h
new file mode 100644
index 000000000..3c17ce3e9
--- /dev/null
+++ b/src/plugins/ip/ip6_hop_by_hop.h
@@ -0,0 +1,296 @@
+/*
+ * Copyright (c) 2016 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef __included_ip6_hop_by_hop_ioam_h__
+#define __included_ip6_hop_by_hop_ioam_h__
+
+#include <vnet/ip/ip6_hop_by_hop_packet.h>
+#include <vnet/ip/ip.h>
+
+
+#define MAX_IP6_HBH_OPTION      256
+
+/* To determine whether a node is decap MS bit is set */
+#define IOAM_DECAP_BIT 0x80000000
+
+#define IOAM_DEAP_ENABLED(opaque_data) (opaque_data & IOAM_DECAP_BIT)
+
+#define IOAM_SET_DECAP(opaque_data) \
+    (opaque_data |= IOAM_DECAP_BIT)
+
+#define IOAM_MASK_DECAP_BIT(x) (x & ~IOAM_DECAP_BIT)
+
+/*
+ * Stores the run time flow data of hbh options
+ */
+typedef struct
+{
+  u32 ctx[MAX_IP6_HBH_OPTION];
+  u8 flow_name[64];
+} flow_data_t;
+
+typedef struct
+{
+  u8 next_index_by_protocol[256];
+} ip6_local_hop_by_hop_runtime_t;
+
+typedef struct
+{ 
+  /* The current rewrite we're using */
+  u8 *rewrite;
+
+  /* Trace data processing callback */
+  void *ioam_end_of_path_cb;
+  /* Configuration data */
+  /* Adjacency */
+  ip6_address_t adj;
+#define IOAM_HBYH_ADD  0
+#define IOAM_HBYH_MOD  1
+#define IOAM_HBYH_POP  2
+  u8 ioam_flag;
+  /* time scale transform. Joy. */
+  u32 unix_time_0;
+  f64 vlib_time_0;
+
+  /* End of IOAM tunnel */
+  ip6_address_t dst_addr;
+
+  /* Source of IOAM tunnel */
+  ip6_address_t src_addr;
+
+  /* Trace option */
+  u8 has_trace_option;
+
+  /* Pot option */
+  u8 has_pot_option;
+
+  /* Per Packet Counter option */
+  u8 has_seqno_option;
+
+  /* Enabling analyis of iOAM data on decap node */
+  u8 has_analyse_option;
+
+  /* Array of function pointers to ADD and POP HBH option handling routines */
+  u8 options_size[MAX_IP6_HBH_OPTION];
+  int (*add_options[MAX_IP6_HBH_OPTION]) (u8 * rewrite_string,
+					  u8 * rewrite_size);
+  int (*pop_options[MAX_IP6_HBH_OPTION]) (vlib_buffer_t * b,
+					  ip6_header_t * ip,
+					  ip6_hop_by_hop_option_t * opt);
+  int (*get_sizeof_options[MAX_IP6_HBH_OPTION]) (u32 * rewrite_size);
+  int (*config_handler[MAX_IP6_HBH_OPTION]) (void *data, u8 disable);
+
+  /* Array of function pointers to handle hbh options being used with classifier */
+  u32 (*flow_handler[MAX_IP6_HBH_OPTION]) (u32 flow_ctx, u8 add);
+  flow_data_t *flows;
+
+  ip6_local_hop_by_hop_runtime_t *ip6_local_hbh_runtime;
+
+  /* convenience */
+  vlib_main_t *vlib_main;
+  vnet_main_t *vnet_main;
+} ip6_hop_by_hop_ioam_main_t;
+
+extern ip6_hop_by_hop_ioam_main_t ip6_hop_by_hop_ioam_main;
+
+extern clib_error_t *ip6_ioam_enable (int has_trace_option,
+				      int has_pot_option,
+				      int has_seqno_option,
+				      int has_analyse_option,
+              ip6_address_t* dst_addr);
+
+extern int ip6_ioam_set_destination (ip6_address_t * addr, u32 mask_width,
+				     u32 vrf_id, int is_add, int is_pop,
+				     int is_none);
+
+extern clib_error_t *clear_ioam_rewrite_fn (void);
+
+static inline u8
+is_zero_ip4_address (ip4_address_t * a)
+{
+  return (a->as_u32 == 0);
+}
+
+static inline void
+copy_ip6_address (ip6_address_t * dst, ip6_address_t * src)
+{
+  dst->as_u64[0] = src->as_u64[0];
+  dst->as_u64[1] = src->as_u64[1];
+}
+
+static inline void
+set_zero_ip6_address (ip6_address_t * a)
+{
+  a->as_u64[0] = 0;
+  a->as_u64[1] = 0;
+}
+
+static inline u8
+cmp_ip6_address (ip6_address_t * a1, ip6_address_t * a2)
+{
+  return ((a1->as_u64[0] == a2->as_u64[0])
+	  && (a1->as_u64[1] == a2->as_u64[1]));
+}
+
+static inline u8
+is_zero_ip6_address (ip6_address_t * a)
+{
+  return ((a->as_u64[0] == 0) && (a->as_u64[1] == 0));
+}
+
+int ip6_hbh_add_register_option (u8 option,
+				 u8 size,
+				 int rewrite_options (u8 * rewrite_string,
+						      u8 * size));
+int ip6_hbh_add_unregister_option (u8 option);
+
+int ip6_hbh_pop_register_option (u8 option,
+				 int options (vlib_buffer_t * b,
+					      ip6_header_t * ip,
+					      ip6_hop_by_hop_option_t * opt));
+int ip6_hbh_pop_unregister_option (u8 option);
+
+int
+ip6_hbh_get_sizeof_register_option (u8 option,
+				    int get_sizeof_hdr_options (u32 *
+								rewrite_size));
+
+int
+ip6_ioam_set_rewrite (u8 ** rwp, int has_trace_option,
+		      int has_pot_option, int has_seq_no);
+
+int
+ip6_hbh_config_handler_register (u8 option,
+				 int config_handler (void *data, u8 disable));
+
+int ip6_hbh_config_handler_unregister (u8 option);
+
+int ip6_hbh_flow_handler_register (u8 option,
+				   u32 ioam_flow_handler (u32 flow_ctx,
+							  u8 add));
+
+int ip6_hbh_flow_handler_unregister (u8 option);
+
+u8 *get_flow_name_from_flow_ctx (u32 flow_ctx);
+
+static inline flow_data_t *
+get_flow (u32 index)
+{
+  flow_data_t *flow = NULL;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+
+  if (pool_is_free_index (hm->flows, index))
+    return NULL;
+
+  flow = pool_elt_at_index (hm->flows, index);
+  return flow;
+}
+
+static inline u32
+get_flow_data_from_flow_ctx (u32 flow_ctx, u8 option)
+{
+  flow_data_t *flow = NULL;
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  u32 index;
+
+  index = IOAM_MASK_DECAP_BIT (flow_ctx);
+  //flow = pool_elt_at_index (hm->flows, index);
+  flow = &hm->flows[index];
+  return (flow->ctx[option]);
+}
+
+static inline u8
+is_seqno_enabled (void)
+{
+  return (ip6_hop_by_hop_ioam_main.has_seqno_option);
+}
+
+int ip6_trace_profile_setup ();
+
+static inline u32
+ioam_flow_add (u8 encap, u8 * flow_name)
+{
+  ip6_hop_by_hop_ioam_main_t *hm = &ip6_hop_by_hop_ioam_main;
+  flow_data_t *flow = 0;
+  u32 index = 0;
+  u8 i;
+
+  pool_get (hm->flows, flow);
+  clib_memset (flow, 0, sizeof (flow_data_t));
+
+  index = flow - hm->flows;
+  strncpy ((char *) flow->flow_name, (char *) flow_name, 31);
+
+  if (!encap)
+  {
+    IOAM_SET_DECAP (index);
+  }
+    
+  for (i = 0; i < 255; i++)
+  {
+    if (hm->flow_handler[i])
+    {
+      flow->ctx[i] = hm->flow_handler[i] (index, 1);
+    }
+  }
+  return (index);
+}
+
+always_inline ip6_hop_by_hop_option_t *
+ip6_hbh_get_option (ip6_hop_by_hop_header_t * hbh0, u8 option_to_search)
+{
+  ip6_hop_by_hop_option_t *opt0, *limit0;
+  u8 type0;
+
+  if (!hbh0)
+    return NULL;
+
+  opt0 = (ip6_hop_by_hop_option_t *) (hbh0 + 1);
+  limit0 = (ip6_hop_by_hop_option_t *)
+    ((u8 *) hbh0 + ((hbh0->length + 1) << 3));
+
+  /* Scan the set of h-b-h options, process ones that we understand */
+  while (opt0 < limit0)
+  {
+    type0 = opt0->type;
+    switch (type0)
+    {
+      case 0:		/* Pad1 */
+        opt0 = (ip6_hop_by_hop_option_t *) ((u8 *) opt0) + 1;
+        continue;
+      case 1:		/* PadN */
+        break;
+      default:
+        if (type0 == option_to_search)
+        {
+          return opt0;
+        }
+        break;
+    }
+    opt0 =
+	      (ip6_hop_by_hop_option_t *) (((u8 *) opt0) + opt0->length +
+				              sizeof (ip6_hop_by_hop_option_t));
+  }
+  return NULL;
+}
+
+#endif /* __included_ip6_hop_by_hop_ioam_h__ */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ip/ip6_hop_by_hop_packet.h b/src/plugins/ip/ip6_hop_by_hop_packet.h
new file mode 100644
index 000000000..2eec30aa3
--- /dev/null
+++ b/src/plugins/ip/ip6_hop_by_hop_packet.h
@@ -0,0 +1,62 @@
+/*
+ * Copyright (c) 2015 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef __included_ip6_hop_by_hop_packet_h__
+#define __included_ip6_hop_by_hop_packet_h__
+
+// This is directly from the IPv6 hop-by-hop extension header
+typedef struct
+{
+  /* Protocol for next header */
+  u8 protocol;
+  /*
+   * Length of hop_by_hop header in 8 octet units,
+   * not including the first 8 octets
+   */
+  u8 length;
+  u8 padding[2];
+} ip6_hop_by_hop_header_t;
+
+// This is what goes in the "Option Data & Padding" of the IPv6 hop-by-hop extension header
+typedef struct
+{
+  /* Option Type */
+#define HBH_OPTION_TYPE_SKIP_UNKNOWN (0x00)
+#define HBH_OPTION_TYPE_DISCARD_UNKNOWN (0x40)
+#define HBH_OPTION_TYPE_DISCARD_UNKNOWN_ICMP (0x80)
+#define HBH_OPTION_TYPE_DISCARD_UNKNOWN_ICMP_NOT_MCAST (0xc0)
+#define HBH_OPTION_TYPE_HIGH_ORDER_BITS (0xc0)
+#define HBH_OPTION_TYPE_DATA_CHANGE_ENROUTE (1<<5)
+  u8 type;
+  /* Length in octets of the option data field */
+  u8 length;
+  u8 reserved;
+  /* Prealloc, incremental, pot, e2e */
+  u8 ioam_type;
+} ip6_hop_by_hop_option_t;
+
+/* $$$$ IANA banana constants */
+#define HBH_OPTION_TYPE_IOAM_TRACE_DATA_LIST 49	/* Third highest bit set (change en-route) */
+#define HBH_OPTION_TYPE_IOAM_PROOF_OF_TRANSIT 50	/* Third highest bit set (change en-route) */
+#define HBH_OPTION_TYPE_IOAM_EDGE_TO_EDGE 17
+
+#endif /* __included_ip6_hop_by_hop_packet_h__ */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/ip/ip_api.c b/src/plugins/ip/ip_api.c
new file mode 100644
index 000000000..1965a0032
--- /dev/null
+++ b/src/plugins/ip/ip_api.c
@@ -0,0 +1,1817 @@
+/*
+ *------------------------------------------------------------------
+ * ip_api.c - vnet ip api
+ *
+ * Copyright (c) 2016 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *------------------------------------------------------------------
+ */
+
+#include <vnet/vnet.h>
+#include <vlibmemory/api.h>
+
+#include <vnet/interface.h>
+#include <vnet/api_errno.h>
+#include <vnet/ethernet/ethernet.h>
+#include <vnet/ethernet/ethernet_types_api.h>
+#include <vnet/ip/ip.h>
+#include <vnet/ip/ip_types_api.h>
+#include <vnet/ip/ip_punt_drop.h>
+#include <vnet/ip/ip_types_api.h>
+#include <vnet/ip/ip_path_mtu.h>
+#include <vnet/fib/fib_table.h>
+#include <vnet/fib/fib_api.h>
+#include <vnet/ethernet/arp_packet.h>
+#include <vnet/mfib/ip6_mfib.h>
+#include <vnet/mfib/ip4_mfib.h>
+#include <vnet/mfib/mfib_signal.h>
+#include <vnet/mfib/mfib_entry.h>
+#include <vnet/mfib/mfib_api.h>
+#include <vnet/ip/ip_source_and_port_range_check.h>
+#include <vnet/fib/fib_path_list.h>
+#include <vnet/ip/ip6_hop_by_hop.h>
+#include <vnet/ip/ip6_link.h>
+#include <vnet/ip/reass/ip4_sv_reass.h>
+#include <vnet/ip/reass/ip4_full_reass.h>
+#include <vnet/ip/reass/ip6_sv_reass.h>
+#include <vnet/ip/reass/ip6_full_reass.h>
+#include <vnet/ip/ip_table.h>
+#include <vnet/ip/ip_container_proxy.h>
+
+#include <vnet/vnet_msg_enum.h>
+
+#define vl_typedefs		/* define message structures */
+#include <vnet/vnet_all_api_h.h>
+#undef vl_typedefs
+
+#define vl_endianfun		/* define message structures */
+#include <vnet/vnet_all_api_h.h>
+#undef vl_endianfun
+
+/* instantiate all the print functions we know about */
+#define vl_print(handle, ...) vlib_cli_output (handle, __VA_ARGS__)
+#define vl_printfun
+#include <vnet/vnet_all_api_h.h>
+#undef vl_printfun
+
+#include <vlibapi/api_helper_macros.h>
+
+#include <vnet/format_fns.h>
+
+#define foreach_ip_api_msg                                                    \
+  _ (SW_INTERFACE_IP6_ENABLE_DISABLE, sw_interface_ip6_enable_disable)        \
+  _ (IP_TABLE_DUMP, ip_table_dump)                                            \
+  _ (IP_ROUTE_DUMP, ip_route_dump)                                            \
+  _ (IP_MTABLE_DUMP, ip_mtable_dump)                                          \
+  _ (IP_MROUTE_DUMP, ip_mroute_dump)                                          \
+  _ (IP_MROUTE_ADD_DEL, ip_mroute_add_del)                                    \
+  _ (MFIB_SIGNAL_DUMP, mfib_signal_dump)                                      \
+  _ (IP_ADDRESS_DUMP, ip_address_dump)                                        \
+  _ (IP_UNNUMBERED_DUMP, ip_unnumbered_dump)                                  \
+  _ (IP_DUMP, ip_dump)                                                        \
+  _ (IP_TABLE_REPLACE_BEGIN, ip_table_replace_begin)                          \
+  _ (IP_TABLE_REPLACE_END, ip_table_replace_end)                              \
+  _ (IP_TABLE_FLUSH, ip_table_flush)                                          \
+  _ (IP_ROUTE_ADD_DEL, ip_route_add_del)                                      \
+  _ (IP_ROUTE_LOOKUP, ip_route_lookup)                                        \
+  _ (IP_TABLE_ADD_DEL, ip_table_add_del)                                      \
+  _ (IP_PUNT_POLICE, ip_punt_police)                                          \
+  _ (IP_PUNT_REDIRECT, ip_punt_redirect)                                      \
+  _ (SET_IP_FLOW_HASH, set_ip_flow_hash)                                      \
+  _ (SET_IP_FLOW_HASH_V2, set_ip_flow_hash_v2)                                \
+  _ (SET_IP_FLOW_HASH_ROUTER_ID, set_ip_flow_hash_router_id)                  \
+  _ (IP_CONTAINER_PROXY_ADD_DEL, ip_container_proxy_add_del)                  \
+  _ (IP_CONTAINER_PROXY_DUMP, ip_container_proxy_dump)                        \
+  _ (IOAM_ENABLE, ioam_enable)                                                \
+  _ (IOAM_DISABLE, ioam_disable)                                              \
+  _ (IP_SOURCE_AND_PORT_RANGE_CHECK_ADD_DEL,                                  \
+     ip_source_and_port_range_check_add_del)                                  \
+  _ (IP_SOURCE_AND_PORT_RANGE_CHECK_INTERFACE_ADD_DEL,                        \
+     ip_source_and_port_range_check_interface_add_del)                        \
+  _ (SW_INTERFACE_IP6_SET_LINK_LOCAL_ADDRESS,                                 \
+     sw_interface_ip6_set_link_local_address)                                 \
+  _ (SW_INTERFACE_IP6_GET_LINK_LOCAL_ADDRESS,                                 \
+     sw_interface_ip6_get_link_local_address)                                 \
+  _ (IP_REASSEMBLY_SET, ip_reassembly_set)                                    \
+  _ (IP_REASSEMBLY_GET, ip_reassembly_get)                                    \
+  _ (IP_REASSEMBLY_ENABLE_DISABLE, ip_reassembly_enable_disable)              \
+  _ (IP_PUNT_REDIRECT_DUMP, ip_punt_redirect_dump)                            \
+  _ (IP_PATH_MTU_UPDATE, ip_path_mtu_update)                                  \
+  _ (IP_PATH_MTU_REPLACE_BEGIN, ip_path_mtu_replace_begin)                    \
+  _ (IP_PATH_MTU_REPLACE_END, ip_path_mtu_replace_end)                        \
+  _ (IP_PATH_MTU_GET, ip_path_mtu_get)
+
+static void
+  vl_api_sw_interface_ip6_enable_disable_t_handler
+  (vl_api_sw_interface_ip6_enable_disable_t * mp)
+{
+  vl_api_sw_interface_ip6_enable_disable_reply_t *rmp;
+  int rv = 0;
+
+  VALIDATE_SW_IF_INDEX (mp);
+
+  rv = ((mp->enable == 1) ?
+	ip6_link_enable (ntohl (mp->sw_if_index), NULL) :
+	ip6_link_disable (ntohl (mp->sw_if_index)));
+
+  BAD_SW_IF_INDEX_LABEL;
+
+  REPLY_MACRO (VL_API_SW_INTERFACE_IP6_ENABLE_DISABLE_REPLY);
+}
+
+static void
+send_ip_table_details (vpe_api_main_t * am,
+		       vl_api_registration_t * reg,
+		       u32 context, const fib_table_t * table)
+{
+  vl_api_ip_table_details_t *mp;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  if (!mp)
+    return;
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_TABLE_DETAILS);
+  mp->context = context;
+
+  mp->table.is_ip6 = (table->ft_proto == FIB_PROTOCOL_IP6);
+  mp->table.table_id = htonl (table->ft_table_id);
+  memcpy (mp->table.name, table->ft_desc,
+	  clib_min (vec_len (table->ft_desc), sizeof (mp->table.name)));
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+vl_api_ip_table_dump_t_handler (vl_api_ip_table_dump_t * mp)
+{
+  vpe_api_main_t *am = &vpe_api_main;
+  vl_api_registration_t *reg;
+  fib_table_t *fib_table;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  /* *INDENT-OFF* */
+  pool_foreach (fib_table, ip4_main.fibs)
+   {
+    send_ip_table_details(am, reg, mp->context, fib_table);
+  }
+  pool_foreach (fib_table, ip6_main.fibs)
+   {
+    /* don't send link locals */
+    if (fib_table->ft_flags & FIB_TABLE_FLAG_IP6_LL)
+      continue;
+    send_ip_table_details(am, reg, mp->context, fib_table);
+  }
+  /* *INDENT-ON* */
+}
+
+typedef struct vl_api_ip_fib_dump_walk_ctx_t_
+{
+  fib_node_index_t *feis;
+} vl_api_ip_fib_dump_walk_ctx_t;
+
+static fib_table_walk_rc_t
+vl_api_ip_fib_dump_walk (fib_node_index_t fei, void *arg)
+{
+  vl_api_ip_fib_dump_walk_ctx_t *ctx = arg;
+
+  vec_add1 (ctx->feis, fei);
+
+  return (FIB_TABLE_WALK_CONTINUE);
+}
+
+static void
+send_ip_route_details (vpe_api_main_t * am,
+		       vl_api_registration_t * reg,
+		       u32 context, fib_node_index_t fib_entry_index)
+{
+  fib_route_path_t *rpaths, *rpath;
+  vl_api_ip_route_details_t *mp;
+  const fib_prefix_t *pfx;
+  vl_api_fib_path_t *fp;
+  int path_count;
+
+  rpaths = NULL;
+  pfx = fib_entry_get_prefix (fib_entry_index);
+  rpaths = fib_entry_encode (fib_entry_index);
+
+  path_count = vec_len (rpaths);
+  mp = vl_msg_api_alloc (sizeof (*mp) + path_count * sizeof (*fp));
+  if (!mp)
+    return;
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_ROUTE_DETAILS);
+  mp->context = context;
+
+  ip_prefix_encode (pfx, &mp->route.prefix);
+  mp->route.table_id =
+    htonl (fib_table_get_table_id
+	   (fib_entry_get_fib_index (fib_entry_index), pfx->fp_proto));
+  mp->route.n_paths = path_count;
+  mp->route.stats_index =
+    htonl (fib_table_entry_get_stats_index
+	   (fib_entry_get_fib_index (fib_entry_index), pfx));
+
+  fp = mp->route.paths;
+  vec_foreach (rpath, rpaths)
+  {
+    fib_api_path_encode (rpath, fp);
+    fp++;
+  }
+
+  vl_api_send_msg (reg, (u8 *) mp);
+  vec_free (rpaths);
+}
+
+typedef struct apt_ip6_fib_show_ctx_t_
+{
+  fib_node_index_t *entries;
+} api_ip6_fib_show_ctx_t;
+
+static void
+vl_api_ip_route_dump_t_handler (vl_api_ip_route_dump_t * mp)
+{
+  vpe_api_main_t *am = &vpe_api_main;
+  fib_node_index_t *fib_entry_index;
+  vl_api_registration_t *reg;
+  fib_protocol_t fproto;
+  u32 fib_index;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  vl_api_ip_fib_dump_walk_ctx_t ctx = {
+    .feis = NULL,
+  };
+
+  fproto = (mp->table.is_ip6 ? FIB_PROTOCOL_IP6 : FIB_PROTOCOL_IP4);
+  fib_index = fib_table_find (fproto, ntohl (mp->table.table_id));
+
+  if (INDEX_INVALID == fib_index)
+    return;
+
+  fib_table_walk (fib_index, fproto, vl_api_ip_fib_dump_walk, &ctx);
+
+  vec_foreach (fib_entry_index, ctx.feis)
+  {
+    send_ip_route_details (am, reg, mp->context, *fib_entry_index);
+  }
+
+  vec_free (ctx.feis);
+}
+
+static void
+send_ip_mtable_details (vl_api_registration_t * reg,
+			u32 context, const mfib_table_t * mfib_table)
+{
+  vl_api_ip_mtable_details_t *mp;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  if (!mp)
+    return;
+  memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_MTABLE_DETAILS);
+  mp->context = context;
+
+  mp->table.table_id = htonl (mfib_table->mft_table_id);
+  mp->table.is_ip6 = (FIB_PROTOCOL_IP6 == mfib_table->mft_proto);
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+vl_api_ip_mtable_dump_t_handler (vl_api_ip_mtable_dump_t * mp)
+{
+  vl_api_registration_t *reg;
+  mfib_table_t *mfib_table;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  /* *INDENT-OFF* */
+  pool_foreach (mfib_table, ip4_main.mfibs)
+   {
+      send_ip_mtable_details (reg, mp->context, mfib_table);
+  }
+  pool_foreach (mfib_table, ip6_main.mfibs)
+   {
+      send_ip_mtable_details (reg, mp->context, mfib_table);
+  }
+  /* *INDENT-ON* */
+}
+
+typedef struct vl_api_ip_mfib_dump_ctx_t_
+{
+  fib_node_index_t *entries;
+} vl_api_ip_mfib_dump_ctx_t;
+
+static walk_rc_t
+mfib_route_dump_walk (fib_node_index_t fei, void *arg)
+{
+  vl_api_ip_mfib_dump_ctx_t *ctx = arg;
+
+  vec_add1 (ctx->entries, fei);
+
+  return (WALK_CONTINUE);
+}
+
+static void
+send_ip_mroute_details (vpe_api_main_t * am,
+			vl_api_registration_t * reg,
+			u32 context, fib_node_index_t mfib_entry_index)
+{
+  fib_route_path_t *rpaths, *rpath;
+  vl_api_ip_mroute_details_t *mp;
+  const mfib_prefix_t *pfx;
+  vl_api_mfib_path_t *fp;
+  u8 path_count;
+
+  rpaths = NULL;
+  pfx = mfib_entry_get_prefix (mfib_entry_index);
+  rpaths = mfib_entry_encode (mfib_entry_index);
+
+  path_count = vec_len (rpaths);
+  mp = vl_msg_api_alloc (sizeof (*mp) + path_count * sizeof (*fp));
+  if (!mp)
+    return;
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_MROUTE_DETAILS);
+  mp->context = context;
+
+  ip_mprefix_encode (pfx, &mp->route.prefix);
+  mp->route.table_id =
+    htonl (mfib_table_get_table_id
+	   (mfib_entry_get_fib_index (mfib_entry_index), pfx->fp_proto));
+  mp->route.n_paths = path_count;
+  fp = mp->route.paths;
+  vec_foreach (rpath, rpaths)
+  {
+    mfib_api_path_encode (rpath, fp);
+    fp++;
+  }
+
+  vl_api_send_msg (reg, (u8 *) mp);
+  vec_free (rpaths);
+}
+
+static void
+vl_api_ip_mroute_dump_t_handler (vl_api_ip_mroute_dump_t * mp)
+{
+  vpe_api_main_t *am = &vpe_api_main;
+  vl_api_registration_t *reg;
+  fib_node_index_t *mfeip;
+  fib_protocol_t fproto;
+  u32 fib_index;
+
+  vl_api_ip_mfib_dump_ctx_t ctx = {
+    .entries = NULL,
+  };
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  fproto = fib_ip_proto (mp->table.is_ip6);
+  fib_index = mfib_table_find (fproto, ntohl (mp->table.table_id));
+
+  if (INDEX_INVALID == fib_index)
+    return;
+
+  mfib_table_walk (fib_index, fproto, mfib_route_dump_walk, &ctx);
+
+  vec_sort_with_function (ctx.entries, mfib_entry_cmp_for_sort);
+
+  vec_foreach (mfeip, ctx.entries)
+  {
+    send_ip_mroute_details (am, reg, mp->context, *mfeip);
+  }
+
+  vec_free (ctx.entries);
+}
+
+static void
+vl_api_ip_punt_police_t_handler (vl_api_ip_punt_police_t * mp,
+				 vlib_main_t * vm)
+{
+  vl_api_ip_punt_police_reply_t *rmp;
+  int rv = 0;
+
+  if (mp->is_ip6)
+    ip6_punt_policer_add_del (mp->is_add, ntohl (mp->policer_index));
+  else
+    ip4_punt_policer_add_del (mp->is_add, ntohl (mp->policer_index));
+
+  REPLY_MACRO (VL_API_IP_PUNT_POLICE_REPLY);
+}
+
+static void
+vl_api_ip_punt_redirect_t_handler (vl_api_ip_punt_redirect_t * mp,
+				   vlib_main_t * vm)
+{
+  vl_api_ip_punt_redirect_reply_t *rmp;
+  int rv = 0;
+  ip46_type_t ipv;
+  ip46_address_t nh;
+
+  if (!vnet_sw_if_index_is_api_valid (ntohl (mp->punt.tx_sw_if_index)))
+    goto bad_sw_if_index;
+
+  ipv = ip_address_decode (&mp->punt.nh, &nh);
+  if (mp->is_add)
+    {
+      if (ipv == IP46_TYPE_IP6)
+	{
+	  ip6_punt_redirect_add (ntohl (mp->punt.rx_sw_if_index),
+				 ntohl (mp->punt.tx_sw_if_index), &nh);
+	}
+      else if (ipv == IP46_TYPE_IP4)
+	{
+	  ip4_punt_redirect_add (ntohl (mp->punt.rx_sw_if_index),
+				 ntohl (mp->punt.tx_sw_if_index), &nh);
+	}
+    }
+  else
+    {
+      if (ipv == IP46_TYPE_IP6)
+	{
+	  ip6_punt_redirect_del (ntohl (mp->punt.rx_sw_if_index));
+	}
+      else if (ipv == IP46_TYPE_IP4)
+	{
+	  ip4_punt_redirect_del (ntohl (mp->punt.rx_sw_if_index));
+	}
+    }
+
+  BAD_SW_IF_INDEX_LABEL;
+
+  REPLY_MACRO (VL_API_IP_PUNT_REDIRECT_REPLY);
+}
+
+static clib_error_t *
+call_elf_section_ip_table_callbacks (vnet_main_t * vnm, u32 table_id,
+				     u32 flags,
+				     _vnet_ip_table_function_list_elt_t **
+				     elts)
+{
+  _vnet_ip_table_function_list_elt_t *elt;
+  vnet_ip_table_function_priority_t prio;
+  clib_error_t *error = 0;
+
+  for (prio = VNET_IP_TABLE_FUNC_PRIORITY_LOW;
+       prio <= VNET_IP_TABLE_FUNC_PRIORITY_HIGH; prio++)
+    {
+      elt = elts[prio];
+
+      while (elt)
+	{
+	  error = elt->fp (vnm, table_id, flags);
+	  if (error)
+	    return error;
+	  elt = elt->next_ip_table_function;
+	}
+    }
+  return error;
+}
+
+void
+ip_table_delete (fib_protocol_t fproto, u32 table_id, u8 is_api)
+{
+  u32 fib_index, mfib_index;
+  vnet_main_t *vnm = vnet_get_main ();
+
+  /*
+   * ignore action on the default table - this is always present
+   * and cannot be added nor deleted from the API
+   */
+  if (0 != table_id)
+    {
+      /*
+       * The API holds only one lock on the table.
+       * i.e. it can be added many times via the API but needs to be
+       * deleted only once.
+       * The FIB index for unicast and multicast is not necessarily the
+       * same, since internal VPP systesm (like LISP and SR) create
+       * their own unicast tables.
+       */
+      fib_index = fib_table_find (fproto, table_id);
+      mfib_index = mfib_table_find (fproto, table_id);
+
+      if ((~0 != fib_index) || (~0 != mfib_index))
+	call_elf_section_ip_table_callbacks (vnm, table_id, 0 /* is_add */ ,
+					     vnm->ip_table_add_del_functions);
+
+      if (~0 != fib_index)
+	{
+	  fib_table_unlock (fib_index, fproto,
+			    (is_api ? FIB_SOURCE_API : FIB_SOURCE_CLI));
+	}
+      if (~0 != mfib_index)
+	{
+	  mfib_table_unlock (mfib_index, fproto,
+			     (is_api ? MFIB_SOURCE_API : MFIB_SOURCE_CLI));
+	}
+    }
+}
+
+void
+vl_api_ip_table_add_del_t_handler (vl_api_ip_table_add_del_t * mp)
+{
+  vl_api_ip_table_add_del_reply_t *rmp;
+  fib_protocol_t fproto = (mp->table.is_ip6 ?
+			   FIB_PROTOCOL_IP6 : FIB_PROTOCOL_IP4);
+  u32 table_id = ntohl (mp->table.table_id);
+  int rv = 0;
+
+  if (mp->is_add)
+    {
+      ip_table_create (fproto, table_id, 1, mp->table.name);
+    }
+  else
+    {
+      ip_table_delete (fproto, table_id, 1);
+    }
+
+  REPLY_MACRO (VL_API_IP_TABLE_ADD_DEL_REPLY);
+}
+
+static int
+ip_route_add_del_t_handler (vl_api_ip_route_add_del_t * mp, u32 * stats_index)
+{
+  fib_route_path_t *rpaths = NULL, *rpath;
+  fib_entry_flag_t entry_flags;
+  vl_api_fib_path_t *apath;
+  fib_prefix_t pfx;
+  u32 fib_index;
+  int rv, ii;
+
+  entry_flags = FIB_ENTRY_FLAG_NONE;
+  ip_prefix_decode (&mp->route.prefix, &pfx);
+
+  rv = fib_api_table_id_decode (pfx.fp_proto,
+				ntohl (mp->route.table_id), &fib_index);
+  if (0 != rv)
+    goto out;
+
+  if (0 != mp->route.n_paths)
+    vec_validate (rpaths, mp->route.n_paths - 1);
+
+  for (ii = 0; ii < mp->route.n_paths; ii++)
+    {
+      apath = &mp->route.paths[ii];
+      rpath = &rpaths[ii];
+
+      rv = fib_api_path_decode (apath, rpath);
+
+      if ((rpath->frp_flags & FIB_ROUTE_PATH_LOCAL) &&
+	  (~0 == rpath->frp_sw_if_index))
+	entry_flags |= (FIB_ENTRY_FLAG_CONNECTED | FIB_ENTRY_FLAG_LOCAL);
+
+      if (0 != rv)
+	goto out;
+    }
+
+  rv = fib_api_route_add_del (mp->is_add,
+			      mp->is_multipath,
+			      fib_index, &pfx, entry_flags, rpaths);
+
+  if (mp->is_add && 0 == rv)
+    *stats_index = fib_table_entry_get_stats_index (fib_index, &pfx);
+
+out:
+  vec_free (rpaths);
+
+  return (rv);
+}
+
+void
+vl_api_ip_route_add_del_t_handler (vl_api_ip_route_add_del_t * mp)
+{
+  vl_api_ip_route_add_del_reply_t *rmp;
+  u32 stats_index = ~0;
+  int rv;
+
+  rv = ip_route_add_del_t_handler (mp, &stats_index);
+
+  /* *INDENT-OFF* */
+  REPLY_MACRO2 (VL_API_IP_ROUTE_ADD_DEL_REPLY,
+  ({
+    rmp->stats_index = htonl (stats_index);
+  }))
+  /* *INDENT-ON* */
+}
+
+void
+vl_api_ip_route_lookup_t_handler (vl_api_ip_route_lookup_t * mp)
+{
+  vl_api_ip_route_lookup_reply_t *rmp = NULL;
+  fib_route_path_t *rpaths = NULL, *rpath;
+  const fib_prefix_t *pfx = NULL;
+  fib_prefix_t lookup;
+  vl_api_fib_path_t *fp;
+  fib_node_index_t fib_entry_index;
+  u32 fib_index;
+  int npaths = 0;
+  int rv;
+
+  ip_prefix_decode (&mp->prefix, &lookup);
+  rv = fib_api_table_id_decode (lookup.fp_proto, ntohl (mp->table_id),
+				&fib_index);
+  if (PREDICT_TRUE (!rv))
+    {
+      if (mp->exact)
+	fib_entry_index = fib_table_lookup_exact_match (fib_index, &lookup);
+      else
+	fib_entry_index = fib_table_lookup (fib_index, &lookup);
+      if (fib_entry_index == FIB_NODE_INDEX_INVALID)
+	rv = VNET_API_ERROR_NO_SUCH_ENTRY;
+      else
+	{
+	  pfx = fib_entry_get_prefix (fib_entry_index);
+	  rpaths = fib_entry_encode (fib_entry_index);
+	  npaths = vec_len (rpaths);
+	}
+    }
+
+  /* *INDENT-OFF* */
+  REPLY_MACRO3_ZERO(VL_API_IP_ROUTE_LOOKUP_REPLY,
+                    npaths * sizeof (*fp),
+  ({
+    if (!rv)
+      {
+        ip_prefix_encode (pfx, &rmp->route.prefix);
+        rmp->route.table_id = mp->table_id;
+        rmp->route.n_paths = npaths;
+        rmp->route.stats_index = fib_table_entry_get_stats_index (fib_index, pfx);
+        rmp->route.stats_index = htonl (rmp->route.stats_index);
+
+        fp = rmp->route.paths;
+        vec_foreach (rpath, rpaths)
+          {
+            fib_api_path_encode (rpath, fp);
+            fp++;
+          }
+      }
+  }));
+  /* *INDENT-ON* */
+  vec_free (rpaths);
+}
+
+void
+ip_table_create (fib_protocol_t fproto,
+		 u32 table_id, u8 is_api, const u8 * name)
+{
+  u32 fib_index, mfib_index;
+  vnet_main_t *vnm = vnet_get_main ();
+
+  /*
+   * ignore action on the default table - this is always present
+   * and cannot be added nor deleted from the API
+   */
+  if (0 != table_id)
+    {
+      /*
+       * The API holds only one lock on the table.
+       * i.e. it can be added many times via the API but needs to be
+       * deleted only once.
+       * The FIB index for unicast and multicast is not necessarily the
+       * same, since internal VPP systesm (like LISP and SR) create
+       * their own unicast tables.
+       */
+      fib_index = fib_table_find (fproto, table_id);
+      mfib_index = mfib_table_find (fproto, table_id);
+
+      if (~0 == fib_index)
+	{
+	  fib_table_find_or_create_and_lock_w_name (fproto, table_id,
+						    (is_api ?
+						     FIB_SOURCE_API :
+						     FIB_SOURCE_CLI), name);
+	}
+      if (~0 == mfib_index)
+	{
+	  mfib_table_find_or_create_and_lock_w_name (fproto, table_id,
+						     (is_api ?
+						      MFIB_SOURCE_API :
+						      MFIB_SOURCE_CLI), name);
+	}
+
+      if ((~0 == fib_index) || (~0 == mfib_index))
+	call_elf_section_ip_table_callbacks (vnm, table_id, 1 /* is_add */ ,
+					     vnm->ip_table_add_del_functions);
+    }
+}
+
+static u32
+mroute_add_del_handler (u8 is_add,
+			u8 is_multipath,
+			u32 fib_index,
+			const mfib_prefix_t * prefix,
+			u32 entry_flags,
+			u32 rpf_id, fib_route_path_t * rpaths)
+{
+  u32 mfib_entry_index = ~0;
+
+  if (0 == vec_len (rpaths))
+    {
+      mfib_entry_index = mfib_table_entry_update (fib_index, prefix,
+						  MFIB_SOURCE_API,
+						  rpf_id, entry_flags);
+    }
+  else
+    {
+      if (is_add)
+	{
+	  mfib_entry_index =
+	    mfib_table_entry_paths_update (fib_index, prefix,
+					   MFIB_SOURCE_API, rpaths);
+	}
+      else
+	{
+	  mfib_table_entry_paths_remove (fib_index, prefix,
+					 MFIB_SOURCE_API, rpaths);
+	}
+    }
+
+  return (mfib_entry_index);
+}
+
+static int
+api_mroute_add_del_t_handler (vl_api_ip_mroute_add_del_t * mp,
+			      u32 * stats_index)
+{
+  fib_route_path_t *rpath, *rpaths = NULL;
+  fib_node_index_t mfib_entry_index;
+  mfib_entry_flags_t eflags;
+  mfib_prefix_t pfx;
+  u32 fib_index;
+  int rv;
+  u16 ii;
+
+  ip_mprefix_decode (&mp->route.prefix, &pfx);
+
+  rv = mfib_api_table_id_decode (pfx.fp_proto,
+				 ntohl (mp->route.table_id), &fib_index);
+  if (0 != rv)
+    goto out;
+
+  vec_validate (rpaths, mp->route.n_paths - 1);
+
+  for (ii = 0; ii < mp->route.n_paths; ii++)
+    {
+      rpath = &rpaths[ii];
+
+      rv = mfib_api_path_decode (&mp->route.paths[ii], rpath);
+
+      if (0 != rv)
+	goto out;
+    }
+
+  eflags = mfib_api_path_entry_flags_decode (mp->route.entry_flags);
+  mfib_entry_index = mroute_add_del_handler (mp->is_add,
+					     mp->is_add,
+					     fib_index, &pfx,
+					     eflags,
+					     ntohl (mp->route.rpf_id),
+					     rpaths);
+
+  if (~0 != mfib_entry_index)
+    *stats_index = mfib_entry_get_stats_index (mfib_entry_index);
+
+out:
+  return (rv);
+}
+
+void
+vl_api_ip_mroute_add_del_t_handler (vl_api_ip_mroute_add_del_t * mp)
+{
+  vl_api_ip_mroute_add_del_reply_t *rmp;
+  u32 stats_index = ~0;
+  int rv;
+
+  rv = api_mroute_add_del_t_handler (mp, &stats_index);
+
+  /* *INDENT-OFF* */
+  REPLY_MACRO2 (VL_API_IP_MROUTE_ADD_DEL_REPLY,
+  ({
+    rmp->stats_index = htonl (stats_index);
+  }));
+  /* *INDENT-ON* */
+}
+
+static void
+send_ip_details (vpe_api_main_t * am,
+		 vl_api_registration_t * reg, u32 sw_if_index, u8 is_ipv6,
+		 u32 context)
+{
+  vl_api_ip_details_t *mp;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_DETAILS);
+
+  mp->sw_if_index = ntohl (sw_if_index);
+  mp->is_ipv6 = is_ipv6;
+  mp->context = context;
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+send_ip_address_details (vpe_api_main_t * am,
+			 vl_api_registration_t * reg,
+			 const fib_prefix_t * pfx,
+			 u32 sw_if_index, u32 context)
+{
+  vl_api_ip_address_details_t *mp;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_ADDRESS_DETAILS);
+
+  ip_prefix_encode (pfx, &mp->prefix);
+  mp->context = context;
+  mp->sw_if_index = htonl (sw_if_index);
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+vl_api_ip_address_dump_t_handler (vl_api_ip_address_dump_t * mp)
+{
+  vpe_api_main_t *am = &vpe_api_main;
+  vl_api_registration_t *reg;
+  ip6_main_t *im6 = &ip6_main;
+  ip4_main_t *im4 = &ip4_main;
+  ip_lookup_main_t *lm6 = &im6->lookup_main;
+  ip_lookup_main_t *lm4 = &im4->lookup_main;
+  ip_interface_address_t *ia = 0;
+  u32 sw_if_index = ~0;
+  int rv __attribute__ ((unused)) = 0;
+
+  VALIDATE_SW_IF_INDEX (mp);
+
+  sw_if_index = ntohl (mp->sw_if_index);
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  if (mp->is_ipv6)
+    {
+      /* *INDENT-OFF* */
+      /* Do not send subnet details of the IP-interface for
+       * unnumbered interfaces. otherwise listening clients
+       * will be confused that the subnet is applied on more
+       * than one interface */
+      foreach_ip_interface_address (lm6, ia, sw_if_index, 0,
+      ({
+        fib_prefix_t pfx = {
+          .fp_addr.ip6 = *(ip6_address_t *)ip_interface_address_get_address (lm6, ia),
+          .fp_len = ia->address_length,
+          .fp_proto = FIB_PROTOCOL_IP6,
+        };
+        send_ip_address_details(am, reg, &pfx, sw_if_index, mp->context);
+      }));
+      /* *INDENT-ON* */
+    }
+  else
+    {
+      /* *INDENT-OFF* */
+      foreach_ip_interface_address (lm4, ia, sw_if_index, 0,
+      ({
+        fib_prefix_t pfx = {
+          .fp_addr.ip4 = *(ip4_address_t *)ip_interface_address_get_address (lm4, ia),
+          .fp_len = ia->address_length,
+          .fp_proto = FIB_PROTOCOL_IP4,
+        };
+
+        send_ip_address_details(am, reg, &pfx, sw_if_index, mp->context);
+      }));
+      /* *INDENT-ON* */
+    }
+
+  BAD_SW_IF_INDEX_LABEL;
+}
+
+static void
+send_ip_unnumbered_details (vpe_api_main_t * am,
+			    vl_api_registration_t * reg,
+			    u32 sw_if_index, u32 ip_sw_if_index, u32 context)
+{
+  vl_api_ip_unnumbered_details_t *mp;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_UNNUMBERED_DETAILS);
+
+  mp->context = context;
+  mp->sw_if_index = htonl (sw_if_index);
+  mp->ip_sw_if_index = htonl (ip_sw_if_index);
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+vl_api_ip_unnumbered_dump_t_handler (vl_api_ip_unnumbered_dump_t * mp)
+{
+  vnet_main_t *vnm = vnet_get_main ();
+  vnet_interface_main_t *im = &vnm->interface_main;
+  int rv __attribute__ ((unused)) = 0;
+  vpe_api_main_t *am = &vpe_api_main;
+  vl_api_registration_t *reg;
+  vnet_sw_interface_t *si;
+  u32 sw_if_index;
+
+  sw_if_index = ntohl (mp->sw_if_index);
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  if (~0 != sw_if_index)
+    {
+      VALIDATE_SW_IF_INDEX (mp);
+
+      si = vnet_get_sw_interface (vnm, ntohl (mp->sw_if_index));
+
+      if (si->flags & VNET_SW_INTERFACE_FLAG_UNNUMBERED)
+	{
+	  send_ip_unnumbered_details (am, reg,
+				      sw_if_index,
+				      si->unnumbered_sw_if_index,
+				      mp->context);
+	}
+    }
+  else
+    {
+      /* *INDENT-OFF* */
+      pool_foreach (si, im->sw_interfaces)
+       {
+        if ((si->flags & VNET_SW_INTERFACE_FLAG_UNNUMBERED))
+          {
+            send_ip_unnumbered_details(am, reg,
+                                       si->sw_if_index,
+                                       si->unnumbered_sw_if_index,
+                                       mp->context);
+          }
+      }
+      /* *INDENT-ON* */
+    }
+
+  BAD_SW_IF_INDEX_LABEL;
+}
+
+static void
+vl_api_ip_dump_t_handler (vl_api_ip_dump_t * mp)
+{
+  vpe_api_main_t *am = &vpe_api_main;
+  vnet_main_t *vnm = vnet_get_main ();
+  //vlib_main_t *vm = vlib_get_main ();
+  vnet_interface_main_t *im = &vnm->interface_main;
+  vl_api_registration_t *reg;
+  vnet_sw_interface_t *si, *sorted_sis;
+  u32 sw_if_index = ~0;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  /* Gather interfaces. */
+  sorted_sis = vec_new (vnet_sw_interface_t, pool_elts (im->sw_interfaces));
+  _vec_len (sorted_sis) = 0;
+  /* *INDENT-OFF* */
+  pool_foreach (si, im->sw_interfaces)
+   {
+    vec_add1 (sorted_sis, si[0]);
+  }
+  /* *INDENT-ON* */
+
+  vec_foreach (si, sorted_sis)
+  {
+    if (!(si->flags & VNET_SW_INTERFACE_FLAG_UNNUMBERED))
+      {
+	/* if (mp->is_ipv6 && !ip6_interface_enabled (vm, si->sw_if_index)) */
+	/*   { */
+	/*     continue; */
+	/*   } */
+	sw_if_index = si->sw_if_index;
+	send_ip_details (am, reg, sw_if_index, mp->is_ipv6, mp->context);
+      }
+  }
+
+  vec_free (sorted_sis);
+}
+
+static void
+vl_api_set_ip_flow_hash_t_handler (vl_api_set_ip_flow_hash_t *mp)
+{
+  vl_api_set_ip_flow_hash_reply_t *rmp;
+  int rv;
+  u32 table_id;
+  flow_hash_config_t flow_hash_config = 0;
+
+  table_id = ntohl (mp->vrf_id);
+
+#define _(a,b) if (mp->a) flow_hash_config |= b;
+  foreach_flow_hash_bit_v1;
+#undef _
+
+  rv = ip_flow_hash_set ((mp->is_ipv6 ? AF_IP6 : AF_IP4), table_id,
+			 flow_hash_config);
+
+  REPLY_MACRO (VL_API_SET_IP_FLOW_HASH_REPLY);
+}
+
+static void
+vl_api_set_ip_flow_hash_v2_t_handler (vl_api_set_ip_flow_hash_v2_t *mp)
+{
+  vl_api_set_ip_flow_hash_v2_reply_t *rmp;
+  ip_address_family_t af;
+  int rv;
+
+  rv = ip_address_family_decode (mp->af, &af);
+
+  if (!rv)
+    rv = ip_flow_hash_set (af, htonl (mp->table_id),
+			   htonl (mp->flow_hash_config));
+
+  REPLY_MACRO (VL_API_SET_IP_FLOW_HASH_V2_REPLY);
+}
+
+static void
+vl_api_set_ip_flow_hash_router_id_t_handler (
+  vl_api_set_ip_flow_hash_router_id_t *mp)
+{
+  vl_api_set_ip_flow_hash_router_id_reply_t *rmp;
+  int rv = 0;
+
+  ip_flow_hash_router_id_set (ntohl (mp->router_id));
+
+  REPLY_MACRO (VL_API_SET_IP_FLOW_HASH_ROUTER_ID_REPLY);
+}
+
+void
+vl_mfib_signal_send_one (vl_api_registration_t * reg,
+			 u32 context, const mfib_signal_t * mfs)
+{
+  vl_api_mfib_signal_details_t *mp;
+  const mfib_prefix_t *prefix;
+  mfib_table_t *mfib;
+  mfib_itf_t *mfi;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_MFIB_SIGNAL_DETAILS);
+  mp->context = context;
+
+  mfi = mfib_itf_get (mfs->mfs_itf);
+  prefix = mfib_entry_get_prefix (mfs->mfs_entry);
+  mfib = mfib_table_get (mfib_entry_get_fib_index (mfs->mfs_entry),
+			 prefix->fp_proto);
+  mp->table_id = ntohl (mfib->mft_table_id);
+  mp->sw_if_index = ntohl (mfi->mfi_sw_if_index);
+
+  ip_mprefix_encode (prefix, &mp->prefix);
+
+  if (0 != mfs->mfs_buffer_len)
+    {
+      mp->ip_packet_len = ntohs (mfs->mfs_buffer_len);
+
+      memcpy (mp->ip_packet_data, mfs->mfs_buffer, mfs->mfs_buffer_len);
+    }
+  else
+    {
+      mp->ip_packet_len = 0;
+    }
+
+  vl_api_send_msg (reg, (u8 *) mp);
+}
+
+static void
+vl_api_mfib_signal_dump_t_handler (vl_api_mfib_signal_dump_t * mp)
+{
+  vl_api_registration_t *reg;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  while (vl_api_can_send_msg (reg) && mfib_signal_send_one (reg, mp->context))
+    ;
+}
+
+static void
+  vl_api_ip_container_proxy_add_del_t_handler
+  (vl_api_ip_container_proxy_add_del_t * mp)
+{
+  vl_api_ip_container_proxy_add_del_reply_t *rmp;
+  vnet_ip_container_proxy_args_t args;
+  int rv = 0;
+  clib_error_t *error;
+
+  clib_memset (&args, 0, sizeof (args));
+
+  ip_prefix_decode (&mp->pfx, &args.prefix);
+
+  args.sw_if_index = clib_net_to_host_u32 (mp->sw_if_index);
+  args.is_add = mp->is_add;
+  if ((error = vnet_ip_container_proxy_add_del (&args)))
+    {
+      rv = clib_error_get_code (error);
+      clib_error_report (error);
+    }
+
+  REPLY_MACRO (VL_API_IP_CONTAINER_PROXY_ADD_DEL_REPLY);
+}
+
+typedef struct ip_walk_ctx_t_
+{
+  vl_api_registration_t *reg;
+  u32 context;
+} ip_walk_ctx_t;
+
+static int
+ip_container_proxy_send_details (const fib_prefix_t * pfx, u32 sw_if_index,
+				 void *args)
+{
+  vl_api_ip_container_proxy_details_t *mp;
+  ip_walk_ctx_t *ctx = args;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  if (!mp)
+    return 1;
+
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_CONTAINER_PROXY_DETAILS);
+  mp->context = ctx->context;
+
+  mp->sw_if_index = ntohl (sw_if_index);
+  ip_prefix_encode (pfx, &mp->prefix);
+
+  vl_api_send_msg (ctx->reg, (u8 *) mp);
+
+  return 1;
+}
+
+static void
+vl_api_ip_container_proxy_dump_t_handler (vl_api_ip_container_proxy_dump_t *
+					  mp)
+{
+  vl_api_registration_t *reg;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  ip_walk_ctx_t ctx = {
+    .context = mp->context,
+    .reg = reg,
+  };
+
+  ip_container_proxy_walk (ip_container_proxy_send_details, &ctx);
+}
+
+static void
+vl_api_ioam_enable_t_handler (vl_api_ioam_enable_t * mp)
+{
+  int rv = 0;
+  vl_api_ioam_enable_reply_t *rmp;
+  clib_error_t *error;
+
+  /* Ignoring the profile id as currently a single profile
+   * is supported */
+  error = ip6_ioam_enable (mp->trace_enable, mp->pot_enable,
+			   mp->seqno, mp->analyse, (ip6_address_t *) mp->dst_addr);
+  if (error)
+    {
+      clib_error_report (error);
+      rv = clib_error_get_code (error);
+    }
+
+  REPLY_MACRO (VL_API_IOAM_ENABLE_REPLY);
+}
+
+static void
+vl_api_ioam_disable_t_handler (vl_api_ioam_disable_t * mp)
+{
+  int rv = 0;
+  vl_api_ioam_disable_reply_t *rmp;
+  clib_error_t *error;
+
+  error = clear_ioam_rewrite_fn ();
+  if (error)
+    {
+      clib_error_report (error);
+      rv = clib_error_get_code (error);
+    }
+
+  REPLY_MACRO (VL_API_IOAM_DISABLE_REPLY);
+}
+
+static void
+  vl_api_ip_source_and_port_range_check_add_del_t_handler
+  (vl_api_ip_source_and_port_range_check_add_del_t * mp)
+{
+  vl_api_ip_source_and_port_range_check_add_del_reply_t *rmp;
+  int rv = 0;
+
+  u8 is_add = mp->is_add;
+  fib_prefix_t pfx;
+  u16 *low_ports = 0;
+  u16 *high_ports = 0;
+  u32 vrf_id;
+  u16 tmp_low, tmp_high;
+  u8 num_ranges;
+  int i;
+
+  ip_prefix_decode (&mp->prefix, &pfx);
+
+  // Validate port range
+  num_ranges = mp->number_of_ranges;
+  if (num_ranges > 32)
+    {				// This is size of array in VPE.API
+      rv = VNET_API_ERROR_EXCEEDED_NUMBER_OF_RANGES_CAPACITY;
+      goto reply;
+    }
+
+  vec_reset_length (low_ports);
+  vec_reset_length (high_ports);
+
+  for (i = 0; i < num_ranges; i++)
+    {
+      tmp_low = mp->low_ports[i];
+      tmp_high = mp->high_ports[i];
+      // If tmp_low <= tmp_high then only need to check tmp_low = 0
+      // If tmp_low <= tmp_high then only need to check tmp_high > 65535
+      if (tmp_low > tmp_high || tmp_low == 0 || tmp_high > 65535)
+	{
+	  rv = VNET_API_ERROR_INVALID_VALUE;
+	  goto reply;
+	}
+      vec_add1 (low_ports, tmp_low);
+      vec_add1 (high_ports, tmp_high + 1);
+    }
+
+  vrf_id = ntohl (mp->vrf_id);
+
+  if (vrf_id < 1)
+    {
+      rv = VNET_API_ERROR_INVALID_VALUE;
+      goto reply;
+    }
+
+
+  if (FIB_PROTOCOL_IP6 == pfx.fp_proto)
+    {
+      rv = ip6_source_and_port_range_check_add_del (&pfx.fp_addr.ip6,
+						    pfx.fp_len,
+						    vrf_id,
+						    low_ports,
+						    high_ports, is_add);
+    }
+  else
+    {
+      rv = ip4_source_and_port_range_check_add_del (&pfx.fp_addr.ip4,
+						    pfx.fp_len,
+						    vrf_id,
+						    low_ports,
+						    high_ports, is_add);
+    }
+
+reply:
+  vec_free (low_ports);
+  vec_free (high_ports);
+  REPLY_MACRO (VL_API_IP_SOURCE_AND_PORT_RANGE_CHECK_ADD_DEL_REPLY);
+}
+
+static void
+  vl_api_ip_source_and_port_range_check_interface_add_del_t_handler
+  (vl_api_ip_source_and_port_range_check_interface_add_del_t * mp)
+{
+  vlib_main_t *vm = vlib_get_main ();
+  vl_api_ip_source_and_port_range_check_interface_add_del_reply_t *rmp;
+  ip4_main_t *im = &ip4_main;
+  int rv;
+  u32 sw_if_index;
+  u32 fib_index[IP_SOURCE_AND_PORT_RANGE_CHECK_N_PROTOCOLS];
+  u32 vrf_id[IP_SOURCE_AND_PORT_RANGE_CHECK_N_PROTOCOLS];
+  uword *p = 0;
+  int i;
+
+  vrf_id[IP_SOURCE_AND_PORT_RANGE_CHECK_PROTOCOL_TCP_OUT] =
+    ntohl (mp->tcp_out_vrf_id);
+  vrf_id[IP_SOURCE_AND_PORT_RANGE_CHECK_PROTOCOL_UDP_OUT] =
+    ntohl (mp->udp_out_vrf_id);
+  vrf_id[IP_SOURCE_AND_PORT_RANGE_CHECK_PROTOCOL_TCP_IN] =
+    ntohl (mp->tcp_in_vrf_id);
+  vrf_id[IP_SOURCE_AND_PORT_RANGE_CHECK_PROTOCOL_UDP_IN] =
+    ntohl (mp->udp_in_vrf_id);
+
+
+  for (i = 0; i < IP_SOURCE_AND_PORT_RANGE_CHECK_N_PROTOCOLS; i++)
+    {
+      if (vrf_id[i] != 0 && vrf_id[i] != ~0)
+	{
+	  p = hash_get (im->fib_index_by_table_id, vrf_id[i]);
+
+	  if (p == 0)
+	    {
+	      rv = VNET_API_ERROR_INVALID_VALUE;
+	      goto reply;
+	    }
+
+	  fib_index[i] = p[0];
+	}
+      else
+	fib_index[i] = ~0;
+    }
+  sw_if_index = ntohl (mp->sw_if_index);
+
+  VALIDATE_SW_IF_INDEX (mp);
+
+  rv =
+    set_ip_source_and_port_range_check (vm, fib_index, sw_if_index,
+					mp->is_add);
+
+  BAD_SW_IF_INDEX_LABEL;
+reply:
+
+  REPLY_MACRO (VL_API_IP_SOURCE_AND_PORT_RANGE_CHECK_INTERFACE_ADD_DEL_REPLY);
+}
+
+static void
+  vl_api_sw_interface_ip6_set_link_local_address_t_handler
+  (vl_api_sw_interface_ip6_set_link_local_address_t * mp)
+{
+  vl_api_sw_interface_ip6_set_link_local_address_reply_t *rmp;
+  ip6_address_t ip;
+  int rv;
+
+  VALIDATE_SW_IF_INDEX (mp);
+
+  ip6_address_decode (mp->ip, &ip);
+
+  rv = ip6_link_set_local_address (ntohl (mp->sw_if_index), &ip);
+
+  BAD_SW_IF_INDEX_LABEL;
+  REPLY_MACRO (VL_API_SW_INTERFACE_IP6_SET_LINK_LOCAL_ADDRESS_REPLY);
+}
+
+static void
+vl_api_sw_interface_ip6_get_link_local_address_t_handler (
+  vl_api_sw_interface_ip6_get_link_local_address_t *mp)
+{
+  vl_api_sw_interface_ip6_get_link_local_address_reply_t *rmp;
+  const ip6_address_t *ip = NULL;
+  int rv = 0;
+
+  VALIDATE_SW_IF_INDEX (mp);
+
+  ip = ip6_get_link_local_address (ntohl (mp->sw_if_index));
+  if (NULL == ip)
+    rv = VNET_API_ERROR_IP6_NOT_ENABLED;
+
+  BAD_SW_IF_INDEX_LABEL;
+  /* clang-format off */
+  REPLY_MACRO2 (VL_API_SW_INTERFACE_IP6_GET_LINK_LOCAL_ADDRESS_REPLY,
+  ({
+    if (!rv)
+      ip6_address_encode (ip, rmp->ip);
+  }))
+  /* clang-format on */
+}
+
+static void
+vl_api_ip_table_replace_begin_t_handler (vl_api_ip_table_replace_begin_t * mp)
+{
+  vl_api_ip_table_replace_begin_reply_t *rmp;
+  fib_protocol_t fproto;
+  u32 fib_index;
+  int rv = 0;
+
+  fproto = (mp->table.is_ip6 ? FIB_PROTOCOL_IP6 : FIB_PROTOCOL_IP4);
+  fib_index = fib_table_find (fproto, ntohl (mp->table.table_id));
+
+  if (INDEX_INVALID == fib_index)
+    rv = VNET_API_ERROR_NO_SUCH_FIB;
+  else
+    {
+      fib_table_mark (fib_index, fproto, FIB_SOURCE_API);
+      mfib_table_mark (mfib_table_find (fproto, ntohl (mp->table.table_id)),
+		       fproto, MFIB_SOURCE_API);
+    }
+  REPLY_MACRO (VL_API_IP_TABLE_REPLACE_BEGIN_REPLY);
+}
+
+static void
+vl_api_ip_table_replace_end_t_handler (vl_api_ip_table_replace_end_t * mp)
+{
+  vl_api_ip_table_replace_end_reply_t *rmp;
+  fib_protocol_t fproto;
+  u32 fib_index;
+  int rv = 0;
+
+  fproto = (mp->table.is_ip6 ? FIB_PROTOCOL_IP6 : FIB_PROTOCOL_IP4);
+  fib_index = fib_table_find (fproto, ntohl (mp->table.table_id));
+
+  if (INDEX_INVALID == fib_index)
+    rv = VNET_API_ERROR_NO_SUCH_FIB;
+  else
+    {
+      fib_table_sweep (fib_index, fproto, FIB_SOURCE_API);
+      mfib_table_sweep (mfib_table_find
+			(fproto, ntohl (mp->table.table_id)), fproto,
+			MFIB_SOURCE_API);
+    }
+  REPLY_MACRO (VL_API_IP_TABLE_REPLACE_END_REPLY);
+}
+
+static void
+vl_api_ip_table_flush_t_handler (vl_api_ip_table_flush_t * mp)
+{
+  vl_api_ip_table_flush_reply_t *rmp;
+  fib_protocol_t fproto;
+  u32 fib_index;
+  int rv = 0;
+
+  fproto = (mp->table.is_ip6 ? FIB_PROTOCOL_IP6 : FIB_PROTOCOL_IP4);
+  fib_index = fib_table_find (fproto, ntohl (mp->table.table_id));
+
+  if (INDEX_INVALID == fib_index)
+    rv = VNET_API_ERROR_NO_SUCH_FIB;
+  else
+    {
+      vnet_main_t *vnm = vnet_get_main ();
+      vnet_interface_main_t *im = &vnm->interface_main;
+      vnet_sw_interface_t *si;
+
+      /* Shut down interfaces in this FIB / clean out intfc routes */
+      /* *INDENT-OFF* */
+      pool_foreach (si, im->sw_interfaces)
+       {
+        if (fib_index == fib_table_get_index_for_sw_if_index (fproto,
+                                                              si->sw_if_index))
+          {
+            u32 flags = si->flags;
+            flags &= ~VNET_SW_INTERFACE_FLAG_ADMIN_UP;
+            vnet_sw_interface_set_flags (vnm, si->sw_if_index, flags);
+          }
+      }
+      /* *INDENT-ON* */
+
+      fib_table_flush (fib_index, fproto, FIB_SOURCE_API);
+      mfib_table_flush (mfib_table_find (fproto, ntohl (mp->table.table_id)),
+			fproto, MFIB_SOURCE_API);
+    }
+
+  REPLY_MACRO (VL_API_IP_TABLE_FLUSH_REPLY);
+}
+
+void
+vl_api_ip_reassembly_set_t_handler (vl_api_ip_reassembly_set_t * mp)
+{
+  vl_api_ip_reassembly_set_reply_t *rmp;
+  int rv = 0;
+  switch ((vl_api_ip_reass_type_t) clib_net_to_host_u32 (mp->type))
+    {
+    case IP_REASS_TYPE_FULL:
+      if (mp->is_ip6)
+	{
+	  rv = ip6_full_reass_set (clib_net_to_host_u32 (mp->timeout_ms),
+				   clib_net_to_host_u32
+				   (mp->max_reassemblies),
+				   clib_net_to_host_u32
+				   (mp->max_reassembly_length),
+				   clib_net_to_host_u32
+				   (mp->expire_walk_interval_ms));
+	}
+      else
+	{
+	  rv = ip4_full_reass_set (clib_net_to_host_u32 (mp->timeout_ms),
+				   clib_net_to_host_u32
+				   (mp->max_reassemblies),
+				   clib_net_to_host_u32
+				   (mp->max_reassembly_length),
+				   clib_net_to_host_u32
+				   (mp->expire_walk_interval_ms));
+	}
+      break;
+    case IP_REASS_TYPE_SHALLOW_VIRTUAL:
+      if (mp->is_ip6)
+	{
+	  rv =
+	    ip6_sv_reass_set (clib_net_to_host_u32 (mp->timeout_ms),
+			      clib_net_to_host_u32 (mp->max_reassemblies),
+			      clib_net_to_host_u32
+			      (mp->max_reassembly_length),
+			      clib_net_to_host_u32
+			      (mp->expire_walk_interval_ms));
+	}
+      else
+	{
+	  rv = ip4_sv_reass_set (clib_net_to_host_u32 (mp->timeout_ms),
+				 clib_net_to_host_u32 (mp->max_reassemblies),
+				 clib_net_to_host_u32
+				 (mp->max_reassembly_length),
+				 clib_net_to_host_u32
+				 (mp->expire_walk_interval_ms));
+	}
+      break;
+    }
+
+  REPLY_MACRO (VL_API_IP_REASSEMBLY_SET_REPLY);
+}
+
+void
+vl_api_ip_reassembly_get_t_handler (vl_api_ip_reassembly_get_t * mp)
+{
+  vl_api_registration_t *rp;
+
+  rp = vl_api_client_index_to_registration (mp->client_index);
+  if (rp == 0)
+    return;
+
+  vl_api_ip_reassembly_get_reply_t *rmp = vl_msg_api_alloc (sizeof (*rmp));
+  clib_memset (rmp, 0, sizeof (*rmp));
+  rmp->_vl_msg_id = ntohs (VL_API_IP_REASSEMBLY_GET_REPLY);
+  rmp->context = mp->context;
+  rmp->retval = 0;
+  u32 timeout_ms;
+  u32 max_reassemblies;
+  u32 max_reassembly_length;
+  u32 expire_walk_interval_ms;
+  switch ((vl_api_ip_reass_type_t) clib_net_to_host_u32 (mp->type))
+    {
+    case IP_REASS_TYPE_FULL:
+      if (mp->is_ip6)
+	{
+	  rmp->is_ip6 = 1;
+	  ip6_full_reass_get (&timeout_ms, &max_reassemblies,
+			      &max_reassembly_length,
+			      &expire_walk_interval_ms);
+	}
+      else
+	{
+	  rmp->is_ip6 = 0;
+	  ip4_full_reass_get (&timeout_ms, &max_reassemblies,
+			      &max_reassembly_length,
+			      &expire_walk_interval_ms);
+	}
+      break;
+    case IP_REASS_TYPE_SHALLOW_VIRTUAL:
+      if (mp->is_ip6)
+	{
+	  rmp->is_ip6 = 1;
+	  ip6_sv_reass_get (&timeout_ms, &max_reassemblies,
+			    &max_reassembly_length, &expire_walk_interval_ms);
+	}
+      else
+	{
+	  rmp->is_ip6 = 0;
+	  ip4_sv_reass_get (&timeout_ms, &max_reassemblies,
+			    &max_reassembly_length, &expire_walk_interval_ms);
+	}
+      break;
+    }
+  rmp->timeout_ms = clib_host_to_net_u32 (timeout_ms);
+  rmp->max_reassemblies = clib_host_to_net_u32 (max_reassemblies);
+  rmp->max_reassembly_length = clib_host_to_net_u32 (max_reassembly_length);
+  rmp->expire_walk_interval_ms =
+    clib_host_to_net_u32 (expire_walk_interval_ms);
+  vl_api_send_msg (rp, (u8 *) rmp);
+}
+
+void
+  vl_api_ip_reassembly_enable_disable_t_handler
+  (vl_api_ip_reassembly_enable_disable_t * mp)
+{
+  vl_api_ip_reassembly_enable_disable_reply_t *rmp;
+  int rv = 0;
+  switch ((vl_api_ip_reass_type_t) clib_net_to_host_u32 (mp->type))
+    {
+    case IP_REASS_TYPE_FULL:
+      rv =
+	ip4_full_reass_enable_disable (clib_net_to_host_u32 (mp->sw_if_index),
+				       mp->enable_ip4);
+      if (0 == rv)
+	rv =
+	  ip6_full_reass_enable_disable (clib_net_to_host_u32
+					 (mp->sw_if_index), mp->enable_ip6);
+      break;
+    case IP_REASS_TYPE_SHALLOW_VIRTUAL:
+      rv =
+	ip4_sv_reass_enable_disable (clib_net_to_host_u32 (mp->sw_if_index),
+				     mp->enable_ip4);
+      if (0 == rv)
+	{
+	  rv =
+	    ip6_sv_reass_enable_disable (clib_net_to_host_u32
+					 (mp->sw_if_index), mp->enable_ip6);
+	}
+      break;
+    }
+
+  REPLY_MACRO (VL_API_IP_REASSEMBLY_ENABLE_DISABLE_REPLY);
+}
+
+static walk_rc_t
+send_ip_punt_redirect_details (u32 rx_sw_if_index,
+			       const ip_punt_redirect_rx_t * ipr, void *arg)
+{
+  vl_api_ip_punt_redirect_details_t *mp;
+  fib_path_encode_ctx_t path_ctx = {
+    .rpaths = NULL,
+  };
+  ip_walk_ctx_t *ctx = arg;
+
+  mp = vl_msg_api_alloc (sizeof (*mp));
+  if (!mp)
+    return (WALK_STOP);;
+
+  clib_memset (mp, 0, sizeof (*mp));
+  mp->_vl_msg_id = ntohs (VL_API_IP_PUNT_REDIRECT_DETAILS);
+  mp->context = ctx->context;
+
+  fib_path_list_walk_w_ext (ipr->pl, NULL, fib_path_encode, &path_ctx);
+
+  mp->punt.rx_sw_if_index = htonl (rx_sw_if_index);
+  mp->punt.tx_sw_if_index = htonl (path_ctx.rpaths[0].frp_sw_if_index);
+
+  ip_address_encode (&path_ctx.rpaths[0].frp_addr,
+		     fib_proto_to_ip46 (ipr->fproto), &mp->punt.nh);
+
+  vl_api_send_msg (ctx->reg, (u8 *) mp);
+
+  vec_free (path_ctx.rpaths);
+
+  return (WALK_CONTINUE);
+}
+
+static void
+vl_api_ip_punt_redirect_dump_t_handler (vl_api_ip_punt_redirect_dump_t * mp)
+{
+  vl_api_registration_t *reg;
+  fib_protocol_t fproto = FIB_PROTOCOL_IP4;
+
+  reg = vl_api_client_index_to_registration (mp->client_index);
+  if (!reg)
+    return;
+
+  if (mp->is_ipv6 == 1)
+    fproto = FIB_PROTOCOL_IP6;
+
+  ip_walk_ctx_t ctx = {
+    .reg = reg,
+    .context = mp->context,
+  };
+
+  if (~0 != mp->sw_if_index)
+    {
+      u32 rx_sw_if_index;
+      index_t pri;
+
+      rx_sw_if_index = ntohl (mp->sw_if_index);
+      pri = ip_punt_redirect_find (fproto, rx_sw_if_index);
+
+      if (INDEX_INVALID == pri)
+	return;
+
+      send_ip_punt_redirect_details (rx_sw_if_index,
+				     ip_punt_redirect_get (pri), &ctx);
+    }
+  else
+    ip_punt_redirect_walk (fproto, send_ip_punt_redirect_details, &ctx);
+}
+
+void
+vl_api_ip_path_mtu_update_t_handler (vl_api_ip_path_mtu_update_t *mp)
+{
+  vl_api_ip_path_mtu_update_reply_t *rmp;
+  ip_address_t nh;
+  int rv = 0;
+
+  ip_address_decode2 (&mp->pmtu.nh, &nh);
+
+  rv = ip_path_mtu_update (&nh, ntohl (mp->pmtu.table_id),
+			   ntohs (mp->pmtu.path_mtu));
+
+  REPLY_MACRO (VL_API_IP_PATH_MTU_UPDATE_REPLY);
+}
+
+void
+vl_api_ip_path_mtu_replace_begin_t_handler (
+  vl_api_ip_path_mtu_replace_begin_t *mp)
+{
+  vl_api_ip_path_mtu_replace_begin_reply_t *rmp;
+  int rv;
+
+  rv = ip_path_mtu_replace_begin ();
+
+  REPLY_MACRO (VL_API_IP_PATH_MTU_REPLACE_BEGIN_REPLY);
+}
+
+void
+vl_api_ip_path_mtu_replace_end_t_handler (vl_api_ip_path_mtu_replace_end_t *mp)
+{
+  vl_api_ip_path_mtu_replace_end_reply_t *rmp;
+  int rv;
+
+  rv = ip_path_mtu_replace_end ();
+
+  REPLY_MACRO (VL_API_IP_PATH_MTU_REPLACE_END_REPLY);
+}
+
+static void
+send_ip_path_mtu_details (index_t ipti, vl_api_registration_t *rp, u32 context)
+{
+  vl_api_ip_path_mtu_details_t *rmp;
+  ip_address_t ip;
+  ip_pmtu_t *ipt;
+
+  ipt = ip_path_mtu_get (ipti);
+
+  REPLY_MACRO_DETAILS4 (VL_API_IP_PATH_MTU_DETAILS, rp, context, ({
+			  ip_pmtu_get_ip (ipt, &ip);
+			  ip_address_encode2 (&ip, &rmp->pmtu.nh);
+			  rmp->pmtu.table_id =
+			    htonl (ip_pmtu_get_table_id (ipt));
+			  rmp->pmtu.path_mtu = htons (ipt->ipt_cfg_pmtu);
+			}));
+}
+
+static void
+vl_api_ip_path_mtu_get_t_handler (vl_api_ip_path_mtu_get_t *mp)
+{
+  vl_api_ip_path_mtu_get_reply_t *rmp;
+  i32 rv = 0;
+
+  REPLY_AND_DETAILS_MACRO (
+    VL_API_IP_PATH_MTU_GET_REPLY, ip_pmtu_pool,
+    ({ send_ip_path_mtu_details (cursor, rp, mp->context); }));
+}
+
+#define vl_msg_name_crc_list
+#include <vnet/ip/ip.api.h>
+#undef vl_msg_name_crc_list
+
+static void
+setup_message_id_table (api_main_t * am)
+{
+#define _(id,n,crc) vl_msg_api_add_msg_name_crc (am, #n "_" #crc, id);
+  foreach_vl_msg_name_crc_ip;
+#undef _
+}
+
+static clib_error_t *
+ip_api_hookup (vlib_main_t * vm)
+{
+  api_main_t *am = vlibapi_get_main ();
+
+#define _(N,n)                                                  \
+    vl_msg_api_set_handlers(VL_API_##N, #n,                     \
+                           vl_api_##n##_t_handler,              \
+                           vl_noop_handler,                     \
+                           vl_api_##n##_t_endian,               \
+                           vl_api_##n##_t_print,                \
+                           sizeof(vl_api_##n##_t), 1);
+  foreach_ip_api_msg;
+#undef _
+
+  /*
+   * Mark the route add/del API as MP safe
+   */
+  am->is_mp_safe[VL_API_IP_ROUTE_ADD_DEL] = 1;
+  am->is_mp_safe[VL_API_IP_ROUTE_ADD_DEL_REPLY] = 1;
+
+  /*
+   * Set up the (msg_name, crc, message-id) table
+   */
+  setup_message_id_table (am);
+
+  return 0;
+}
+
+VLIB_API_INIT_FUNCTION (ip_api_hookup);
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/timestamp/node.c b/src/plugins/timestamp/node.c
new file mode 100644
index 000000000..357f51e1a
--- /dev/null
+++ b/src/plugins/timestamp/node.c
@@ -0,0 +1,245 @@
+/*
+ * Copyright (c) 2015 Cisco and/or its affiliates.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#include <vlib/vlib.h>
+#include <vnet/vnet.h>
+#include <vnet/pg/pg.h>
+#include <vnet/ethernet/ethernet.h>
+#include <vppinfra/error.h>
+#include <timestamp/timestamp.h>
+
+typedef struct
+{
+  u32 next_index;
+  u32 sw_if_index;
+  u64 stamp;
+} timestamp_trace_t;
+
+extern vlib_node_registration_t timestamp_ingress_node;
+extern vlib_node_registration_t timestamp_egress_node;
+
+/* packet trace format function */
+static u8 *
+format_timestamp_trace (u8 * s, va_list * args)
+{
+  CLIB_UNUSED (vlib_main_t * vm) = va_arg (*args, vlib_main_t *);
+  CLIB_UNUSED (vlib_node_t * node) = va_arg (*args, vlib_node_t *);
+  timestamp_trace_t *t = va_arg (*args, timestamp_trace_t *);
+
+  s = format (s, "TIMESTAMP: sw_if_index %d, next_index %d, sec %Lx", 
+                            t->sw_if_index, t->next_index, t->stamp);
+  return s;
+}
+
+#define foreach_timestamp_error \
+_(INGRESS_STAMPED, "Timestamp ingress packets processed") \
+_(EGRESS_STAMPED, "Timestamp egress packets processed")
+
+typedef enum
+{
+#define _(sym,str) TIMESTAMP_ERROR_##sym,
+  foreach_timestamp_error
+#undef _
+    TIMESTAMP_N_ERROR,
+} timestamp_error_t;
+
+static char *timestamp_error_strings[] = {
+#define _(sym,string) string,
+  foreach_timestamp_error
+#undef _
+};
+
+typedef enum
+{
+  TIMESTAMP_NEXT_DROP,
+  TIMESTAMP_NEXT_ETHERNET_INPUT,
+  TIMESTAMP_N_NEXT,
+} timestamp_next_t;
+typedef union
+{
+  u64 as_u64;
+  u32 as_u32[2];
+} time_u64_t;
+/*
+ * Simple dual/single loop version, default version which will compile
+ * everywhere.
+ *
+ * Node costs 30 clocks/pkt at a vector size of 51
+ */
+static uword
+timestamp_node_inline (vlib_main_t * vm, vlib_node_runtime_t * node, vlib_frame_t * frame, u8 egress)
+{
+  u32 n_left_from, *from, *to_next;
+  timestamp_next_t next_index;
+  u32 pkts_stamped = 0;
+  vnet_main_t * vnm = vnet_get_main();
+  vnet_interface_main_t * im = & vnm -> interface_main;
+  u8 arc = im -> output_feature_arc_index;
+  vnet_feature_config_main_t * fcm;
+
+  if (egress)
+    fcm = vnet_feature_get_config_main(arc);
+
+  from = vlib_frame_vector_args (frame);
+  n_left_from = frame->n_vectors;
+  next_index = node->cached_next_index;
+
+  while (n_left_from > 0)
+  {
+    u32 n_left_to_next;
+
+    vlib_get_next_frame (vm, node, next_index, to_next, n_left_to_next);
+     // Single loop
+    while (n_left_from > 0 && n_left_to_next > 0)
+    {
+      u32 bi0;
+      vlib_buffer_t *b0;
+      u32 next0;
+      u64 stamp;
+
+      /* speculatively enqueue b0 to the current next frame */
+      bi0 = from[0];
+      to_next[0] = bi0;
+      from += 1;
+      to_next += 1;
+      n_left_from -= 1;
+      n_left_to_next -= 1;
+
+      b0 = vlib_get_buffer (vm, bi0);
+      // Stamp
+      stamp = unix_time_now_nsec();
+
+      /* Pass the timestamp, thanks to the vnet_buffer->opaque2 unused metadata field */
+      /* Set next0 to e.g. interface-tx */
+      timestamp_meta_t *time_meta = (void *)  &vnet_buffer2 (b0)->unused[0];
+      if (egress)
+      {
+        vnet_get_config_data(&fcm->config_main, &b0->current_config_index, &next0,/* # bytes of config data */0);
+        // Save egress timestamp
+        time_meta->timestamp_egress = stamp;
+        // If we have all 3, then ioam data must be inserted
+        if(time_meta->ptr_to_ioam_transit_delay && time_meta->timestamp_ingress && time_meta->timestamp_egress)
+        {
+          time_u64_t transit_delay;
+          transit_delay.as_u64 = time_meta->timestamp_egress - time_meta->timestamp_ingress;
+          // overflow
+          if (transit_delay.as_u32[1])
+          {
+            transit_delay.as_u32[0] = 0x80000000; // overflow as per IETF
+          }
+          *time_meta->ptr_to_ioam_transit_delay = clib_host_to_net_u32(transit_delay.as_u32[0]);
+          // Clear
+          time_meta->ptr_to_ioam_transit_delay = NULL;
+        }
+      }
+      else
+      {
+        next0 = TIMESTAMP_NEXT_ETHERNET_INPUT;
+        time_meta->timestamp_ingress = stamp;
+      }
+      if (PREDICT_FALSE ((node->flags & VLIB_NODE_FLAG_TRACE)
+            && (b0->flags & VLIB_BUFFER_IS_TRACED)))
+      {
+        timestamp_trace_t *t = vlib_add_trace (vm, node, b0, sizeof (*t));
+        t->next_index = next0;
+        if(egress)
+        {
+          t->sw_if_index = vnet_buffer (b0)->sw_if_index[VLIB_TX];
+          t->stamp = time_meta->timestamp_egress;
+        }
+        else
+        {
+          t->sw_if_index = vnet_buffer (b0)->sw_if_index[VLIB_RX];
+          t->stamp = time_meta->timestamp_ingress;
+        }
+      }
+
+      pkts_stamped += 1;
+
+      /* verify speculative enqueue, maybe switch current next frame */
+      vlib_validate_buffer_enqueue_x1 (vm, node, next_index,
+                                      to_next, n_left_to_next,
+                                      bi0, next0);
+	  }
+    vlib_put_next_frame (vm, node, next_index, n_left_to_next);
+  }
+
+  if (egress)
+  {
+    vlib_node_increment_counter (vm, node->node_index, TIMESTAMP_ERROR_EGRESS_STAMPED, pkts_stamped);
+  }
+  else
+  {
+    vlib_node_increment_counter (vm, node->node_index, TIMESTAMP_ERROR_INGRESS_STAMPED, pkts_stamped);
+  }
+  return frame->n_vectors;
+}
+static uword
+timestamp_ingress_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node, vlib_frame_t * frame)
+{
+  return timestamp_node_inline (vm, node, frame, 0); /* ingress */
+}
+/* *INDENT-OFF* */
+VLIB_REGISTER_NODE (timestamp_ingress_node) =
+{
+  .function = timestamp_ingress_node_fn,
+  .name = "timestamp-ingress",
+  .vector_size = sizeof (u32),
+  .format_trace = format_timestamp_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+
+  .n_errors = ARRAY_LEN(timestamp_error_strings),
+  .error_strings = timestamp_error_strings,
+
+  .n_next_nodes = TIMESTAMP_N_NEXT,
+
+  /* edit / add dispositions here */
+  .next_nodes = {
+    [TIMESTAMP_NEXT_ETHERNET_INPUT] = "ethernet-input",
+    [TIMESTAMP_NEXT_DROP] = "error-drop", /* not used */
+  },
+};
+static uword
+timestamp_egress_node_fn (vlib_main_t * vm, vlib_node_runtime_t * node, vlib_frame_t * frame)
+{
+  return timestamp_node_inline (vm, node, frame, 1); /* egress */
+}
+VLIB_REGISTER_NODE (timestamp_egress_node) =
+{
+  .function = timestamp_egress_node_fn,
+  .name = "timestamp-egress",
+  .vector_size = sizeof (u32),
+  .format_trace = format_timestamp_trace,
+  .type = VLIB_NODE_TYPE_INTERNAL,
+
+  .n_errors = ARRAY_LEN(timestamp_error_strings),
+  .error_strings = timestamp_error_strings,
+
+  .n_next_nodes = TIMESTAMP_N_NEXT,
+
+  /* edit / add dispositions here */
+  .next_nodes = {
+    [TIMESTAMP_NEXT_DROP] = "error-drop", 
+    [TIMESTAMP_NEXT_ETHERNET_INPUT] = "ethernet-input", /* not used */
+  },
+};
+/* *INDENT-ON* */
+
+/*
+ * fd.io coding-style-patch-verification: ON
+ *
+ * Local Variables:
+ * eval: (c-set-style "gnu")
+ * End:
+ */
diff --git a/src/plugins/timestamp/timestamp.api b/src/plugins/timestamp/timestamp.api
new file mode 100644
index 000000000..64a84c636
--- /dev/null
+++ b/src/plugins/timestamp/timestamp.api
@@ -0,0 +1,34 @@
+/* Hey Emacs use -*- mode: C -*- */
+/*
+ * Copyright (c) 2020 TNO.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+/* Define a timestamp binary API to control the feature */
+
+option version = "0.1.0";
+import "vnet/interface_types.api";
+
+autoreply define timestamp_enable_disable {
+  /* Client identifier, set from api_main.my_client_index */
+  u32 client_index;
+
+  /* Arbitrary context, so client can match reply to request */
+  u32 context;
+
+  /* Enable / disable the feature */
+  bool enable_disable;
+
+  /* Interface handle */
+  vl_api_interface_index_t sw_if_index;
+};
diff --git a/src/plugins/timestamp/timestamp.c b/src/plugins/timestamp/timestamp.c
new file mode 100644
index 000000000..5a567b936
--- /dev/null
+++ b/src/plugins/timestamp/timestamp.c
@@ -0,0 +1,177 @@
+/*
+ * Copyright (c) 2020 TNO.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/**
+ * @file
+ * @brief Timestamp Plugin, plugin API / trace / CLI handling.
+ */
+
+#include <vnet/vnet.h>
+#include <vnet/plugin/plugin.h>
+#include <timestamp/timestamp.h>
+
+#include <vlibapi/api.h>
+#include <vlibmemory/api.h>
+
+#include <timestamp/timestamp.api_enum.h>
+#include <timestamp/timestamp.api_types.h>
+
+#define REPLY_MSG_ID_BASE sm->msg_id_base
+#include <vlibapi/api_helper_macros.h>
+
+/* *INDENT-OFF* */
+VLIB_PLUGIN_REGISTER () = {
+    .version = TIMESTAMP_PLUGIN_BUILD_VER,
+    .description = "Timestamp plugin for VPP",
+};
+/* *INDENT-ON* */
+
+timestamp_main_t timestamp_main;
+
+/**
+ * @brief Enable/disable the timestamp plugin. 
+ *
+ * Action function shared between message handler and debug CLI.
+ */
+
+int timestamp_enable_disable (timestamp_main_t * sm, u32 sw_if_index,
+                              int enable_disable)
+{
+  vnet_sw_interface_t * sw;
+  int rv = 0;
+
+  /* Utterly wrong? */
+  if (pool_is_free_index (sm->vnet_main->interface_main.sw_interfaces, sw_if_index))
+  {
+    return VNET_API_ERROR_INVALID_SW_IF_INDEX;
+  }
+
+  /* Not a physical port? */
+  sw = vnet_get_sw_interface (sm->vnet_main, sw_if_index);
+  if (sw->type != VNET_SW_INTERFACE_TYPE_HARDWARE)
+  {
+    return VNET_API_ERROR_INVALID_SW_IF_INDEX;
+  }
+  
+  vnet_feature_enable_disable ("device-input", "timestamp-ingress", sw_if_index, enable_disable, 0, 0);
+  vnet_feature_enable_disable ("interface-output", "timestamp-egress", sw_if_index, enable_disable, 0, 0);
+
+  return rv;
+}
+
+static clib_error_t *
+timestamp_enable_disable_command_fn (vlib_main_t * vm,
+                                     unformat_input_t * input,
+                                     vlib_cli_command_t * cmd)
+{
+  timestamp_main_t * sm = &timestamp_main;
+  u32 sw_if_index = ~0;
+  int enable_disable = 1;
+    
+  int rv;
+
+  while (unformat_check_input (input) != UNFORMAT_END_OF_INPUT) 
+  {
+    if (unformat (input, "disable")) enable_disable = 0;
+    else if (unformat (input, "%U", unformat_vnet_sw_interface, sm->vnet_main, &sw_if_index));
+    else break;
+  }
+
+  if (sw_if_index == ~0)
+  {
+    return clib_error_return (0, "Please specify an interface...");
+  }
+    
+  rv = timestamp_enable_disable (sm, sw_if_index, enable_disable);
+
+  switch(rv) 
+  {
+    case 0:
+      break;
+
+    case VNET_API_ERROR_INVALID_SW_IF_INDEX:
+      return clib_error_return(0, "Invalid interface, only works on physical ports");
+      break;
+
+    case VNET_API_ERROR_UNIMPLEMENTED:
+      return clib_error_return (0, "Device driver doesn't support");
+      break;
+
+    default:
+      return clib_error_return (0, "timestamp_enable_disable returned %d", rv);
+  }
+  return 0;
+}
+
+/**
+ * @brief CLI command to enable/disable the timestamp plugin.
+ */
+VLIB_CLI_COMMAND (enable_disable_timestamp, static) = {
+    .path = "timestamp",
+    .short_help = 
+    "timestamp <interface-name> [disable]",
+    .function = timestamp_enable_disable_command_fn,
+};
+
+/**
+ * @brief Plugin API message handler.
+ */
+static void vl_api_timestamp_enable_disable_t_handler
+(vl_api_timestamp_enable_disable_t * mp)
+{
+  vl_api_timestamp_enable_disable_reply_t * rmp;
+  timestamp_main_t * sm = &timestamp_main;
+  int rv;
+
+  rv = timestamp_enable_disable (sm, ntohl(mp->sw_if_index), (int) (mp->enable_disable));
+  
+  REPLY_MACRO(VL_API_TIMESTAMP_ENABLE_DISABLE_REPLY);
+}
+
+/* API definitions */
+#include <timestamp/timestamp.api.c>
+
+/**
+ * @brief Initialize the timestamp plugin.
+ */
+static clib_error_t * timestamp_init (vlib_main_t * vm)
+{
+  timestamp_main_t * sm = &timestamp_main;
+
+  sm->vnet_main =  vnet_get_main ();
+  /* Add our API messages to the global name_crc hash table */
+  sm->msg_id_base = setup_message_id_table ();
+
+  return 0;
+}
+
+VLIB_INIT_FUNCTION (timestamp_init) =
+{
+  .runs_after = VLIB_INITS("ip_neighbor_init"),
+};
+/**
+ * @brief Hook the timestamp plugin into the VPP graph hierarchy.
+ */
+VNET_FEATURE_INIT (timestamp_ingress, static) = 
+{
+  .arc_name = "device-input",
+  .node_name = "timestamp-ingress",
+  .runs_before = VNET_FEATURES ("ethernet-input"),
+};
+VNET_FEATURE_INIT (timestamp_egress, static) = 
+{
+  .arc_name = "interface-output",
+  .node_name = "timestamp-egress",
+  .runs_before = VNET_FEATURES ("interface-tx"),
+};
diff --git a/src/plugins/timestamp/timestamp.h b/src/plugins/timestamp/timestamp.h
new file mode 100644
index 000000000..9ad69e847
--- /dev/null
+++ b/src/plugins/timestamp/timestamp.h
@@ -0,0 +1,47 @@
+/*
+ * Copyright (c) 2020 TNO.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+#ifndef __included_timestamp_h__
+#define __included_timestamp_h__
+
+#include <vnet/vnet.h>
+#include <vnet/ip/ip.h>
+#include <vnet/ethernet/ethernet.h>
+
+#include <vppinfra/hash.h>
+#include <vppinfra/error.h>
+#include <vppinfra/elog.h>
+
+typedef struct {
+    /* API message ID base */
+    u16 msg_id_base;
+    
+    /* convenience */
+    vnet_main_t * vnet_main;
+} timestamp_main_t;
+
+#define TIMESTAMP_
+typedef struct {
+  u32 *ptr_to_ioam_transit_delay;
+  u64 timestamp_ingress;
+  u64 timestamp_egress;
+} timestamp_meta_t;
+extern timestamp_main_t timestamp_main;
+
+extern vlib_node_registration_t timestamp_ingress_node;
+extern vlib_node_registration_t timestamp_egress_node;
+
+#define TIMESTAMP_PLUGIN_BUILD_VER "1.0"
+
+#endif /* __included_timestamp_h__ */
diff --git a/src/plugins/timestamp/timestamp_plugin_doc.md b/src/plugins/timestamp/timestamp_plugin_doc.md
new file mode 100644
index 000000000..a57fdb6aa
--- /dev/null
+++ b/src/plugins/timestamp/timestamp_plugin_doc.md
@@ -0,0 +1,44 @@
+# Timestamp plugin for VPP    {#timestamp_plugin_doc}
+
+## Overview
+
+This is the VPP timestamp plugin.  It timestamps a packet coming INTO the device-input
+feature arc in order for the another plugin to take calculate the delays between input
+and their nodes.
+
+For deeper dive information see the annotations in the  timestamp code itself. See [timestamp.c](@ref timestamp.c)
+
+## How to build and run the timestamp plugin.
+
+Now (re)build VPP.
+
+	$ make wipe
+
+Define environmental variable 'TIMESTAMP_PLUGIN=yes' with a process scope
+
+	$ TIMESTAMP_PLUGIN=yes make build
+
+or a session scope, and build VPP. 
+
+	$ export TIMESTAMP_PLUGIN=yes
+	$ make build
+
+Now run VPP and make sure the plugin is loaded. 
+
+	$ make run
+	...
+	load_one_plugin:184: Loaded plugin: memif_plugin.so (Packet Memory Interface (experimetal))
+	load_one_plugin:184: Loaded plugin: timestamp_plugin.so (Timestamp of VPP Plugin)
+	load_one_plugin:184: Loaded plugin: nat_plugin.so (Network Address Translation)
+	...
+	DBGvpp#
+
+## Configuration
+
+To enable the timestamp plugin
+
+	timestamp <interface name>
+
+To disable the timestamp plugin
+
+	timestamp <interface name> disable
diff --git a/src/plugins/timestamp/timestamp_test.c b/src/plugins/timestamp/timestamp_test.c
new file mode 100644
index 000000000..7f3aa949b
--- /dev/null
+++ b/src/plugins/timestamp/timestamp_test.c
@@ -0,0 +1,83 @@
+/*
+ * Copyright (c) 2020 TNO.
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at:
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+/*
+ *------------------------------------------------------------------
+ * timestamp_test.c - test harness plugin
+ *------------------------------------------------------------------
+ */
+
+#include <vat/vat.h>
+#include <vlibapi/api.h>
+#include <vlibmemory/api.h>
+#include <vppinfra/error.h>
+
+#define __plugin_msg_base timestamp_test_main.msg_id_base
+#include <vlibapi/vat_helper_macros.h>
+
+uword unformat_sw_if_index (unformat_input_t * input, va_list * args);
+
+/* Declare message IDs */
+#include <timestamp/timestamp.api_enum.h>
+#include <timestamp/timestamp.api_types.h>
+
+typedef struct {
+    /* API message ID base */
+    u16 msg_id_base;
+    vat_main_t *vat_main;
+} timestamp_test_main_t;
+
+timestamp_test_main_t timestamp_test_main;
+
+static int api_timestamp_enable_disable (vat_main_t * vam)
+{
+    unformat_input_t * i = vam->input;
+    int enable_disable = 1;
+    u32 sw_if_index = ~0;
+    vl_api_timestamp_enable_disable_t * mp;
+    int ret;
+
+    /* Parse args required to build the message */
+    while (unformat_check_input (i) != UNFORMAT_END_OF_INPUT) 
+    {
+      if (unformat (i, "%U", unformat_sw_if_index, vam, &sw_if_index));
+	    else if (unformat (i, "sw_if_index %d", &sw_if_index));
+      else if (unformat (i, "disable"))  enable_disable = 0;
+      else break;
+    }
+
+    if (sw_if_index == ~0) 
+    {
+      errmsg ("missing interface name / explicit sw_if_index number \n");
+      return -99;
+    }
+
+    /* Construct the API message */
+    M(TIMESTAMP_ENABLE_DISABLE, mp);
+    mp->sw_if_index = ntohl (sw_if_index);
+    mp->enable_disable = enable_disable;
+
+    /* send it... */
+    S(mp);
+
+    /* Wait for a reply... */
+    W (ret);
+    return ret;
+}
+
+/*
+ * List of messages that the api test plugin sends,
+ * and that the data plane plugin processes
+ */
+#include <timestamp/timestamp.api_test.c>
-- 
2.36.0.windows.1

